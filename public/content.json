{"meta":{"title":"软微9133","subtitle":null,"description":"只争朝夕，不负韶华","author":"PPsteven","url":"http://ppsteven.github.io","root":"/"},"pages":[{"title":"","date":"2020-02-14T17:42:37.825Z","updated":"2019-12-22T15:16:34.050Z","comments":true,"path":"404/index.html","permalink":"http://ppsteven.github.io/404/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-10-26T17:38:06.000Z","updated":"2020-02-15T16:29:40.108Z","comments":false,"path":"categories/index.html","permalink":"http://ppsteven.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2019-10-26T17:38:15.000Z","updated":"2020-02-15T17:06:40.671Z","comments":true,"path":"about/index.html","permalink":"http://ppsteven.github.io/about/index.html","excerpt":"","text":"自我介绍研二,对计算机和金融感兴趣。目前在一家互联网公司做后台开发实习，PHP开发。擅长爬虫，爬过的网站有：美团，点评，协程，马蜂窝等。"},{"title":"归档","date":"2019-10-27T08:36:41.000Z","updated":"2019-12-22T15:16:34.054Z","comments":true,"path":"archives/index.html","permalink":"http://ppsteven.github.io/archives/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-11-04T14:03:28.000Z","updated":"2020-02-16T09:47:47.761Z","comments":false,"path":"link/index.html","permalink":"http://ppsteven.github.io/link/index.html","excerpt":"","text":"用户 网址 描述 jordenbruce https://jordenbruce.com/ 数仓大神 wangjs-jacky http://wangjs-jacky.github.io/ 风雪之隅 http://www.laruence.com/2015/05/28/3038.html 鸟哥,PHP7主要开发人 韩天峰 http://rango.swoole.com/ swoole创始人"},{"title":"tags","date":"2019-10-26T17:09:48.000Z","updated":"2020-02-15T16:29:21.685Z","comments":false,"path":"tags/index.html","permalink":"http://ppsteven.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker搭建elasticsearch+kibana","slug":"docker-elasticsearch-Kibana-installation","date":"2020-02-25T01:10:44.000Z","updated":"2020-02-25T03:24:08.469Z","comments":false,"path":"2020/02/25/docker-elasticsearch-Kibana-installation/","link":"","permalink":"http://ppsteven.github.io/2020/02/25/docker-elasticsearch-Kibana-installation/","excerpt":"工作中需要对公司的es服务器进行配置，小白不敢直接在公司的开发机上直接修改。故需要在测试机上临时搭建一个es+kibana环境。 为了避开基础的环境问题和快速搭建，docker是我们非常好的伙伴","text":"工作中需要对公司的es服务器进行配置，小白不敢直接在公司的开发机上直接修改。故需要在测试机上临时搭建一个es+kibana环境。 为了避开基础的环境问题和快速搭建，docker是我们非常好的伙伴 elasticsearch安装1docker pull elasticsearch:6.6.1 创建配置文件 12345# vim /etc/elasticsearch.ymlcluster.name: \"docker-cluster\"network.host: 0.0.0.0# 允许任何端口访问transport.host: 0.0.0.0 启动容器 1docker run -di --name=es -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /etc/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml elasticsearch:6.6.1 开放了9300端口 挂载配置文件：/usr/share/elasticsearch/config/elasticsearch.yml 查看容器是否启动，以及端口是否正常开放 123$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESacc39c54a0d8 elasticsearch:6.6.1 \"/usr/local/bin/dock…\" 18 hours ago Up 18 hours 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp es 更加直观的判断是否启动成功的提示是，直接访问 9200 端口号。成功的话，会返回如下信息。 12345678910111213141516# 这里假设一个公网的ip http://111.111.111.111:9200/&#123; &quot;name&quot; : &quot;cWz9ZWm&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;5v3SilrTQyCjjQO-a5heBA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.2.4&quot;, &quot;build_hash&quot; : &quot;ccec39f&quot;, &quot;build_date&quot; : &quot;2018-04-12T20:37:28.497551Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.2.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; kibana安装1docker pull kibana:6.6.1 接下来，如果我们手里没有kibana配置文件的信息的话，需要先从容器中copy一份过来。 1234567891011# 启动容器 tempdocker run -di -p 5601:5601 --name temp kibana:6.6.1# 创建文件夹存放配置文件mkdir -p /etc/kibana# 从容器中复制过来，注意配置文件地址是 /usr/share/kibana/configdocker cp temp:/usr/share/kibana/config /etc/kibana/config# 删除临时的temp文件，强制删除docker container rm -f temp 注意挂载的配置文件地址为： /usr/share/kibana/config 修改本地配置文件 123456789# vim /etc/kibana/config/kibana.ymlserver.name: kibana# 允许所有地址访问server.host: \"0.0.0.0\"# elasticsearch的地址，注意这里我直接填写的公网ip。# 有的教程里面填写elasticsearch，127.0.0.1，localhost 等# docker容器的网络问题是我的弱项，采用上述方案，需要在docker容器互联，网络方面有一定的知识，不然会出问题。elasticsearch.url: http://111.111.111.111:9200xpack.monitoring.ui.container.elasticsearch.enabled: true 启动容器 1docker run -di --name=kibana -p 5601:5601 -v /etc/kibana/config:/usr/share/kibana/config kibana:6.6.1 这里开放了新的端口 5601 验证是否成功，直接访问 http://111.111.111.111:5601 就可以看到如下界面 注意点 elasticsearch 和 kibana 的版本最好保持一致，这里我都使用了 6.6.1 elasticsearch 和 kibana 都是比较吃内存的家伙，所以如果你的服务器的内存少于4G，可能就会出很多问题。 kibana 端口可能会被封掉。注意你的服务器有没有打开 5601 端口，若是没有的话，换一个端口映射即可。-p 7899:5601 配置修改后可能会需要重启服务/容器 12345# 重启/查看 服务状态service kibana restart/statussystemctl restart/status kibana# 容器重启docker restart kibana TODO如果是搭建ELK，我们可能还需要 Filebeat 和 Logstash 的配和，这些还要后续的进行搭建。ELK 是好东西，只是太吃内存了。如果不是公司基本的项目，只是做的玩票性质的小服务，估计买服务器的开销就不小，所以我暂时不太会用 ELK 搭建日志系统。 参考资料Docker安装ELK","categories":[{"name":"docker","slug":"docker","permalink":"http://ppsteven.github.io/categories/docker/"}],"tags":[{"name":"es","slug":"es","permalink":"http://ppsteven.github.io/tags/es/"},{"name":"kibana","slug":"kibana","permalink":"http://ppsteven.github.io/tags/kibana/"},{"name":"docker","slug":"docker","permalink":"http://ppsteven.github.io/tags/docker/"}]},{"title":"linux 环境变量读取顺序","slug":"linux-environment-variable-config-file-order","date":"2020-02-22T13:02:00.000Z","updated":"2020-02-22T13:21:29.402Z","comments":false,"path":"2020/02/22/linux-environment-variable-config-file-order/","link":"","permalink":"http://ppsteven.github.io/2020/02/22/linux-environment-variable-config-file-order/","excerpt":"","text":"linux 环境变量读取顺序参考了许多优秀的教程，总结了 linux 读取配置文件的顺序 文件 系统/用户 描述 /etc/environment 系统 系统环境变量 /etc/profile 系统 此文件为系统的每个用户设置环境信息当用户第一次登录时,该文件被执行并从/etc/profile.d目录的配置文件中搜集shell的设置. /etc/profile.d/test.sh 系统 新建文件，没有文件夹可略过 /etc/bashrc/etc/bash.bashrc 系统 为每一个运行 bash shell的用户执行此文件当 bash shell被打开时,该文件被读取. ~/.bash_profile~/.bash_login 用户 每个用户输入专用于自己使用的shell信息当用户登录时,该文件仅仅执行一次!默认情况下,设置一些环境变量,执行用户的.bashrc文件 ~/.profile 用户 只在用户登录的时候读取一次 ~/.bashrc 用户 每次打开新 bash shell 或 登录时生效 ~/.bash_logout 用户 每次退出 bash shell 或 系统时生效 参考资料Linux环境变量配置全攻略 /etc/profile和~/.bash_profile等文件的区别和联系","categories":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/tags/linux/"},{"name":"环境变量","slug":"环境变量","permalink":"http://ppsteven.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"}]},{"title":"【转载】Linux环境变量配置全攻略","slug":"转载/Linux环境变量配置全攻略","date":"2020-02-22T07:02:00.000Z","updated":"2020-02-22T13:21:13.450Z","comments":false,"path":"2020/02/22/转载/Linux环境变量配置全攻略/","link":"","permalink":"http://ppsteven.github.io/2020/02/22/%E8%BD%AC%E8%BD%BD/Linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E5%85%A8%E6%94%BB%E7%95%A5/","excerpt":"Linux环境变量配置全攻略 注：本文是转载文章 原文链接：Linux环境变量配置全攻略 Linux环境变量配置在自定义安装软件的时候，经常需要配置环境变量，下面列举出各种对环境变量的配置方法。 下面所有例子的环境说明如下： 系统：Ubuntu 14.0 用户名：uusama 需要配置MySQL环境变量路径：/home/uusama/mysql/bin Linux读取环境变量读取环境变量的方法： export命令显示当前系统定义的所有环境变量 echo $PATH命令输出当前的PATH环境变量的值","text":"Linux环境变量配置全攻略 注：本文是转载文章 原文链接：Linux环境变量配置全攻略 Linux环境变量配置在自定义安装软件的时候，经常需要配置环境变量，下面列举出各种对环境变量的配置方法。 下面所有例子的环境说明如下： 系统：Ubuntu 14.0 用户名：uusama 需要配置MySQL环境变量路径：/home/uusama/mysql/bin Linux读取环境变量读取环境变量的方法： export命令显示当前系统定义的所有环境变量 echo $PATH命令输出当前的PATH环境变量的值 这两个命令执行的效果如下 123456789101112131415uusama@ubuntu:~$ exportdeclare -x HOME=&quot;/home/uusama&quot;declare -x LANG=&quot;en_US.UTF-8&quot;declare -x LANGUAGE=&quot;en_US:&quot;declare -x LESSCLOSE=&quot;/usr/bin/lesspipe %s %s&quot;declare -x LESSOPEN=&quot;| /usr/bin/lesspipe %s&quot;declare -x LOGNAME=&quot;uusama&quot;declare -x MAIL=&quot;/var/mail/uusama&quot;declare -x PATH=&quot;/home/uusama/bin:/home/uusama/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;declare -x SSH_TTY=&quot;/dev/pts/0&quot;declare -x TERM=&quot;xterm&quot;declare -x USER=&quot;uusama&quot;uusama@ubuntu:~$ echo $PATH/home/uusama/bin:/home/uusama/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin 其中PATH变量定义了运行命令的查找路径，以冒号:分割不同的路径，使用export定义的时候可加双引号也可不加。 Linux环境变量配置方法一：export PATH使用export命令直接修改PATH的值，配置MySQL进入环境变量的方法: 1234export PATH=/home/uusama/mysql/bin:$PATH# 或者把PATH放在前面export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：立即生效 生效期限：当前终端有效，窗口关闭后无效 生效范围：仅对当前用户有效 配置的环境变量中不要忘了加上原来的配置，即$PATH部分，避免覆盖原来配置 Linux环境变量配置方法二：vim ~/.bashrc通过修改用户目录下的~/.bashrc文件进行配置： 1234vim ~/.bashrc# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：使用相同的用户打开新的终端时生效，或者手动source ~/.bashrc生效 生效期限：永久有效 生效范围：仅对当前用户有效 如果有后续的环境变量加载文件覆盖了PATH定义，则可能不生效 Linux环境变量配置方法三：vim ~/.bash_profile和修改~/.bashrc文件类似，也是要在文件最后加上新的路径即可： 1234vim ~/.bash_profile# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：使用相同的用户打开新的终端时生效，或者手动source ~/.bash_profile生效 生效期限：永久有效 生效范围：仅对当前用户有效 如果没有~/.bash_profile文件，则可以编辑~/.profile文件或者新建一个 Linux环境变量配置方法四：vim /etc/bashrc该方法是修改系统配置，需要管理员权限（如root）或者对该文件的写入权限： 1234567# 如果/etc/bashrc文件不可编辑，需要修改为可编辑chmod -v u+w /etc/bashrcvim /etc/bashrc# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source /etc/bashrc生效 生效期限：永久有效 生效范围：对所有用户有效 Linux环境变量配置方法五：vim /etc/profile该方法修改系统配置，需要管理员权限或者对该文件的写入权限，和vim /etc/bashrc类似： 1234567# 如果/etc/profile文件不可编辑，需要修改为可编辑chmod -v u+w /etc/profilevim /etc/profile# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source /etc/profile生效 生效期限：永久有效 生效范围：对所有用户有效 Linux环境变量配置方法六：vim /etc/environment该方法是修改系统环境配置文件，需要管理员权限或者对该文件的写入权限： 1234567# 如果/etc/bashrc文件不可编辑，需要修改为可编辑chmod -v u+w /etc/environmentvim /etc/profile# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source /etc/environment生效 生效期限：永久有效 生效范围：对所有用户有效 Linux环境变量加载原理解析上面列出了环境变量的各种配置方法，那么Linux是如何加载这些配置的呢？是以什么样的顺序加载的呢？ 特定的加载顺序会导致相同名称的环境变量定义被覆盖或者不生效。 环境变量的分类环境变量可以简单的分成用户自定义的环境变量以及系统级别的环境变量。 用户级别环境变量定义文件：~/.bashrc、~/.profile（部分系统为：~/.bash_profile） 系统级别环境变量定义文件：/etc/bashrc、/etc/profile(部分系统为：/etc/bash_profile）、/etc/environment 另外在用户环境变量中，系统会首先读取~/.bash_profile文件，如果没有该文件则读取~/.bash_login，如果也没有该文件，则读取~/.profile，根据这些文件中内容再去读取~/.bashrc。 测试Linux环境变量加载顺序的方法为了测试各个不同文件的环境变量加载顺序，我们在每个环境变量定义文件中的第一行都定义相同的环境变量UU_ORDER，该变量的值为本身的值连接上当前文件名称。 需要修改的文件如下： /etc/environment /etc/profile /etc/profile.d/test.sh，新建文件，没有文件夹可略过 /etc/bashrc，或者/etc/bash.bashrc /.bash_profile，或者/.profile ~/.bashrc 在每个文件中的第一行都加上下面这句代码，并相应的把冒号后的内容修改为当前文件的绝对文件名。 1export UU_ORDER=&quot;$UU_ORDER:~/.bash_profile&quot; 修改完之后保存，新开一个窗口，然后echo $UU_ORDER观察变量的值： 12uusama@ubuntu:~$ echo $UU_ORDER$UU_ORDER:/etc/environment:/etc/profile:/etc/bash.bashrc:/etc/profile.d/test.sh:~/.profile:~/.bashrc 可以推测出Linux加载环境变量的顺序如下： /etc/environment /etc/profile /etc/bash.bashrc /etc/profile.d/test.sh ~/.profile ~/.bashrc Linux环境变量文件加载详解由上面的测试可容易得出Linux加载环境变量的顺序如下，： 系统环境变量 -&gt; 用户自定义环境变量/etc/environment -&gt; /etc/profile -&gt; ~/.profile 打开/etc/profile文件你会发现，该文件的代码中会加载/etc/bash.bashrc文件，然后检查/etc/profile.d/目录下的.sh文件并加载。 123456789101112131415161718192021222324252627# /etc/profile: system-wide .profile file for the Bourne shell (sh(1))# and Bourne compatible shells (bash(1), ksh(1), ash(1), ...).if [ &quot;$PS1&quot; ]; then if [ &quot;$BASH&quot; ] &amp;&amp; [ &quot;$BASH&quot; != &quot;/bin/sh&quot; ]; then # The file bash.bashrc already sets the default PS1. # PS1=&apos;\\h:\\w\\$ &apos; if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ &quot;`id -u`&quot; -eq 0 ]; then PS1=&apos;# &apos; else PS1=&apos;$ &apos; fi fifiif [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset ifi 其次再打开~/.profile文件，会发现该文件中加载了~/.bashrc文件。 12345678910# if running bashif [ -n &quot;$BASH_VERSION&quot; ]; then # include .bashrc if it exists if [ -f &quot;$HOME/.bashrc&quot; ]; then . &quot;$HOME/.bashrc&quot; fifi# set PATH so it includes user&apos;s private bin directoriesPATH=&quot;$HOME/bin:$HOME/.local/bin:$PATH&quot; 从~/.profile文件中代码不难发现，/.profile文件只在用户登录的时候读取一次，而/.bashrc会在每次运行Shell脚本的时候读取一次。 一些小技巧可以自定义一个环境变量文件，比如在某个项目下定义uusama.profile，在这个文件中使用export定义一系列变量，然后在~/.profile文件后面加上：sourc uusama.profile，这样你每次登陆都可以在Shell脚本中使用自己定义的一系列变量。 也可以使用alias命令定义一些命令的别名，比如alias rm=&quot;rm -i&quot;（双引号必须），并把这个代码加入到~/.profile中，这样你每次使用rm命令的时候，都相当于使用rm -i命令，非常方便。","categories":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/tags/linux/"},{"name":"环境变量","slug":"环境变量","permalink":"http://ppsteven.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"name":"转载","slug":"转载","permalink":"http://ppsteven.github.io/tags/%E8%BD%AC%E8%BD%BD/"}]},{"title":"linux crontab 入门","slug":"linux-crontab-basic","date":"2020-02-18T16:18:48.000Z","updated":"2020-02-22T13:56:47.084Z","comments":true,"path":"2020/02/19/linux-crontab-basic/","link":"","permalink":"http://ppsteven.github.io/2020/02/19/linux-crontab-basic/","excerpt":"crontab 的作用是，执行 linux 上的定时任务。当我们需要运行一些诸如 日志采集 、心跳检查 这种任务的时候，需要用到。 最近在做 linux 脚本检查 python 爬虫脚本 是否健康运行，故采用这个方法。 只要是常驻的程序，对于程序的要求比较高，必须有很好的稳健性，可以面对各种情况。 一个程序很难考虑到各种极端情况(死机，内存爆，网络问题等)，这时候我们必须要实时监控这些进程的方法。 这里我准备采用的方法一：日记采集+监控， 方法二：定期检查并唤起。日志采集的东西准备放在下一篇讲。 当安装完成操作系统之后，默认便会启动此任务调度命令。crond 命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作","text":"crontab 的作用是，执行 linux 上的定时任务。当我们需要运行一些诸如 日志采集 、心跳检查 这种任务的时候，需要用到。 最近在做 linux 脚本检查 python 爬虫脚本 是否健康运行，故采用这个方法。 只要是常驻的程序，对于程序的要求比较高，必须有很好的稳健性，可以面对各种情况。 一个程序很难考虑到各种极端情况(死机，内存爆，网络问题等)，这时候我们必须要实时监控这些进程的方法。 这里我准备采用的方法一：日记采集+监控， 方法二：定期检查并唤起。日志采集的东西准备放在下一篇讲。 当安装完成操作系统之后，默认便会启动此任务调度命令。crond 命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作 而 linux 任务调度的工作主要分为以下两类： 1、系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 2、个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 安装1yum install crontabs 对于 crontabs 服务的操作 123456systemctl status crond // systemctl 和 service 也是一样service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看服务是否启动 基础语法12345crontab [ -u user ] filecrontab [ -u user ] &#123; -l | -r | -e &#125; -l 列出目前用户的时程表-r 删除目前用户的时程表-e 编辑目前用户的时程表(默认采用VI) 等价于运行 vi /var/spool/cron/root [注:假如你是root用户(文件名与用户名一样)] 使用方法1f1 f2 f3 f4 f5 program 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,… 时表示第 a, b, c,… 分钟要执行，f2 为 a, b, c,… 时表示第 a, b, c…个小时要执行，其馀类推 12345678* * * * *- - - - -| | | | || | | | +----- 星期中星期几 (0 - 7) (星期天 为0)| | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31)| +-------------------- 小时 (0 - 23)+------------------------- 分钟 (0 - 59) 实例12345670 */2 * * * /sbin/service httpd restart 意思是每两个小时重启一次apache 50 7 * * * /sbin/service sshd start 意思是每天7：50开启ssh服务 50 22 * * * /sbin/service sshd stop 意思是每天22：50关闭ssh服务 0 0 1,15 * * fsck /home 每月1号和15号检查/home 磁盘 1 * * * * /home/bruce/backup 每小时的第一分执行 /home/bruce/backup这个文件 00 03 * * 1-5 find /home &quot;*.xxx&quot; -mtime +4 -exec rm &#123;&#125; \\; 每周一至周五3点钟，在目录/home中，查找文件名为*.xxx的文件，并删除4天前的文件。30 6 */10 * * ls 意思是每月的1、11、21、31日是的6：30执行一次ls命令 配置文件crontab 是系统任务调度的配置文件 1234# /etc/crontabSHELL=/bin/bash # 记录使用的 shell PATH=/sbin:/bin:/usr/sbin:/usr/bin # 记录 crontab 的环境变量MAILTO=root # 发送邮件的用户 常见问题如何查看日志执行日志 存储地址 /var/log/cron* 执行日志按天排列：cron 、cron-20171119 … 1tail -f /var/log/cron 运行日志 存储地址 /var/spool/mail/root mail/root 中的root 是文件名，与用户保持一致 发邮件的功能，我没有尝试成功 // TODO 如何查看/备份任务12345678# 编辑任务crontab -e # 实际上所有的配置都存放在 /var/spool/cron/*下，文件名与用户名一致/var/spool/conf/root :root 用户任务/var/spool/conf/mysql :mysql 用户任务# 备份任务crontab -l &gt; $HOME/mycrontabcp /var/spool/conf/root $HOME/YOURPLACE/root 注意事项crontab 有很多的注意实现，新手很容易翻车 建议不输出日志原因是任务运行太频繁，日志会累积的非常大，不留意会撑爆你的硬盘 1&gt; /dev/null 2&gt;&amp;1 环境变量问题crontab 的环境变量是一个大问题，crontab运行的时候不是以交互式的方式运行我们的程序，这样的话，我们常规的用来配置 linux 环境变量 的方法。如 .bashrc ，.bash_profile 等都不会起作用。 官方给的建议是，不要假定 cron 知道所需要的特殊环境，所以要保证 shell 脚本中提供所有必要的路径和环境变量。 脚本中涉及文件路径时写全局路径； 脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如: 123456cat start_cbp.sh#!/bin/sh# shell 脚本中写入所需引入的环境变量source /etc/profileexport RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf/usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 当手动执行脚本OK，但是crontab死活不执行时,很可能是环境变量惹的祸，可尝试在crontab中直接引入环境变量解决问题。如: 10 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 参考资料菜鸟教程：Linux crontab 命令 小a玖拾柒：Linux crontab命令详解","categories":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/tags/linux/"},{"name":"crontab","slug":"crontab","permalink":"http://ppsteven.github.io/tags/crontab/"},{"name":"运维","slug":"运维","permalink":"http://ppsteven.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"mysql error:Waiting for table metadata lock","slug":"mysql-bug-solution","date":"2020-02-11T15:57:07.000Z","updated":"2020-02-15T17:00:07.283Z","comments":true,"path":"2020/02/11/mysql-bug-solution/","link":"","permalink":"http://ppsteven.github.io/2020/02/11/mysql-bug-solution/","excerpt":"背景是，Navicat 在针对一张表格做删除操作的时候，会一直等待，无法进行任何操作。 经过 show PROCESSLIST 发现是 Waiting for table metadata lock 错误。","text":"背景是，Navicat 在针对一张表格做删除操作的时候，会一直等待，无法进行任何操作。 经过 show PROCESSLIST 发现是 Waiting for table metadata lock 错误。 删除 mysql 中表格遇到锁出现了Waiting for table metadata lock 的原因是，程序中对于数据库的一次操作并没有成功关闭，导致数据库上锁后，没有解锁。按照如下操作即可解决问题。 12345show PROCESSLIST; # 显示所有的操作select * from information_schema.innodb_trx # 查看未提交事务kill sid # 删除锁住的操作set session lock_wait_timeout = 1800; set global lock_wait_timeout = 1800;# 调整锁超时阈值 lock_wait_timeout 表示获取metadata lock的超时（单位为秒），允许的值范围为1到31536000（1年）。 默认值为31536000。 参考资料：MySQL出现Waiting for table metadata lock的原因以及解决方法 参考资料","categories":[{"name":"mysql","slug":"mysql","permalink":"http://ppsteven.github.io/categories/mysql/"}],"tags":[{"name":"mysql error","slug":"mysql-error","permalink":"http://ppsteven.github.io/tags/mysql-error/"}]},{"title":"Python装饰器：将装饰器定义为类","slug":"define-decorators-as-class","date":"2020-02-08T16:18:59.000Z","updated":"2020-02-15T17:53:24.593Z","comments":false,"path":"2020/02/09/define-decorators-as-class/","link":"","permalink":"http://ppsteven.github.io/2020/02/09/define-decorators-as-class/","excerpt":"最近在强化补齐 Python 的基础知识，向高阶玩家进发。主攻《Python CookBook 3rd》，上面的知识点比较多，我挑重点看这几个方面。 yield + 协程 装饰器 多线程 面向对象 本篇博客讨论的主题是 装饰器 ，装饰器其实也不是什么新鲜的用法，就是传入的参数是 函数 ，这一点上，它更像是一个语法糖。装饰器的作用是可以给我们原本编写好的函数再一次的加上额外的功能（比如统计时间，打日志）。 装饰器可以给我们的函数加上武器，使它们更加强大。如果是利用 Python 进行 Web 开发的小伙伴对装饰器并不陌生，在 Flask 和 Django 中 @ 符号应该不少见了","text":"最近在强化补齐 Python 的基础知识，向高阶玩家进发。主攻《Python CookBook 3rd》，上面的知识点比较多，我挑重点看这几个方面。 yield + 协程 装饰器 多线程 面向对象 本篇博客讨论的主题是 装饰器 ，装饰器其实也不是什么新鲜的用法，就是传入的参数是 函数 ，这一点上，它更像是一个语法糖。装饰器的作用是可以给我们原本编写好的函数再一次的加上额外的功能（比如统计时间，打日志）。 装饰器可以给我们的函数加上武器，使它们更加强大。如果是利用 Python 进行 Web 开发的小伙伴对装饰器并不陌生，在 Flask 和 Django 中 @ 符号应该不少见了 用类来实现装饰器Python 对某个对象是否能通过装饰器（@decorator）形式使用只有一个要求：decorator 必须是一个“可被调用（callable）的对象。类也可以通过实现 __call__ 方法，变得和函数一样可调用 123456789class Foo: def __call__(self): print('__call__ has been called')foo = Foo()# OUTPUT: __call__ has been calledfoo()# OUTPUT: Trueprint(callable(foo)) 这样的话，我们就可以直接开始用类来实现装饰器了 123456789101112131415161718class Profiled: def __init__(self, func): self.func = func self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1 return self.func(*args, **kwargs)@Profileddef add(x, y): return x + y# 3 add(1,2)# 7add(3,4)# OUTPUT:2 总共调用了2次装饰器print(add.ncalls) 问题一：装饰器无法装饰类内的方法这时候出现了第一个问题，当装饰器尝试装饰类内的方法的时候，我们常常会出现 参数输入不正确的提示 12345678class Spam: @Profiled def bar(self, x): print(self, x)s = Spam()# TypeError: bar() missing 1 required positional argument: 'x's.bar(1) 这个问题会让很多人感到困惑，明明我已经输入了参数x，赋值为1，但是却提示没有收到函数。我当时困惑了很久。终于发现了一个我们不容易注意到的细节：函数和方法的功能相似，当时实现方式不同。 我的理解是：与实例绑定的函数，叫做过程。不与实例绑定的叫做函数。这里的实例，在代码里面就是 self类内的方法，需要多传一个 self ，它本质上可以看做是一个指向实例的指针。 123456# 我们在 __call__ 里面多加一行，看看输出会是什么def __call__(self, *args, **kwargs): self.ncalls += 1+ print(self, *args, **kwargs) return self.func(*args, **kwargs)# &lt;__main__.Profiled object at 0x10faf1128&gt; 1 self 就是 &lt;__main__.Profiled object at 0x10faf1128&gt; ，而输入的参数是 1 。 Self 到低是一个什么玩意？ 为了探寻 self 的本质，我又多做了一个实验。发现 self ，Spam.bar ，s.bar 都是一个东西，相互替换的话，也是OK的，它就是类的一个实例。需要注意的是@Profiled 等价于 bar = Profiled(bar) ，所以这个实例也就是 Spam.bar 。 123456self&lt;__main__.Profiled object at 0x10aaf5470&gt;Spam.bar&lt;__main__.Profiled object at 0x10aaf5470&gt;s.bar&lt;__main__.Profiled object at 0x10aaf5470&gt; 下面的例子，可以帮助我们更好的理解 对象的方法 和 类的方法 1234567891011121314# 带 self 的意思是对象的方法，所以我们必须传入一个对象class Spam: def bar(self, x): print(self, x)# 正常用法，实例化对象，然后调用对象的方法# OUTPUT: &lt;__main__.Spam object at 0x10b3470b8&gt; 111s = Spam()s.bar(111)# 直接使用 Spam.bar 方法Spam.bar(123) # 错误用法，因为这里当做类的方法去使用了# OUTPUT: &lt;__main__.Spam object at 0x10b3470b8&gt; 123Spam.bar(Spam(),123) # 正确用法 更进一步，我们发现，定义类的方法的时候，类并不关心你传入的实例到底是什么，可以是 self ，也可以是任何类型的实例。 12345678# &lt;__main__.Spam object at 0x107bcc128&gt; 123Spam.bar(Spam(),123)# &lt;__main__.Spam object at 0x107bc2e80&gt; 123Spam.bar(s,123)# &lt;function Spam.bar at 0x107badea0&gt; 123Spam.bar(Spam.bar,123)# 任何类型的对象都可以 123Spam.bar(\"任何类型的对象都可以\",123) 解决方案回到正题，我们终于找到了原先错误的原因，就是漏掉了 self 。 1234567891011121314151617181920212223class Profiled: def __init__(self, func): self.func = func self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1- return self.func(*args, **kwargs)+ return self.func(self, *args, **kwargs)class Spam: @Profiled def bar(self, x): print(self, x)s = Spam()s.bar(1)s.bar(2)print(Spam.bar.ncalls)# OUTPUT&lt;__main__.Profiled object at 0x104168eb8&gt; 1&lt;__main__.Profiled object at 0x104168eb8&gt; 22 解决完这个问题，附带的我们对 self 的理解就加深了一层。 类方法 和 实例方法1234567891011121314class Spam: \"\"\"实例方法\"\"\" def bar(self, x): print(self, x)class Swam: \"\"\"类方法\"\"\" @classmethod def bar(cls, x): print(cls, x)# OUTPUT: &lt;__main__.Spam object at 0x1102080f0&gt; 1Spam().bar(1)# OUTPUT: &lt;class '__main__.Swam'&gt; 1Swam.bar(1) 问题二：如何兼顾类内类外的函数刚刚的问题一解决后，我们发现，对原来类外的函数又失效了，原因是它并没有 self 这个参数。为了解决这个问题，我们需要花一番功夫，其实简单来说，有实例的情况下，我们需要填充实例到 self 参数的位置。 这里我们借助 types.MethodTpye 和 __get__ 解决方法（完美版）12345678910111213141516171819202122232425262728293031323334import typesfrom functools import wrapsclass Profiled: def __init__(self, func): self.func = func self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1 return self.func(*args, **kwargs) def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance)@Profileddef add(x, y): return x + yclass Spam: @Profiled def bar(self, x): print(self, x)add(1,2)add(3,4)print(add.ncalls)s = Spam()s.bar(1)s.bar(2)print(Spam.bar.ncalls) __get__ 是怎么使用当一个类中实现了任意的 __get__()、__set__() 和__delete__() 三个特殊的方法后， 这个类就是一个描述器类。当这个描述器在另一个类中被调用的时候，就会调用以上的三个方法。 123456789101112131415161718# 定义一个描述器类class Integer: def __init__(self, name): self.name = name def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] def __set__(self, instance, value): if not isinstance(value, int): raise TypeError('Expected an int') instance.__dict__[self.name] = value def __delete__(self, instance): del instance.__dict__[self.name] 为了使用一个描述器，这个类必须作为另外一个类的属性 1234567891011121314151617# x, y 都是 Point 的描述器属性# 需要注意的是: x, y 是类的属性，需要在方法前定义class Point: x = Integer('x') y = Integer('y') def __init__(self, x, y): self.x = x self.y = y# 下面的定义是错误的class Point: def __init__(self, x, y): self.x = Integer('x') # No! Must be a class variable self.y = Integer('y') self.x = x self.y = y 使用方法如下 1234&gt;&gt;&gt; p = Point(2, 3)&gt;&gt;&gt; p.x # Calls Point.x.__get__(p,Point)2&gt;&gt;&gt; p.y = 5 # Calls Point.y.__set__(p, 5) 我们会发现 __get__ 方法实现起来比较复杂 12345def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] self, instance, cls 分别代表什么意思？self 是 Integer 类的实例，这里 x、y 都可以看做是self。instance 是 Point 类的实例，也就是 p。cls（也可以写成 owner）是类本身，这里就是 Point 类。 如果一个描述器被当做一个类变量来访问，那么 instance 参数被设置成 None 。 这种情况下，标准做法就是简单的返回这个描述器本身即可(尽管你还可以添加其他的自定义操作)。 1234&gt;&gt;&gt; p.x # Calls Point.x.__get__(p, Point)2&gt;&gt;&gt; Point.x # Calls Point.x.__get__(None, Point)&lt;__main__.Integer object at 0x100671890&gt; types.MethodType 详解Python 是动态的编程语言，可以在执行的过程中，给类动态的添加方法。 下面举一个经典用法 123456789import types def fn_get_name(self): return self.nameclass Person(object): def __init__(self, name, score): self.name = name self.score = score 添加函数到 Person 类的方法上。 12345678&gt;&gt;&gt; p1 = Person('Bob', 90) &gt;&gt;&gt; p1.get_name = types.MethodType(fn_get_name, p1) &gt;&gt;&gt; print p1.get_name() Bob&gt;&gt;&gt; p2 = Person('Alice', 65) &gt;&gt;&gt; print p2.get_name() # ERROR: AttributeError: 'Person' object has no attribute 'get_name' # 因p2实例没有绑定get_name方法，所以出现错误。 下面我们深入理解一下 p1.get_name = types.MethodType(fn_get_name, p1)types.MethodType 接受两个参数（好像Python2 是3 个参数？） 第一个参数：绑定的函数 第二个参数：需要绑定的实例 孤立的看两个参数和实现的结果并不能很好的理解其中的原理，实际上，所谓的绑定的实质上是：第二个实例是作为参数，传入到绑定函数(现在是类的过程)的 self 中去。 如果理解了这一句话，那么应该不难理解下面的程序。明明是 p1 调用自己的方法，最后输出的是 p2 的结果 12345p1 = Person('Bob', 90) p2 = Person('Tom', 0)p1.get_name = types.MethodType(fn_get_name, p2) print (p1.get_name())# OUTPUT: Tom 原因是我们的类最终是变成了下面的样子 12345678910111213141516import types def fn_get_name(self): return self.nameclass Person(object): def __init__(self, name, score): self.name = name self.score = score def get_name(self): self = p2 return self.namep1 = Person('Bob', 90) p2 = Person('Tom', 0)print (p1.get_name())# OUTPUT: TOM 回顾有了上面的各种铺垫后，我们再一次的回顾 __get__, __call__ 两个方法，就瞬间了然。 1234567891011def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance) # 该实例会作为参数传入 self 中def __call__(self, *args, **kwargs): # 当实例发生调用的时候，__call__(self, self, 1) # args = (self, 1) self.ncalls += 1 return self.func(*args, **kwargs) # self.func(self, 1) 利用 wrapper 再次包装一下wrapper 的作用非常简单，就是让复制被包装函数的元信息。下面的代码就是 Python Cookbook 给出的答案。 12345678910111213141516171819import typesfrom functools import wrapsclass Profiled: def __init__(self, func):- self.func = func+ wraps(func)(self) self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1- return self.func(*args, **kwargs)+ return self.__wrapped__(*args, **kwargs) def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance) 小结花了相当长的一个篇幅去讨论 Python Cookbook 的一个章节，虽然有点小题大做。不过也是把很多不懂的地方理清楚了。特别是对于 函数和方法 的认识更深一步了。 后续会利用装饰器去做一个应用，计划是做一个 requests 包的一个封装，使得 request 请求的时候自动加上代理，把它封装成一个 Util 工具。 参考资料Python 工匠：使用装饰器的技巧 python中函数和方法区别，以及如何给python类动态绑定方法和属性（涉及types.MethodType()和slots） Python Cookbook 8.9 创建新的类或实例属性 Python Cookbook 9.9 将装饰器定义为类","categories":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/categories/python/"}],"tags":[{"name":"python高级","slug":"python高级","permalink":"http://ppsteven.github.io/tags/python%E9%AB%98%E7%BA%A7/"}]},{"title":"如何在python项目中使用import导入自编模块","slug":"how-to-import-module-in-python-project","date":"2020-01-26T09:06:02.000Z","updated":"2020-02-15T17:54:37.443Z","comments":false,"path":"2020/01/26/how-to-import-module-in-python-project/","link":"","permalink":"http://ppsteven.github.io/2020/01/26/how-to-import-module-in-python-project/","excerpt":"背景是在python项目中导入模块时碰到的问题，当需要导入的模块是位于项目的不同层级的时候，导入文件就变成了一个非常麻烦的事情。 下面举一个例子 123456789. # 当前工作目录├── DB │ ├── MySQLClient.py│ └── RedisClient.py└── Util│ └── LogHandler.py├── Email│ └── SendEmail.py # 本文件│ └── Email_setting.py # 待导入文件 DB 和 Util 是我们经常使用到的模块，若是我们的工作目录位于项目文件的第一层的话，当我们导入 Email_setting.py 的时候，我们应该是 1234from DB.MySQLClient import MySQLClassfrom Util.LogHandler import LogHandlerfrom Email_setting import * # 这是错误的例子from Email.Email_setting import * 下面我们讨论一下如何在python中导入模块 参考自: Python 101: All about imports","text":"背景是在python项目中导入模块时碰到的问题，当需要导入的模块是位于项目的不同层级的时候，导入文件就变成了一个非常麻烦的事情。 下面举一个例子 123456789. # 当前工作目录├── DB │ ├── MySQLClient.py│ └── RedisClient.py└── Util│ └── LogHandler.py├── Email│ └── SendEmail.py # 本文件│ └── Email_setting.py # 待导入文件 DB 和 Util 是我们经常使用到的模块，若是我们的工作目录位于项目文件的第一层的话，当我们导入 Email_setting.py 的时候，我们应该是 1234from DB.MySQLClient import MySQLClassfrom Util.LogHandler import LogHandlerfrom Email_setting import * # 这是错误的例子from Email.Email_setting import * 下面我们讨论一下如何在python中导入模块 参考自: Python 101: All about imports 导入 Python 模块的各种姿势 Regular imports Using from Relative imports Optional imports Local imports import Pitfalls 常规导入我们最常见的导入方式是 import module ，我们一般用来导入 官方库 和 第三方库 。 123import math # 官方库from bs4 import Beautfiul # 第三方库import pandas as pd 以上两个来源的库用起来比较省心，因为它们的目录已经加入了环境变量中了 1234# 查看环境变量的方式&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path['', '/Users/ppsteven/anaconda3/lib/python37.zip', '/Users/ppsteven/anaconda3/lib/python3.7', '/Users/ppsteven/anaconda3/lib/python3.7/lib-dynload', '/Users/ppsteven/anaconda3/lib/python3.7/site-packages', '/Users/ppsteven/anaconda3/lib/python3.7/site-packages/aeosa', '/Users/ppsteven/anaconda3/lib/python3.7/site-packages/xgboost-1.0.0_SNAPSHOT-py3.7.egg'] 从模块导入12from functools import lru_cachelru_cache(*args) 同样，你也可以导入该模块中的所有函数和变量，只是这种导入方式是不被推荐的 1from os import * 官方建议我们，需要对 import 的函数，要显式的写出，但是当函数过多的时候，我们可能写成多行的形式 12from os import path, walk, unlinkfrom os import uname, remove 为了能用一个 import 实现，我们可以利用 括号 帮助，或者 \\ 1234from os import (path, walk, unlink, uname, remove, rename)from os import path, walk, unlink, uname, \\ remove, rename 相对导入当使用的是绝对路径时，容易出现的问题是，在大型的项目中，当你改变包结构的时候，你需要对你的代码进行大幅度的修改。 另外，如果没有相对路径，那么包内的模块无法轻松导入自身。 一些例子12from .foo import barfrom ...foo import bar 这两种形式有两种不同的建议语义。一种语义是使每个点代表一个级别。但是数需要多少个点也是一件麻烦事。 另一种选择是只允许一个相对导入级别，这样的话又会制约模块的功能。 最后的选择是定义一种算法，用于查找相关的模块和软件包。 这里的反对意见是“明确胜于隐含”。 （建议的算法是“从当前程序包目录中搜索，直到最终的父程序包被命中为止。”） 只导入兄弟模块一种建议是，只导入 兄弟 模块。换言之，对于更高层级的模块，使用绝对路径 12from .spam import eggsimport .spam.eggs 使用索引父节点12from -2.spam import eggs # 高层级from .spam import eggs # 本地 把代码组织成很多分层模块的包使用一个 leading dot 作为相对路径，两个或以上代表父目录。 这里我们把整个项目作为一个包来看待，需要对每一层写一个 __init__.py 文件这里，我们整个项目可以看成 package 包，和 subpackage1 和 subpackage2 两个子包。 实现的方法很简单，就是确保在每一层目录上添加一个 __init__.py 文件 下面是我们的目录结构 12345678910package/ __init__.py subpackage1/ __init__.py moduleX.py # 当前文件 moduleY.py subpackage2/ __init__.py # 当前文件 moduleZ.py moduleA.py 假设 moduleX.py 和 __init__.py 是我们的当前文件，那么正确的导入的做法是 12345678from .moduleY import spamfrom .moduleY import spam as hamfrom . import moduleYfrom ..subpackage1 import moduleYfrom ..subpackage2.moduleZ import eggsfrom ..moduleA import foofrom ...package import barfrom ...sys import path 相对路径必须使用 from &lt;&gt; import 绝对路径使用 import &lt;&gt; 12345678910111213141516# my_package/__init__.pyfrom . import subpackage1from . import subpackage2# my_package/subpackage1/__init__.pyfrom . import module_xfrom . import module_y# my_package/subpackage1/module_x.pyfrom .module_y import spam as ham def main(): ham()# my_package/subpackage1/module_y.pydef spam(): print('spam ' * 3) 我们切换到 my_package 上一层的目录，运行下面代码是正常的。 1234567In [1]: import my_package In [2]: my_package.subpackage1.module_xOut[2]: &lt;module 'my_package.subpackage1.module_x' from 'my_package/subpackage1/module_x.py'&gt; In [3]: my_package.subpackage1.module_x.main()spam spam spam 可选导入可选导入用的情况比较少，一般是用在需要导入一个模块，但是这个模块并不一定存在的情况。比如我们使用的python 版本不一致的时候，需要导入的模块也会有所不同，这样的写法能加强模块的健壮性= github2下面是一段来自 github2 的例子 123456789try: # For Python 3 from http.client import responsesexcept ImportError: # For Python 2.5-2.7 try: from httplib import responses # NOQA except ImportError: # For Python 2.4 from BaseHTTPServer import BaseHTTPRequestHandler as _BHRH responses = dict([(k, v[0]) for k, v in _BHRH.responses.items()]) lxml下面是一段来自 lxml package 的例子 1234567try: from urlparse import urljoin from urllib2 import urlopenexcept ImportError: # Python 3 from urllib.parse import urljoin from urllib.request import urlopen 本地导入导入的模块分为 local scope 和 global scope 空间。当你在 python script 的头部导入的时候，作用在全局域。当在函数中导入的时候是本地域。 1234567891011121314import sys # global scope def square_root(a): # This import is into the square_root functions local scope import math return math.sqrt(a) def my_pow(base_num, power): # 这里直接使用 math 会报错的 return math.pow(base_num, power) if __name__ == '__main__': print(square_root(49)) print(my_pow(2, 3)) 导入的注意事项容易犯错误的主要有两点 循环导入 Shadowed imports 循环导入简言之，就是模块相互导入 12345678# a.pyimport b def a_test(): print(\"in a_test\") b.b_test() a_test() 我们在相同的文件夹下，创建一个文件 b.py 1234567import a def b_test(): print('In test_b\"') a.a_test() b_test() 如果是你运行这些模块的话，你将会获得 AttributeError 报错。虽然有一些旁门左道的变通方法可以解决，但是还是建议重构代码。 覆盖导入(Shadowed imports)覆盖导入是指导入一个和官方库起名一样的模块，会报错。 主要的原因是，python 会首先搜索本地文件夹下的模块，其次是搜索其他路径。 123456import math def square_root(number): return math.sqrt(number) square_root(72) 参考资料Python 101: All about imports","categories":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/tags/python/"},{"name":"import","slug":"import","permalink":"http://ppsteven.github.io/tags/import/"}]},{"title":"Python编码规范","slug":"python编码规范","date":"2020-01-12T09:37:56.000Z","updated":"2020-01-28T12:03:49.314Z","comments":false,"path":"2020/01/12/python编码规范/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/python%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/","excerpt":"Python编码规范 Python 编码规范(Google Python Style Guide 目前写了: 函数、模块、变量等命名 函数注释 字符串编码规范 TODO 模块的导入规范，项目的结构","text":"Python编码规范 Python 编码规范(Google Python Style Guide 目前写了: 函数、模块、变量等命名 函数注释 字符串编码规范 TODO 模块的导入规范，项目的结构 命名module_name, package_name, ClassName, method_name, ExceptionName, function_name, GLOBAL_VAR_NAME, instance_var_name, function_parameter_name, local_var_name. 应该避免的名称 单字符名称, 除了计数器和迭代器. 包/模块名中的连字符(-) 双下划线开头并结尾的名称(Python保留, 例如init) 命名约定 所谓”内部(Internal)”表示仅模块内可用, 或者, 在类内是保护或私有的. 用单下划线(_)开头表示模块变量或函数是protected的(使用import * from时不会包含). 用双下划线(__)开头的实例变量或方法表示类内私有. 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块. 对类名使用大写字母开头的单词(如CapWords, 即Pascal风格), 但是模块名应该用小写加下划线的方式(如lower_with_under.py). 尽管已经有很多现存的模块使用类似于CapWords.py这样的命名, 但现在已经不鼓励这样做, 因为如果模块名碰巧和类名一致, 这会让人困扰. Python之父Guido推荐的规范 Type Public Internal Modules lower_with_under _lower_with_under Packages lower_with_under Classes CapWords _CapWords Exceptions CapWords Functions lower_with_under() _lower_with_under() Global/Class Constants CAPS_WITH_UNDER _CAPS_WITH_UNDER Global/Class Variables lower_with_under _lower_with_under Instance Variables lower_with_under _lower_with_under (protected) or __lower_with_under (private) Method Names lower_with_under() _lower_with_under() (protected) or __lower_with_under() (private) Function/Method Parameters lower_with_under Local Variables lower_with_under 注意 模块尽量使用小写命名，首字母保持小写，尽量不要用下划线 类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头 函数名一律小写，如有多个单词，用下划线隔开 私有函数可用一个下划线开头 变量名尽量小写, 如有多个单词，用下划线隔开 常量采用全大写，如有多个单词，使用下划线隔开 函数注释reST 参考：python代码规范以及函数注释规范 12345678\"\"\"This is a reST style. :param param1: this is a first param:param param2: this is a second param:returns: this is a description of what is returned:raises keyError: raises an exception\"\"\" 下面的一个例子，来自：这里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546def pinyin(hans, style=Style.TONE, heteronym=False, errors='default', strict=True): \"\"\"将汉字转换为拼音. :param hans: 汉字字符串( ``'你好吗'`` )或列表( ``['你好', '吗']`` ). 可以使用自己喜爱的分词模块对字符串进行分词处理, 只需将经过分词处理的字符串列表传进来就可以了。 :type hans: unicode 字符串或字符串列表 :param style: 指定拼音风格，默认是 :py:attr:`~pypinyin.Style.TONE` 风格。 更多拼音风格详见 :class:`~pypinyin.Style` :param errors: 指定如何处理没有拼音的字符 * ``'default'``: 保留原始字符 * ``'ignore'``: 忽略该字符 * ``'replace'``: 替换为去掉 ``\\\\u`` 的 unicode 编码字符串 (``'\\\\u90aa'`` =&gt; ``'90aa'``) * callable 对象: 回调函数之类的可调用对象。如果 ``errors`` 参数 的值是个可调用对象，那么程序会回调这个函数: ``func(char)``:: def foobar(char): return 'a' pinyin('あ', errors=foobar) :param heteronym: 是否启用多音字 :param strict: 是否严格遵照《汉语拼音方案》来处理声母和韵母，详见 :ref:`strict` :return: 拼音列表 :rtype: list Usage:: &gt;&gt;&gt; from pypinyin import pinyin, Style &gt;&gt;&gt; import pypinyin &gt;&gt;&gt; pinyin('中心') [['zhōng'], ['xīn']] &gt;&gt;&gt; pinyin('中心', heteronym=True) # 启用多音字模式 [['zhōng', 'zhòng'], ['xīn']] &gt;&gt;&gt; pinyin('中心', style=Style.FIRST_LETTER) # 设置拼音风格 [['z'], ['x']] &gt;&gt;&gt; pinyin('中心', style=Style.TONE2) [['zho1ng'], ['xi1n']] &gt;&gt;&gt; pinyin('中心', style=Style.CYRILLIC) [['чжун1'], ['синь1']] \"\"\" # 对字符串进行分词处理 if isinstance(hans, text_type): Py文件头文件12345678910111213# -*- encoding:utf-8 -*-\"\"\"------------------------------------------------- File Name： $&#123;NAME&#125; Description : Author : $&#123;USER&#125; date： $&#123;DATE&#125; $&#123;HOUR&#125;:$&#123;MINUTE&#125;------------------------------------------------- Change Activity: $&#123;DATE&#125;: -------------------------------------------------\"\"\"# 上面的代码加入 PyCharm 中","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/tags/python/"}]},{"title":"Centos 环境配置（持续总结）","slug":"centos-install-introduction","date":"2020-01-12T08:35:50.000Z","updated":"2020-02-23T09:32:17.584Z","comments":false,"path":"2020/01/12/centos-install-introduction/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/centos-install-introduction/","excerpt":"本章节收集一下配置一个centos 环境所需要的操作 第一部分：必要软件的安装 git wget MiniConda(python) mysql 第二部分：Docker 服务 web-vscode phpredisAdmin(redis web 管理工具)","text":"本章节收集一下配置一个centos 环境所需要的操作 第一部分：必要软件的安装 git wget MiniConda(python) mysql 第二部分：Docker 服务 web-vscode phpredisAdmin(redis web 管理工具) 基础配置显示完整文件路径123456命令行提示符完全显示完整的工作目录名称:（推荐用法）export PS1='[\\u@\\h $PWD]$ '命令行提示符只列出最后一个目录：export PS1='[\\u@\\h \\W]$'命令行提示符显示完整工作目录，当前用户目录会以 ~代替：export PS1='[\\u@\\h \\w]$' 命令释义 123456\\u 显示当前用户账号\\h 显示当前主机名\\W 只显示当前路径最后一个目录\\w 显示当前绝对路径（当前用户目录会以 ~代替）$PWD 显示当前全路径\\$ 显示命令行’$&apos;或者’#&apos;符号 参考资料：linux下显示完整路径，linux下显示绝对路径 必要软件安装git1$ yum install -y git wget1$ yum install -y wget MiniConda网址https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/ 下载最新的版本，一般来说是 Miniconda-latest-Linux 12345678$ wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda-latest-Linux-x86_64.sh$ bash Miniconda-latest-Linux-x86_64.sh# 添加环境变量$ echo \"export PATH=/root/miniconda2/bin:$PATH\" &gt;&gt; .bashrc$ source ~/.bashrc# 检查是否成功安装$ /root/miniconda2/bin/conda -Vconda 4.0.5 配置 Anaconda 仓库镜像源123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes 设置快捷命令12345alias conl=\"conda env list\"alias conc=\"conda create -n\"alias cona=\"source activate\"alias cond=\"source deactivate\"alias conr=\"conda remove --all -n\" 新建 python 环境123456789101112# 创建新环境 base 并安装python3.6$ conda create -n base python=3.6# 查看当前环境$ conl# conda environments:#base /root/miniconda2/envs/baseroot * /root/miniconda2# 切换为 base 环境$ cona base$ which python /root/miniconda2/envs/base/bin/python # 当前python的地址 安装必要的库 12$ pip install --upgrade pip$ pip install numpy pandas jsonpath pymysql requests datetime dateutil 参考来源：Centos7安装Miniconda及配置jupyter mysqlMariaDB 是由 MySQL 开发的 MySQL的替代版本。如果我们直接在 Centos 上 yum install mysql 第零步：查看系统版本号12$ cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 第一步：安装MySQL需要到如下网站上去定位需要安装的版本号 https://dev.mysql.com/downloads/repo/yum/ 注意：我们使用的CentOs Linux 7 选择下面的第二个 不用试图去点击右手边的 Download 按钮，因为这个会导向一个登陆界面。获取版本号后，直接用 wget 下载 12345678910$ wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm# 下载完了以后，还是可以检查一下是否正常下载$ md5sum mysql80-community-release-fc30-1.noarch.rpm$ rpm -ivh mysql80-community-release-fc30-1.noarch.rpm警告：mysql80-community-release-fc30-1.noarch.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mysql80-community-release-fc30-1 ################################# [100%] 若是安装错误 repo 源了怎么办？我很不幸就干过 12345# 查看所有 mysql 源$ rpm -qa|grep mysql# 删掉安装错误的 mysql 源$ rpm -e mysql80-community-release-fc30-1.noarch --nodeps 安装 MySQL 1$ sudo yum install mysql-server 第二步：启动 mysql 服务1sudo systemctl start mysqld 该命令不会返回报错，为了进一步确认 mysql 服务确实启动 123456789101112$ sudo systemctl status mysqldLoaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2020-01-28 20:07:00 CST; 6s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 12281 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 12402 (mysqld) Status: \"Server is operational\" Tasks: 39 Memory: 616.5M CGroup: /system.slice/mysqld.service └─12402 /usr/sbin/mysqld 第三步：修改默认配置首先，我们需要修改 MySQL 给我们的默认密码，这个直接从日志中获取即可 12cat /var/log/mysqld.log | grep \"temporary password\"2020-01-28T12:06:55.699956Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 5H(?khVdysDW 初始密码只能用于登录，但是此时你不能进行任何操作，必须修改新的密码 在修改密码之前，你需要做的是修改密码的规格（默认的规格···太严格了） 12345# validate_password_policy代表密码策略，默认是1：符合长度，且必须含有数字，小写或大写字母，特殊字符。设置为0判断密码的标准就基于密码的长度了。一定要先修改两个参数再修改密码set global validate_password.policy=0;# validate_password_length代表密码长度，最小值为4set global validate_password.length=4; 最后，修改为合适的密码 1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new password&apos;; 如果我们安装的是 MySQL8.0 以上的版本，加密规则是mysql_native_password,而在mysql8之后,加密规则是caching_sha2_password。为了解决兼容性问题，一般来说，我选择把加密等级调低一点。 1mysql&gt; select host,user,plugin,authentication_string from mysql.user; 最后需要修改一下，加密规则 和 远程登录 12345USE mysql;UPDATE user SET host = &apos;%&apos; where user = &apos;root&apos;;ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;password&apos;;FLUSH PRIVILEGES; 参考资料:CentOS7 安装并配置MySQL8.0How To Install MySQL on CentOS 7 dockerdocker 安装其实比较麻烦的，感谢 图灵:Docker开发指南 给的安装建议，我们可以直接用别人写好的脚本。 123456curl https://get.docker.com &gt; install.shchmod +x install.shcat install.sh # 感兴趣的话，可以研究一下 shell 究竟写了啥./install.sh # 安装完了，记得启动 docker 服务sudo systemctl start docker linux下 docker 加速123456789101112131415$ sudo touch /etc/docker/daemon.json # 添加国内站点&#123; \"registry-mirrors\": [\"https://registry.docker-cn.com\",\"http://hub-mirror.c.163.com\",\"https://mirror.ccs.tencentyun.com\",\"https://dockerhub.azk8s.cn\"]&#125;# 重启docker daemon$ sudo systemctl restart docker # 查看是否有修改成功$ docker info # 查看Register Mirrors的信息Registry Mirrors: https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ docker-compose(github 安装) 有条件的话，参考 docker官方教程这一种方法是官方推荐，但是鉴于中国墙，速度有可能非常感人 1. 从 github 上下载 docker-compose 命令1sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.3/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 2. 赋予可执行权限1sudo chmod +x /usr/local/bin/docker-compose 3. 验证是否安装成功1docker-compose --version docker-compose(pip 安装) 一般容易出问题的是 pip 的版本，如果是使用了conda作为包管理的话，可能主要注意pip的版本。我一开始是使用base环境的pip作下载，然后将安装的docker-compose 软连接至 /usr/local/bin 中 1pip install docker-compose Selenium + Chrome 环境配置linux 是无图形化界面，selenium 需要借助图形化的工具，下面我们直接看如何配置。 参考教程：centos7安装selenium 安装selenium1pip install selenium 安装chrome-browser12345wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm --no-check-certificateyum install ./google-chrome-stable_current_x86_64.rpm# 安装后，注意要查看一下 chrome 的版本号$ google-chrome --versionGoogle Chrome 80.0.3987.87 下载chromedriver 建议到 淘宝镜像下载 12345$ wget https://npm.taobao.org/mirrors/chromedriver/80.0.3987.16/chromedriver_linux64.zip# 解压此文件，并将文件移动到/usr/bin目录下unzip chromedriver_linx64.zip# 移到 /usr/bin 下后，之后运行的时候就不必特意制定 chromedriver 路径了mv chromedriver /usr/bin/ 使用selenium12345678from selenium import webdriverurl='http://bing.com'option = webdriver.ChromeOptions()option.add_argument('--no-sandbox')option.add_argument('--headless')driver = webdriver.Chrome(chrome_options=option)driver.get(url)print(driver.page_source) Docker 服务用 docker 安装需要用到的服务实在是太方便了，我们下面介绍一些好的轮子来用。 web-vscode 安装 传送门: code-server 1234567891011121314151617181920212223242526#创建docker rm -f vscode docker run \\# 后台运行-d \\ # 总是运行--restart=always \\ # Alias--name web_vscode \\ # hostname-h vscode \\ # 一定要以root账号运行,不然会报 Permission denied-u root \\ # 所有端口映射，而不要是127.0.0.1-p 8086:8080 \\ -v \"$&#123;HOME&#125;/.local/share/code-server:/home/coder/.local/share/code-server\" \\ # 密码是通过环境变量加入的-e PASSWORD=mycode \\ # $PWD 是当前希望项目放置的位置-v \"$PWD:/home/coder/project\" \\# 镜像名，本地不存在的话，会从仓库拉取codercom/code-server:v2 #查看docker ps -ldocker logs web_vscode 运行成功后 12345info Server listening on http://0.0.0.0:8080info - Password is 558ba38067432e3beddf1228info - To use your own password, set the PASSWORD environment variableinfo - To disable use `--auth none`info - Not serving HTTPS 由于我们的 web-vscode 是运行在容器内的，所以很多环境我们需要自己配置，参考上述操作。 redis web 管理工具mac 上 redis 管理工具破解版不好找，但是在 github 上找到了一个开源的工具，非常方便。拿来用一下 传送门: phpRedisAdmin 1234docker pull erikdubbelboer/phpredisadmindocker run --rm -itd -e REDIS_1_HOST=redis -e REDIS_1_NAME=myredis -p 8015:80 --link redis-test:redis --name redisadmin erikdubbelboer/phpredisadmin# 需要注意的是 REDIS_1_HOST 填写的是自己 redis 服务器的地址# 这里我采用的是容器链接的方式 因为服务器地址是会变的，所以我这里就直接写一个 docker-compose.yml 作为启动的脚本 12345678910# phpredisadmin.ymlphpredisadmin: image: erikdubbelboer/phpredisadmin environment: - ADMIN_USER=admin - ADMIN_PASS=admin - REDIS_1_HOST=127.0.0.1/172.17.0.1 - REDIS_1_PORT=6379 ports: - \"8011:80\" 每次使用直接 12docker-compose -f phpredisadmin up -d # 启动(以后台方式)docker-compose down # 关闭","categories":[{"name":"centos","slug":"centos","permalink":"http://ppsteven.github.io/categories/centos/"}],"tags":[{"name":"centos","slug":"centos","permalink":"http://ppsteven.github.io/tags/centos/"}]},{"title":"git 实战（持续更新）","slug":"git-skill-in-learning","date":"2020-01-12T08:35:50.000Z","updated":"2020-02-19T09:12:22.397Z","comments":false,"path":"2020/01/12/git-skill-in-learning/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/git-skill-in-learning/","excerpt":"主要记录 git 在实际使用中碰到的问题，会逐步慢慢积累 问题一：新项目如何与远端同步？12345$ git init$ git remote add origin git@e.coding.net:datamate/pujiangjiaoye.git # 添加远端仓库$ git branch --set-upstream-to=origin/master # 设置分支对应关系$ git push --set-upstream origin master # 设置push 对应的远程仓库，建立本地分支的上游$ git remote -v # 查看分支 当我们尝试push的时候又会出现一个问题","text":"主要记录 git 在实际使用中碰到的问题，会逐步慢慢积累 问题一：新项目如何与远端同步？12345$ git init$ git remote add origin git@e.coding.net:datamate/pujiangjiaoye.git # 添加远端仓库$ git branch --set-upstream-to=origin/master # 设置分支对应关系$ git push --set-upstream origin master # 设置push 对应的远程仓库，建立本地分支的上游$ git remote -v # 查看分支 当我们尝试push的时候又会出现一个问题 12345678error: 推送一些引用到 'git@e.coding.net:datamate/pujiangjiaoye.git' 失败提示：更新被拒绝，因为您当前分支的最新提交落后于其对应的远程分支。提示：再次推送前，先与远程变更合并（如 'git pull ...'）。详见提示：'git push --help' 中的 'Note about fast-forwards' 小节。# 按照提示，尝试用git pull 合并,又失败$ git pullfatal: 拒绝合并无关的历史 原因是我们本地与远程的版本不一致，但是我们是新提交，怎么会出现这样的问题呢？因为很多平台在我们创建项目的时候，自动帮我们创建了README.md文件，所以会有不一致的情况存在。git pull 失败的原因是，两个不一致的文件没有共同祖先的历史。 解决方法也很简单 1git pull origin master --allow-unrelated-histories 问题二：如何修改上一次的提交？git 是分支管理的工具，我们的工作最好在一个 commit 中提交相应的代码，完成一个功能（如 bugfix 或者 feature_add ）。但是有的时候，我们的提交经过 Code Review 之后，可能会被打回来。这样面对新的修改，不应该重复提交。 首先，我们可以先建立一个提交。面对第二个文件（这里我们给 a 新增了 Hello world again ） 第一种选择，我们提交两个 commit 12git add .git commit -m \"second commit\" 第二种选择，我们直接修改上一次的修改（推荐） 工作流如下 123git add .git commit --amend # 代表直接在上一次的提交修改，这里会弹出上一次 commit 的信息。git push -f # 由于我们只是改了本地，提交的时候使用 -f 强制推送一下 这里强烈建议，使用 –amend 的方法的时候，一定要检查 commit 的信息，确定不是把别人的给冲掉了。 问题三：服务器端强制同步远端 git 仓库？1234git fetch git reset --hard origin/master # 要强制同步的分支！--hard 是丢弃分支的修改git pullAlready up-to-date. 问题四：为什么修改了 .gitignore 文件，忽略项还是不起作用新建的文件在git中会有缓存，如果某些文件已经被纳入了版本管理中，就算是在.gitignore中已经声明了忽略路径也是不起作用的，这时候我们就应该先把本地缓存删除，然后再进行git的push git清除本地缓存命令如下： 12git rm -r --cached .git add . 下面附上我的 .gitignore 文件 12345678910111213141516171819# Windows:Thumbs.dbehthumbs.dbDesktop.ini# MAC:*.DS_Store# Python:*.py[cod]*.so*.egg*.egg-infodistbuild# My configurations:*.log*.log.* 如何使用 git merge 123456789101112131415# 开发分支（dev）上的代码达到上线的标准后，要合并到 master 分支git checkout devgit pullgit checkout mastergit pull git merge devgit push -u origin master# 当master代码改动了，需要更新开发分支（dev）上的代码git checkout master git pull git checkout dev # 这里默认dev 远端没有动git merge master git push -u origin dev 参考: git merge最简洁用法 推荐一个 git merge 比较好的教程： merge：合并 commits","categories":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"}]},{"title":"如何配置多个git账号","slug":"how-to-manage-multipul-git","date":"2020-01-12T07:02:00.000Z","updated":"2020-02-22T13:20:09.591Z","comments":false,"path":"2020/01/12/how-to-manage-multipul-git/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/how-to-manage-multipul-git/","excerpt":"随着学习和工作的深入，不可避免的会在电脑上有多个 git 账号，那么我们碰到的一个棘手的问题是如何管理我们的 git 账号。 本篇教程就是讲述如何处理这一类问题。","text":"随着学习和工作的深入，不可避免的会在电脑上有多个 git 账号，那么我们碰到的一个棘手的问题是如何管理我们的 git 账号。 本篇教程就是讲述如何处理这一类问题。 介绍Git共有三个级别的 config 文件，分别是 system 、global 和 local。global 的在$home\\.gitconfig，local的在仓库目录下的.git\\config。这三个级别都分别配置了用户信息，当git commit时，会依次从local、global、system里读取用户信息。因此，我们利用local的配置来设置不同的用户信息 生成公钥12345678910111213141516# 查看git账号，会按顺序读取local,global的用户信息git config user.namegit config user.email# 若是在空仓库中使用如下命令会出错，我们在仓库中使用--local，提前运行git initgit config --local -lfatal: --local 只能在一个仓库内使用# 更改本地账号git config --local/--global user.name \"Your name\"git config --local/--global user.email \"Your email\"# 生成公钥ssh-keygen -t rsa -C \"your_email@example.com\" -f ./-t rsa 约定加密类型-C 添加评论-f 保存秘钥的地址（默认是 ~/.ssh/id_rsa） 生成公钥的地方需要注意的是，生成的公钥会自动生成在~/.ssh/id_rsa中，若是你有多个账号的话，无疑会把原先的秘钥覆盖。可以在后续弹出的提示中约定key保存的地址 12Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter] // 推荐使用默认地址Enter passphrase (empty for no passphrase): //此处点击 Enter 键即可，也可以填写密码，填写密码后每次使用 SSH 方式推送代码时都会要求输入密码，由于这个 Key 也不是用于军事目的，所以也无需设置密码。 也可以在ssh-keygen中约定好 1234567ssh-keygen -t rsa -C \"your_email@example.com\" -f ~/.ssh/coding -f 保存在yon下的.ssh/coding文件中Your identification has been saved in /Users/ppsteven/.ssh/coding.Your public key has been saved in /Users/ppsteven/.ssh/coding.pub.The key fingerprint is:SHA256:P6R/Fo70VkCyKsQsFXXX... XXX@outlook.com .ssh 文件夹下也多了coding和coding.pub两个文件 coding是你的私钥，需要好好保管，在下面的配置文件中还需要使用，用以证明你自己的身份，coding.pub是公钥，我们需要上传到github，coding，码云等平台上去。 上传公钥这里只要找到对应上传的地方上传即可，一般平台都有对应的教程，下面我们copy一下coding的操作。 mac 复制文件小技巧 1cat coding.pub | pbcopy # 输出到剪切板 pbcopy : 表示复制剪切版pbpaste ：表示粘贴剪切版 配置config文件和添加私钥若是拥有多个账号，需要在 .ssh 下配置多个账号的配置文件 config ，这个配置文件是用来作为路由使用。我们需要检查是否存在 ~/.ssh/config 文件，不存在的话就创建如下文件。 123456789101112131415161718192021222324# ~/.ssh/config# github 账号Host github # HostName的别名,这个可以随便起HostName github.com # HostName: 远程仓库的域名AddKeysToAgent yes UseKeychain yes # Mac 上秘钥被持久化到&quot;钥匙串&quot;中，代表从钥匙串中使用保存的秘钥IdentityFile ~/.ssh/id_rsa # 私钥存储的地址User git # git 只是ssh的一个应用，会把 User 和 HostName 拼接 # coding 账号Host codingHostName git@e.coding.net # 如果不填写User，可以直接拼接AddKeysToAgent yesUseKeychain yesIdentityFile ~/.ssh/coding # github_work github工作账号Host github-workerHostName github.com AddKeysToAgent yesUseKeychain yesIdentityFile ~/.ssh/github_work User git 为了让SSH识别新的私钥，需将其添加到SSH agent中 12345ssh-agent bashssh-add -D # 删除之前存储的keyssh-add -l # 查看存储的key，这里应该是空的ssh-add ~/.ssh/id_rsassh-add ~/.ssh/coding 测试ssh是否设置成功123456789# ssh -T 后面的名字可以是上面的别名$ ssh -T githubHi PPsteven! You've successfully authenticated, but GitHub does not provide shell access.(base)$ ssh -T codingCoding 提示: Hello ppsteven, You've connected to Coding.net via SSH. This is a personal key.ppsteven，你好，你已经通过 SSH 协议认证 Coding.net 服务，这是一个个人公钥(base) 自动添加 秘钥 的几种方法ssh-add 这个命令是手动把私钥添加到 ssh-agent 所管理的 session 中，ssh-agent 是一个用于存储私钥的临时性的 session 服务。所以当我们重启机器的时候，ssh-agent 的服务也会重置。 方案一：使用 keychain（Mac推荐）keychain 是 Mac 电脑上的钥匙串服务，作用是存储密码、秘钥，证书等信息。Win 和 Linux 也有对应的机制，没有研究。 首先，我们要保证 config 里面有这样两段代码，Mac OS 10.12.2 以上系统需要，不然的话，无法持久化的添加到钥匙串中。 123456789# ~/.ssh/config# github 账号Host github # HostName的别名,这个可以随便起HostName github.com # HostName: 远程仓库的域名+ AddKeysToAgent yes # 是否把+ UseKeychain yes # Mac 上秘钥被持久化到\"钥匙串\"中，代表从钥匙串中使用保存的秘钥IdentityFile ~/.ssh/id_rsa # 私钥存储的地址User git # git 只是ssh的一个应用，会把 User 和 HostName 拼接 然后，利用 ssh-add -K ~/.ssh/[your file] 存储到 keychain 中。 1ssh-add -K Store passphrases in your keychain. 这时候，你可能在你的 钥匙串 中并没有发现成功添加，你可以利用 ssh -T github/coding/.. 也就是上面提到的测试的方法去测一下，如何成功的话，你会发现钥匙串中多了如下信息。 方案二：添加到启动配置中去（Linux推荐）我的 linux 上是直接把 私钥添加到 ssh-agent 中去的，尽管会失效，但是只要每次登陆的时候，都会添加一下就好，这个比较简单，适合懒人。 123$ eval \"$(ssh-agent -s)\"&gt; Agent pid 59566$ ssh-add ~/.ssh/id_rsa 下一个问题，应该把这一段代码添加到哪里。这里的建议是加到 .bashrc 或者 .bashrc_profile 这两个区别是前者是每次打开新 shell 的时候运行。后者是仅在登录的时候执行一次。 更多的地方参考我的另一篇教程：linux 环境变量执行顺序 参考资料如何添加多账号如何设置多个Git帐号 coding帮助中心 下面两个是 google 出来的解答，质量很高，建议参考 How to manage multiple GitHub accounts on a single machine with SSH keys 自动添加ssh账号是否必须每次添加ssh-add (推荐看) Generating a new SSH key and adding it to the ssh-agent (github 官方推荐流程)","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"}]},{"title":"docker命令大全","slug":"docker-cheetsheet","date":"2019-12-31T09:09:15.000Z","updated":"2020-01-26T08:59:10.833Z","comments":false,"path":"2019/12/31/docker-cheetsheet/","link":"","permalink":"http://ppsteven.github.io/2019/12/31/docker-cheetsheet/","excerpt":"最近在实习的过程中，需要将现有的服务上云，使用到了容器化的操作。需要自己制作Dockerfile文件，完成部署。鉴于对于docker技术的不熟练，用了几天时间好好把这个知识梳理了一下。 安装和基础命令详见上一篇文章 Docker安装及基础命令 P.S. 这篇博客又切换回了next 主题，主要的原因是这篇文章中一些代码与Butterfly主题有所冲突，所以又改用兼容性比较好的hexo。今天发现原来WordPress是用php写的，作为一个php程序员肯定要搞一把，之后有时间再研究一下。","text":"最近在实习的过程中，需要将现有的服务上云，使用到了容器化的操作。需要自己制作Dockerfile文件，完成部署。鉴于对于docker技术的不熟练，用了几天时间好好把这个知识梳理了一下。 安装和基础命令详见上一篇文章 Docker安装及基础命令 P.S. 这篇博客又切换回了next 主题，主要的原因是这篇文章中一些代码与Butterfly主题有所冲突，所以又改用兼容性比较好的hexo。今天发现原来WordPress是用php写的，作为一个php程序员肯定要搞一把，之后有时间再研究一下。 docker 镜像拉取镜像12$ docker pull alpine$ docker pull registry.hub.docker.com/alpine:latest 指定默认的仓库和版本号 123456[root@VM_118_62_centos ~]# docker pull alpineUsing default tag: latestlatest: Pulling from library/alpinee6b0cf9c0882: Pull complete Digest: sha256:2171658620155679240babee0a7714f6509fae66898db422ad803b951257db78Status: Downloaded newer image for alpine:latest 列出镜像12$ docker images$ docker image ls 给镜像加tag1$ docker tag alpine test 起到了链接的作用 查看镜像12$ docker inspect IMAGE # 返回json 格式$ docker inspect -f &#123;&#123; .\"DockerVersion\"&#125;&#125; IMAGE # 以GO 模范返回格式化的信息 搜索镜像123docker search IMAGE # 搜索镜像docker search --filter=starts=4 IMAGE # 返回收藏超过4的镜像docker search --filter=is-official=true IMAGE # 返回官方镜像 移除镜像123456789docker rmi IMAGE # 删除镜像docker image rm IMAGE # 删除镜像docker image rm ubuntu:latest # 删除指定tag 的镜像-f --force # 强制删除docker image prune -a, --all Remove all unused images, not just dangling ones （临时镜像） --filter filter Provide filter values (e.g. 'until=&lt;timestamp&gt;') -f, --force Do not prompt for confirmation 创建镜像 commit import build 三个子命令 commit 基于现有容器创建docker run -it alpine /bash/sh 1234# add a new file to this container [root@VM_118_62_centos ~]# docker run -it alpine /bin/sh / # touch text/ # exit docker [container] commit -m “add a new file” -a “johnjhwang” CONTAINER 注：方括号中的 container 是可以省略不写的。这里指出是说明commit 这个命令是 容器相关的命令比较建议写全，比如rm 在image 和 container 中都有，避免歧义 -m: 表示 Comment -a: 表示 Author由于是添加了一个文件，所以镜像的 IAMGE ID 发生了变化 当我们查看新的镜像的时候，能看到我们后续追加的信息 1234567891011[root@VM_118_62_centos ~]# docker inspect 764a657de081[ &#123; &quot;Id&quot;: &quot;sha256:764a657de08117c11b3af9720efe2310386fa99074802ad13f68973081972819&quot;, &quot;Parent&quot;: &quot;sha256:cc0abc535e36a7ede71978ba2bbd8159b8a5420b91f2fbc520cdf5f673640a34&quot;, &quot;Comment&quot;: &quot;add a new file &quot;, ...... &quot;Author&quot;: &quot;johnjhwang&quot;, ...... &#125;] 基于Dockerfile创建首先，创建一个文件Dockerfile 文件名必须是Dockerfile 编辑Dockerfile 12345FROM ununtu:latestLABEL version='1.0' maintainer='johnjhwang@tencent.com'RUN apt-get update &amp;&amp;\\ apt-get install -y python3 \\ apt-get clean 1docker [image] build -t python:3 .(小数点:这是上下文环境为当前目录) python 是镜像名，3是版本号注意，最后有一个点，代表的是上下文环境(当前目录) 基于本地模板导入// TO DO 存出和载入镜像12docker [image] save -o ubuntu_18.04.tar ubuntu:18.04 # 本地会出现ubuntu_18.04.tar 文件docker [image] load -i ubuntu_18.04.tar # 导入本地的文件，之后查看镜像库，发现出现了该镜像 这里我们可以用更加简便的写法 12docker save alpine &gt; alpine.tardocker load alpine &lt; alpine.tar 上传镜像 push// TO DO docker 容器新建容器&amp;&amp;启动容器 create、start、run docker create/start123docker [container] create -it alpine # 用create创建的容器处于停止状态 Created ，加-it 使用的是默认的shdocker [container] start CONTAINER # 运行后的容器状态转为 Up 查看状态 1234[root@VM_118_62_centos ~/desktop]# docker start 77a32260848[root@VM_118_62_centos ~/desktop]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES77a32260848e alpine \"/bin/sh\" 2 minutes ago Up 5 seconds naughty_lamport 还有一个更加方便的启动方式，等价于 先执行create 后执行 start docker run1234docker [container] run -it alpine /bin/sh-t, --tty Allocate a pseudo-TTY 分配一个伪终端 -i, --interactive Keep STDIN open even if not attached 标准输入保持打开 -d, --detach Run container in background and print container ID 暂停终止容器暂停/恢复容器 状态变为： Up (Paused) 1docker [container] pause/unpause CONTAINER 终止/启动容器 stop、kill、运行结束会使容器状态变为： Exited 1234docker [container] stop/start CONTAINER -t, --time int Seconds to wait for stop before killing it (default 10)docker [container] kill CONTAINER stop 是主动向容器发送 SIGTERM 信号，等待一段时候后，再发送SIGKILL信号来终止容器。默认10kill 是直接发送SIGKILL信号去终止容器。 有一种情况，当容器运行结束后，状态也会变为Exited 123456[root@VM_118_62_centos ~]# docker attach test/ # psPID USER TIME COMMAND 1 root 0:00 /bin/sh 6 root 0:00 ps/ # exit // 退出后容器会终止 可以看到容器中只有 /bin/sh 命令运行，此时使用 exit 或者 ctrl+d 退出容器，该容器会终止 清除容器prune12docker container prune # Remove all stopped containers -f, --force Do not prompt for confirmation rm1234docker container rm \\&lt;CONTAINER ID&gt; # Remove one or more containers -f, --force Force the removal of a running container (uses SIGKILL) -l, --link Remove the specified link -v, --volumes Remove the volumes associated with the container 重启容器 先停止容器后重启容器 1docker restart CONTAINER 进入容器attach1docker attach CONTAINER exec exec 相较于 attach 的优势是可以在运行的容器内执行任意命令Run a command in a running container 123456docker exec -it CONTAINER /bin/sh --detach-keys string Override the key sequence for detaching a container // 重载退出容器的方法,默认是ctrl+q -e, --env list Set environment variables -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) -w, --workdir string Working directory inside the container 导入/导出容器12docker [container] export -o test.tar test docker [image] import test.tar test01/test02:v1.0 注意: docker export 是 container 下的方法 docker import 是 image 下的方法，不要以为import 后导入到的容器库。 可以看到 docker [image] save 和 dokcer [image] load 是一对。docker [container] export 和 docker [image] import 是一对。但是 load 和 import 同样都是导入到 镜像库，区别在什么地方? docker save images_name：将一个镜像导出为文件，再使用docker load命令将文件导入为一个镜像，会保存该镜像的的所有历史记录。比docker export命令导出的文件大，很好理解，因为会保存镜像的所有历史记录。 docker export container_id：将一个容器导出为文件，再使用docker import命令将容器导入成为一个新的镜像，但是相比docker save命令，容器文件会丢失所有元数据和历史记录，仅保存容器当时的状态，相当于虚拟机快照。 查看容器123docker [container] inspect CONTAINRERdocker [container] top CONTAINER # 显示docker 内运行的进程 docker [container] stats CONTAINER # 显示docker的状态，CPU，内存，存储，网络等实时监控 * 其他容器命令 制作Dockerfile所需掌握的命令 docker cp 复制文件123Usage: docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH# FROM 左 TO 右 docker [container] cp data test:/temp 这是将本地路径下的 data 复制到 test 容器的/temp 路径下，注意只是复制文件内容，不没有包含文件夹。 docker [container] cp data test:/temp/data 这样才是把data文件夹移到了目标容器的文件夹下 docker container 命令大全12345678910111213141516171819202122232425attach Attach local standard input, output, and error streams to a running containercommit Create a new image from a container&apos;s changescp Copy files/folders between a container and the local filesystemcreate Create a new containerdiff Inspect changes to files or directories on a container&apos;s filesystemexec Run a command in a running containerexport Export a container&apos;s filesystem as a tar archiveinspect Display detailed information on one or more containerskill Kill one or more running containerslogs Fetch the logs of a containerls List containerspause Pause all processes within one or more containersport List port mappings or a specific mapping for the containerprune Remove all stopped containersrename Rename a containerrestart Restart one or more containersrm Remove one or more containersrun Run a command in a new containerstart Start one or more stopped containersstats Display a live stream of container(s) resource usage statisticsstop Stop one or more running containerstop Display the running processes of a containerunpause Unpause all processes within one or more containersupdate Update configuration of one or more containerswait Block until one or more containers stop, then print their exit codes docker 容器卷本章不再详述命令细节，只关注于常用命令 容器中对数据进行持久化的操作，需要借助数据管理操作。 一般有两种管理方式: Data Volumes Data Volume Containers 数据卷(Data Volumes)创建一个本地数据卷 docker volume create -d local –name haha 12-d, --driver string Specify volume driver name (default \"local\") --name 重命名 docker volumn create 创建完成的数据卷是在 /var/lib/docker/volumes 下的，可以通过 ls （查看） inspect(详细信息) prune 和 rm 去做进一步的操作。 123$ docker volume lsDRIVER VOLUME NAMElocal haha 这里mac需要注意，因为在mac上用docker会在mac上启动一个虚拟机运行docker，因此volume创建的directory并不在你的machine上，而是在虚拟机中。 mac用户如何查看数据卷地址如何进入mac上的虚拟机的办法请参考:这篇教程 具体的做法是执行：screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty 然后查看/var/lib/docker/volumes里面的容器 数据卷的类型 volume : 普通数据卷，映射到 /var/lib/docker/volumes下 bind: 绑定数据卷，是自己制定的目录 tmpfs: 临时数据卷，只存在于内存中，目前没有使用过 docker run -d –name test –mount type=bind,source=/mydata,destination=/opt/mydata CONTAINER COMMAND 这句话是绑定当前目录下的mydata文件夹至docker容器下的/opt/mydata文件夹 还有一个简洁的方式 -v docker run -d –name test -v /mydata:/opt/mydata CONTAINER COMMAND 数据容器(Data Volume Containers)创建一个数据卷容器，起别名 dbtest，并挂载 ~/Desktop/dbfile 到当前容器 docker run -it –name dbtest -v ~/Desktop/dbfile:/dbfile alpine:latest 然后，可以在其他容器中使用 –volumes-from 挂载dbtest 中的数据卷 docker run -it –name db1 –volumes-from dbtest alpinedocker run -it –name db2 –volumes-from dbtest alpine 数据卷高级用法：迁移数据数据的迁移有两步构成：备份+迁移 首先我们使用了上面建立好的 dbtest 数据卷容器，该容器和 ~/Desktop/dbfile 绑定，其中包含了我们需要保存的重要的数据。 备份 docker run –volumes-from dbtest -v $(pwd):/backup –name worker alpine tar cvf /backup/backup.tar /dbfile 这里我们把绑定的本地和容器内的/backup绑定，所以我们用压缩方法，把dbfile 内的数据打包放入了/backup文件夹中，直观的来说，在当前目录下会看到backup.tar 文件。 迁移 先创建一个新的数据卷容器dbtest2 docker run -v ~/Desktop/dbfile2:/dbfile –name dbtest2 alpine 创建新容器，挂载dbtest2的容器，并使用untar解压放在/backup/backup.tar 文件 docker run –volumes-from dbtest2 -v $(pwd):/backup –name worker2 ubuntu tar xvf /backup/backup.tar docker 端口映射启动一个web服务 12345docker run -d -P straining/webapp python app.py // 随机映射端口，49000~49900到容器内部端口docker run -d -p 5000:5000 training/webapp python app.py// HostPort:ContainerPortdocker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py// IP:HostPort:ContainerPortdocker run -d -p 127.0.0.1::5000 training/webapp python app.py // 自动分配一个端口docker run -d -p 127.0.0.1::5000/udp training/webapp python app.py // 制定UDP 稍后我们可以看到映射结果（下面是举例） 123127.0.0.1:32768-&gt;5000/tcp 0.0.0.0:3306-&gt;3306/tcp127.0.0.1:32768-&gt;5000/udp 容器互联–link name:aliasname:连接的容器 alias 容器的别名 容器间的互联是一个比较重要的知识点，后续会写一篇博客完善 参考资料docker load与docker import","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Docker","slug":"Docker","permalink":"http://ppsteven.github.io/tags/Docker/"}]},{"title":"Hexo进阶:博客转载文章设置","slug":"Hexo进阶:博客转载文章设置","date":"2019-12-22T07:10:44.000Z","updated":"2020-01-26T09:02:08.612Z","comments":false,"path":"2019/12/22/Hexo进阶:博客转载文章设置/","link":"","permalink":"http://ppsteven.github.io/2019/12/22/Hexo%E8%BF%9B%E9%98%B6:%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD%E6%96%87%E7%AB%A0%E8%AE%BE%E7%BD%AE/","excerpt":"遇见好的博客文章怎么办：1. 打上书签，让它永远的留在你的书签夹中。2. 在博客中转载在博客中转载的目的是把一些 工具类的网站，快捷键的整理记录下来。但是Hexo是用Markdown编写的，没有博客转载的功能，这时候我们就需要借助 HTML 的 iframe 去实现我们的功能了。这一部分知识属于前端的范畴了，也算是对于知识面的一个补充。","text":"遇见好的博客文章怎么办：1. 打上书签，让它永远的留在你的书签夹中。2. 在博客中转载在博客中转载的目的是把一些 工具类的网站，快捷键的整理记录下来。但是Hexo是用Markdown编写的，没有博客转载的功能，这时候我们就需要借助 HTML 的 iframe 去实现我们的功能了。这一部分知识属于前端的范畴了，也算是对于知识面的一个补充。 Same-Domain &amp;&amp; Cross-Domain我们的需求是在用 iframe 引用别人的网站的时候，需要根据这个网站的大小自动调节我们网站的大小。但是因为chrome 的安全限制，我们是无法直接获取别的网站的大小的。 &lt;iframe&gt;’s which display content from different domains have security measures in place to prevent all sorts of stuff. For example, you can’t have JavaScript access anything inside it. It can be very frustrating, for example, if you just want to do something normal and white-hat like adjust the height of the iframe to fit the content inside it. These security measures are in place to prevent all the black-hat kind of things you could do if you did have JavaScript access to the innards of an iframe. 简言之，就是游览器会阻止JavaScript 去做一些高危操作，如果是不一样的domian 的话，获取网站内部信息的行为就会被认为是危险的。 Same-DomianSame-Domain 的解决方法非常多，可以说，百度上搜到的大部分方法都是针对这一情况的。 我们直接附上代码 &amp;&amp; 实例 123456789101112131415161718&lt;style&gt; iframe &#123; width: 100px; min-width: 100%; &#125;&lt;/style&gt;&lt;script type=\"text/javascript\"&gt; function resizeIframe(obj) &#123; obj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px'; obj.style.width = obj.contentWindow.document.documentElement.scrollWidth + 'px'; alert(obj.style.height); alert(obj.style.width); &#125;&lt;/script&gt;&lt;iframe src=\"https://ppsteven.github.io/about/\"frameborder=\"0\" scrolling=\"no\" onload=\"resizeIframe(this)\" id = \"myiframe\"&gt;&lt;/iframe&gt; 下面是实例，这里未了方便展示，我们直接限制了Height最大为400 iframe { width: 100px; min-width: 100%; } function resizeIframe(obj) { obj.style.width = obj.contentWindow.document.documentElement.scrollWidth + 'px'; var height = obj.contentWindow.document.documentElement.scrollHeight; if (height > 400) height = 400; obj.style.height = height + 'px'; //alert(obj.style.height); //提示大小 //alert(obj.style.width); } Cross domain手动定义Size我们尝试使用上面Same-domain 的代码去获取百度的信息 1234&lt;iframe src=&quot;http://www.baidu.com&quot;frameborder=&quot;0&quot; scrolling=&quot;no&quot; onload=&quot;resizeIframe(this)&quot; id = &quot;abc&quot;&gt;&lt;/iframe&gt; 最终我们会得到 游览器 Block 的 警告 这个警告的页面是 在 Chrome 开发者工具的Console 中获得的，以后我们需要多次借助这个工具 123Uncaught DOMException: Blocked a frame with origin &quot;http://localhost:4000&quot; from accessing a cross-origin frame. at resizeIframe (http://localhost:4000/2019/12/21/test/:32:42) at HTMLIFrameElement.onload (http://localhost:4000/2019/12/21/test/:39:2) 其实最重要的问题就是获取 页面的大小，这个过程如果不让游览器自己去完成的话，我们人手工也可以完成，只是费劲一点（当然和写一篇博客比，这个过程可能只花费不到一分钟） 只要在Console 中输入 12document.body.scrollHeightdocument.body.scrollWidth 12345&lt;iframe src=\"http://www.laruence.com/2015/05/28/3038.html\"frameborder=\"0\" scrolling=\"no\"width=\"855px\"highth=\"26012px\"&gt;&lt;/iframe&gt; Autozise第二种方法就是利用postMessage 的方式，这一种方法我也亲自用过了，但是繁琐程度比较高。 需要在 Host.html 和 Frame.html 中都需要插入Js 代码 Host.html 就是 &lt;iframe&gt; 所在html，负责接受 Frame.html 传递过来的参数 Frame.html 也可以看做 source web 的网站，负责 传送数据。 这要求我们主动的去修改目标的html 代码，从中插入Js，这样的话，感觉不是很便捷，而且Js 代码也过于负责，目前不想整理这一块的内容。 具体操作请移步 参考资料 2 静态文本这一段是后加的, 我们可以直接存储html 格式的文件，然后在头部加上yaml 格式即可完成和markdown一样的操作 123---layout: false--- 参考资料 Cross Domain iframe Resizing这篇文章算是国外教程中整理的相当不错的文章了，介绍了在 same-domain 和 cross-domian 两种情况下的应对方式。 http://geekswithblogs.net/rashid/archive/2007/01/13/103518.aspx第一篇的教程就是参考这一篇文章的代码，原创级别","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"},{"name":"iframe","slug":"iframe","permalink":"http://ppsteven.github.io/tags/iframe/"}]},{"title":"PHP+phpstorm+xdebug 环境配置","slug":"PHP+phpstorm+xdebug 环境配置","date":"2019-12-14T15:19:51.000Z","updated":"2020-01-26T08:59:20.781Z","comments":false,"path":"2019/12/14/PHP+phpstorm+xdebug 环境配置/","link":"","permalink":"http://ppsteven.github.io/2019/12/14/PHP+phpstorm+xdebug%20%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"php 环境搭建是一件相当麻烦的事情，本篇博客记录了在Mac 系统下的环境配置。 Win上的php 环境搭建，建议使用XAMPP，一键搭建，而且自带xdebug.dll，用过就知道。Mac 上的php 环境，我一开始也使用了 XAMPP 作为环境，但是发现Mac 上的是阉割版的，也没有xdebug。 目前介绍的环境搭建方法是: brew 和 pecl","text":"php 环境搭建是一件相当麻烦的事情，本篇博客记录了在Mac 系统下的环境配置。 Win上的php 环境搭建，建议使用XAMPP，一键搭建，而且自带xdebug.dll，用过就知道。Mac 上的php 环境，我一开始也使用了 XAMPP 作为环境，但是发现Mac 上的是阉割版的，也没有xdebug。 目前介绍的环境搭建方法是: brew 和 pecl PHP 安装安装过程Mac 上是自带php和Apache的 12$ whereis php/usr/bin/php 我这里准备用brew 装一个最新的 12345678910$ brew search php==&gt; Formulaebrew-php-switcher php@7.2 phpmyadminphp php@7.3 ✔ phpstanphp-code-sniffer phplint phpunitphp-cs-fixer phpmd==&gt; Caskseclipse-php netbeans-php phpstorm(base) 安装最新的 php 7.3 1234567891011121314151617$ brew install php@7.3# 安装后，我们需要添加环境变量php@7.3 is keg-only, which means it was not symlinked into /usr/local,because this is an alternate version of another formula.If you need to have php@7.3 first in your PATH run: echo 'export PATH=\"/usr/local/opt/php@7.3/bin:$PATH\"' &gt;&gt; ~/.zshrc echo 'export PATH=\"/usr/local/opt/php@7.3/sbin:$PATH\"' &gt;&gt; ~/.zshrcFor compilers to find php@7.3 you may need to set: export LDFLAGS=\"-L/usr/local/opt/php@7.3/lib\" export CPPFLAGS=\"-I/usr/local/opt/php@7.3/include\"To have launchd start php@7.3 now and restart at login: brew services start php@7.3Or, if you don't want/need a background service you can just run: php-fpm brew 安装遇到的问题brew 安装php@7.3 的过程中，中间一条命令是 brew clean 产生了问题 12345$ brew cleanupWarning: Skipping opam: most recent version 2.0.3 not installedWarning: Skipping python: most recent version 3.7.2_2 not installedWarning: Skipping sqlite: most recent version 3.27.1 not installedError: Permission denied @ unlink_internal - /usr/local/lib/node_modules/@angular/cli/node_modules/.bin/in-install 既然说我们权限不够，第一反应是使用 sudo 命令，但是brew 不允许用户这么做。 经过查询后，可以使用如下命令，可以给没有权限的文件夹，更改权限。 1$ sudo chown -R \"$(whoami)\":admin /usr/local # 这里文件夹填写需要的 安装 xdebugxdebug 的安装是比较麻烦的，若是没有xdebug 需要的步骤复制很多。涉及到自己编译（自己编译的话，由于计算机环境不同又会产生很多问题） XAMPP 环境的安装这里XAMPP环境的话我建议参考下面的教程 Mac下XAMPP+PhpStorm中集成xdebug 简单的描述一下过程就是： 生成 phpinfo ，复制到 xdebug 官网官网下载xdebug.so 下载xdebug.tgz 解压文件: tar -xvzf xdebug.tgz 编译过程官方教程(有坑) 坑一：使用对phpize 命令。如果你电脑中安装的是XAMPP环境，你需要使用XAMPP环境的phpize /Applications/XAMPP/xamppfiles/bin/phpize 坑二：出现Cannot find autoconf 错误 brew install autoconf 坑三：./configure 编译问题 ./configure --with-php-config=/Applications/XAMPP/xamppfiles/bin/php-config make 获得 xdebug.so 文件 Pecl 方法安装（采用的方法）我们使用的较为简单的方法，就是使用pecl命令，如果我们成功的安装了 php 的话，pecl 是自带的。pecl 相当于为我们省去了编译的过程，也帮我们避免了很多的坑 pecl 之于 php 相当于 pip 之于 python 和 npm 之于 node.js，管理的是 php 的扩展(或者叫插件？) 配置php.ini找到php.ini 地址 12345$ php --iniConfiguration File (php.ini) Path: /usr/local/etc/php/7.3Loaded Configuration File: /usr/local/etc/php/7.3/php.iniScan for additional .ini files in: /usr/local/etc/php/7.3/conf.dAdditional .ini files parsed: /usr/local/etc/php/7.3/conf.d/ext-opcache.ini 添加如下代码 12345678910[xdebug]zend_extension=/Applications/XAMPP/xamppfiles/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so # xdebug 存放路径xdebug.remote_autostart=onxdebug.remote_enable=onxdebug.remote_mode=\"req\"xdebug.remote_host=localhostxdebug.remote_port=9000 # 端口号，记住xdebug.remote_handler=\"dbgp\"xdebug.idekey=\"PhpStorm\"xdebug.profiler_enable = Off 查看xdebug 是否成功安装，使用 php -m 查看所有已安装的扩展，存在xdebug 则表明安装成功。当然也可以使用 phpinfo() 查看xdebug。 注意: 重启Apache 服务才能看到 phpinfo 输出的情况 配置phpstorm 环境xdebug 在phpstorm 中的设置，有大量图，不想重复造轮子。看下面两个教程足够了。 史上最佳 Mac+PhpStorm+XAMPP+Xdebug 集成开发和断点调试环境的配置 Mac下XAMPP+PhpStorm中集成xdebug 实践下来，由于我只是作为php 后端开发，不需要与前端交互的话，我这里只需要保证下面的端口设置正确即可。 后记真实工作环境中，其实由于项目是很大的，实际上没有用到xdebug的机会（主要通过日志排查问题）。我这里安装xdebug 主要是想要通过逐步调试的过程，更好的理解php 语言，协程的使用方法等。 参考资料xdebug 官方安装教程 brew cleanup 问题解决方法–stackoverflow","categories":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/tags/php/"},{"name":"php环境配置","slug":"php环境配置","permalink":"http://ppsteven.github.io/tags/php%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"phpstorm","slug":"phpstorm","permalink":"http://ppsteven.github.io/tags/phpstorm/"}]},{"title":"php协程笔记","slug":"php协程笔记","date":"2019-12-07T10:19:13.000Z","updated":"2020-02-15T17:59:01.513Z","comments":false,"path":"2019/12/07/php协程笔记/","link":"","permalink":"http://ppsteven.github.io/2019/12/07/php%E5%8D%8F%E7%A8%8B%E7%AC%94%E8%AE%B0/","excerpt":"前言在实习的过程中使用到了腾讯微服务平台（Tencent Service Framework，TSF）框架，tsf中经常看到 $ret = (yield func(a,b)); 这样的用法。yield 外面包括号的用法并不常见，实际上这是yield的一种特殊的用法——协程。这里我准备通读一下这一领域的经典教程，好好理解yield 和 协程 是如何在PHP 项目开发中起到作用的。 在PHP中使用协程实现多任务调度| 风雪之隅 作者背景：风雪之隅，PHP开发组核心成员，鸟叔，PHP7的主要开发者。本篇文章其实他对一篇英文教程的翻译之作。 之所以标题起笔记，原因是原文理解起来稍有难度，所以我这里加上自己的理解。本篇可以在大家读原文的过程中做一个参考。","text":"前言在实习的过程中使用到了腾讯微服务平台（Tencent Service Framework，TSF）框架，tsf中经常看到 $ret = (yield func(a,b)); 这样的用法。yield 外面包括号的用法并不常见，实际上这是yield的一种特殊的用法——协程。这里我准备通读一下这一领域的经典教程，好好理解yield 和 协程 是如何在PHP 项目开发中起到作用的。 在PHP中使用协程实现多任务调度| 风雪之隅 作者背景：风雪之隅，PHP开发组核心成员，鸟叔，PHP7的主要开发者。本篇文章其实他对一篇英文教程的翻译之作。 之所以标题起笔记，原因是原文理解起来稍有难度，所以我这里加上自己的理解。本篇可以在大家读原文的过程中做一个参考。 进程、线程、协程的区别进程 进程是程序执行的一个实例 进程是资源分配的最小单位，资源包括：CPU，内存，I/O等 进程间的通讯方式（IPC） &lt;—- 抄，参考https://blog.csdn.net/daaikuaichuan/article/details/82951084 管道 Pipe 命名管道 FIFO * 消息队列（Message Queue) 腾讯的hippo Kafka 信号量（Semaphore） 共享内存（Shared Memory） * 套接字（Socket） 线程 轻量级进程(Lightweight Process，LWP） CPU调度的最小单位 进程由于是拥有系统资源，所以切换时需要保存上下文环境，开销大。线程开销小 协程 协程是一种比线程更加轻量级的存在 与进程线程不同的是，协程是完全由程序控制在（用户态执行） 举例： 当我们读文件的时候，我们可以主动让出控制权，而不是等待I/O操作完成。 特点 极高的执行效率，没有线程那么大的切换开销。我们知道涉及到内核参与管理的程序，需要从用户态通过中断的方式切换到内核态。这样的开销是极大的。 不需要多线程的锁机制，在协程中控制共享资源不加锁 对用户可见 协同，因为是由程序员自己写的调度策略，其通过协作而不是抢占来进行切换 协程的思想本质上就是控制流的主动让出（yield）和恢复（resume）机制（来源：PHP7下的协程实现） 迭代生成器迭代生成器是我们对于 yield 最常用的一个功能。用 yield 替代 return 作为函数的返回最大的作用是，它返回的不仅是一个值，而是一个迭代器。这一优点在面对无法载入到内存的大型数据集有很大的作用。 如以下代码 123456789function xrange($start,$end,$step = 1)&#123; for ($i = $start ; $i &lt;= $end ; $i += $step)&#123; yield $i; &#125;&#125;foreach (xrange(1,10000000000) as $num) &#123; echo $num .\"&lt;br&gt;\";&#125; 很明显，这里使用return的话，返回的是一个非常大的数组，当你数据量特别大的时候会造成数据溢出的问题。yield 的神奇之处在于，它会保持生成器的状态。函数会一直运行，直到下一个yield。程序执行的控制流可以在主代码和生成器函数之间切换，也不用用户担心上下文环境的问题。优点 运行大型数据集 不用编写就能生成复杂的生成器 写一个生成器的流程，需要 被迭代的类实现 IteratorAggregate 接口 定义一个返回迭代类的方法，这个类必须实现Iterator 接口 提供一系列必须实现的方法 rewind : 函数内部指针设置回到数据开始处 valid : 判读是否还有数据 key : 返回数据指针值 current : 返回当前指针指向的值 next : 移动到下一位yield 关键字简化了实现迭代器的过程。 TODO 实现一个PHP Iterator 对象 协程yield 的一个特性是函数每次执行到yield 的时候，就会主动让出控制权。这一点可以很好的帮助我们控制程序的执行顺序。 send 函数public Generator::send ( mixed $value ) : mixed 向生成器中传入一个值，并且当做 yield 表达式的结果。 然后继续执行生成器。 如果当这个方法被调用时，生成器不在 yield 表达式，那么在传入值之前，它会先运行到第一个 yield 表达式。传入生成器的值。这个值将会被作为生成器当前所在的 yield 的返回值。 利用send 函数，我们可以很方便的与协程进行交互，具体如下。 yield 作为参数接受者12345678910111213&lt;?phpfunction logger($fileName) &#123; echo \"这个语句只会执行一次\",\"\\n\"; while (true) &#123; echo yield . \"\\n\"; //函数每次都会执行要yield 暂停，然后让出控制权。 &#125;&#125;$logger = logger(__DIR__ . '/log');$logger-&gt;send('Foo'); // 输出 \"这个语句只会执行一次\", 输出 Foo \\n;$logger-&gt;send('Bar'); // 输出 Bar \\n;?&gt; yield 作用： 类似于debug 时候的断点，每一次都是运行到 yield 停止 可以利用send方法给 yield 传递数据 那自然会有一个疑问，此处的 yield 有没有接受数据回来？经过试验，发现此处的yield 是没有返回数据的。 这个例子可以看到yield 并没有返回数据，是NULL 12345678910111213&lt;?phpfunction logger($fileName) &#123; echo \"这个语句只会执行一次\",\"\\n\"; while (true) &#123; echo yield . \"\\n\"; //函数每次都会执行要yield 暂停，然后让出控制权。 &#125;&#125;$logger = logger(__DIR__ . '/log');$a = $logger-&gt;send('Foo'); // 输出 \"这个语句只会执行一次\", 输出 Foo;var_dump($a); // 返回 NULL , 这里的yield 并没有返回任何值?&gt; yield 同时接受和发送数据123456789101112131415&lt;?phpfunction gen() &#123; $ret = (yield 'yield1'); var_dump($ret); $ret = (yield 'yield2'); var_dump($ret);&#125; $gen = gen();var_dump($gen-&gt;current()); // string(6) \"yield1\"var_dump($gen-&gt;send('ret1')); // string(4) \"ret1\" (the first var_dump in gen) // string(6) \"yield2\" (the var_dump of the -&gt;send() return value)var_dump($gen-&gt;send('ret2')); // string(4) \"ret2\" (again from within gen) // NULL (the return value of -&gt;send())?&gt; 逐句分析 $ gen = gen() 指针指向这个迭代器 $ gen-&gt; current() 运行到第一个yield ，返回 yield 语句的值 yield，并 输出 类型和值 $ gen -&gt;send(“ret1”) 当前生成器在 yield 语句，于是把 “ret1” 当做 （yield “yield1”）的结果，并赋值给 $ret1。而且还会执行一个 gen-&gt;next() 移到下一个yield 处，返回第二个yield 语句的返回值 $ gen -&gt;send(“ret2”) 当前生成器在第二个yield 语句，把”ret2” 当做 (yield “yield2”) 的结果，并赋值给 $ret2 。继续向下执行，此时指针会移至迭代器末尾，此时已经没有yield ，所以返回NULL 多任务合作为了帮助理解 协程和任务调度的关机，yield 在 任务运行的过程中可以主动中断自身，并把控制权交还给调度器。 这里我们先需要实现: 任务、调度器 任务1234567891011121314151617181920212223242526272829303132333435&lt;?phpclass Task &#123; //实现一个任务 protected $taskId; //任务ID protected $coroutine;//协程 protected $sendValue = null;//send 传送的value protected $beforeFirstYield = true;//是不是第一次传送 // 因为每次send 返回的值，都是当前yield 的下一个yield 的返回值，这导致了第一个yield 的返回值被丢弃了。对于第一个 yield，我们需要用current()获取返回值，从第二个往后用send()获取返回值。 public function __construct($taskId, Generator $coroutine) &#123;//协程类型是 迭代器 $this-&gt;taskId = $taskId; $this-&gt;coroutine = $coroutine; &#125; public function getTaskId() &#123; return $this-&gt;taskId; &#125; public function setSendValue($sendValue) &#123; $this-&gt;sendValue = $sendValue; &#125; public function run() &#123; if ($this-&gt;beforeFirstYield) &#123;// 如果是第一次yield，那么就用current()返回 $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); &#125; else &#123;//如果不是第一个yield，就用send设置一个value，并返回下一个yield的值 $retval = $this-&gt;coroutine-&gt;send($this-&gt;sendValue); $this-&gt;sendValue = null;//设置完毕清空value return $retval; &#125; &#125; public function isFinished() &#123; return !$this-&gt;coroutine-&gt;valid();// 判断迭代器是否迭代完毕 &#125;&#125; 迭代器1234567891011121314151617181920212223242526272829303132333435363738&lt;?phpclass Scheduler &#123;//实现一个调度器 protected $maxTaskId = 0; // 最大任务 protected $taskMap = []; // taskId =&gt; task protected $taskQueue;// 任务队列 public function __construct() &#123; $this-&gt;taskQueue = new SplQueue(); // 实例化一个队列 &#125; public function newTask(Generator $coroutine) &#123; $tid = ++$this-&gt;maxTaskId;// 生成任务id $task = new Task($tid, $coroutine); // 创建任务 $this-&gt;taskMap[$tid] = $task;// 标识 taskId =&gt; task $this-&gt;schedule($task); return $tid; &#125; //任务入队 public function schedule(Task $task) &#123; $this-&gt;taskQueue-&gt;enqueue($task); &#125; //任务运行 public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue();// 出队 $task-&gt;run(); //任务运行 if ($task-&gt;isFinished()) &#123; //当前任务结束，删除 unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task);//未完成的话，放入队尾继续执行 &#125; &#125; &#125;&#125;?&gt; 用一个例子看看程序是否按照我们的期望在运行 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpinclude (\"Task.php\"); // 载入定义好的模块include(\"Scheduler.php\");function task1() &#123;// 程序运行10次 for ($i = 1; $i &lt;= 10; ++$i) &#123; echo \"This is task 1 iteration $i.\\n\"; yield; &#125;&#125;function task2() &#123;// 程序运行5次 for ($i = 1; $i &lt;= 5; ++$i) &#123; echo \"This is task 2 iteration $i.\\n\"; yield; &#125;&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task1());$scheduler-&gt;newTask(task2());$scheduler-&gt;run();结果如下:This is task 1 iteration 1.This is task 2 iteration 1.This is task 1 iteration 2.This is task 2 iteration 2.This is task 1 iteration 3.This is task 2 iteration 3.This is task 1 iteration 4.This is task 2 iteration 4.This is task 1 iteration 5.This is task 2 iteration 5.This is task 1 iteration 6.This is task 1 iteration 7.This is task 1 iteration 8.This is task 1 iteration 9.This is task 1 iteration 10. 发现程序是交替运行的，和我们的预期是相同的。因为我们使用了队列的结构，若是一个任务从队列中取出后并没有运行结束，我们会放入队尾继续运行。 与调度器之间的通信我们再看一眼，上面例子中需要运行的程序 123456function task1() &#123;// 程序运行10次 for ($i = 1; $i &lt;= 10; ++$i) &#123; echo \"This is task 1 iteration $i.\\n\"; // &lt;-- 若是要在用调度器中的taskid 替代此句需要怎么做。 yield; &#125;&#125; 如何实现：任务与调度器之间的通信。 我们使用的是 进程用来和操作系统会话的同样的方式来通信：系统调用。 要注意的是，不能简单的把调度器作为一个参数，传递给任务，不然很危险。这里作者通过yield表达式，配合send 来传递信息。 首先是对可调用的系统调用做一个封装 1234567891011121314151617&lt;?phpclass SystemCall &#123; protected $callback; // 传入的值是 一个可调用的类/函数 public function __construct(callable $callback) &#123; $this-&gt;callback = $callback; &#125; // __invoke:当类发生调用的使用使用 // 这样，类在使用的时候看上去和一个函数一样 // 传入的参数是 任务 和 调度器 // 作用是运行 初始化的函数/类 public function __invoke(Task $task, Scheduler $scheduler) &#123; $callback = $this-&gt;callback; return $callback($task, $scheduler); &#125;&#125;?&gt; 下面我们需要进行消息通讯 1234567891011121314151617&lt;?phpfunction task($max) &#123; // 我们需要传入 $tid 的值 从调度器中 $tid = (yield getTaskId()); // &lt;-- here's the syscall! for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"This is task $tid iteration $i.\\n\"; yield; &#125;&#125; $scheduler = new Scheduler; $scheduler-&gt;newTask(task(10));$scheduler-&gt;newTask(task(5)); $scheduler-&gt;run();?&gt; 这里，我们需要对传入的getTaskId 进行修改 传入的值是来自与调度器和任务的，结合之前的封装的系统调用 12345678910&lt;?phpfunction getTaskId() &#123; return new SystemCall(function(Task $task, Scheduler $scheduler) &#123; $task-&gt;setSendValue($task-&gt;getTaskId()); $scheduler-&gt;schedule($task); // 这里返回的是一个系统调用 // 作用是给任务设置 send 的值，send值的内容是 taskid // 把此任务加入调度器的队列中去 &#125;);&#125; 这里return 的不是如函数名写的 taskid，而是一个系统调用。 最后程序中的 $tid = (yield getTaskId()); 又会把这个系统调用传入调度器的队列中 进过这样的操作，我们调度器的队列中有两种类型的任务 SystemCall类型，但是它也可以和函数一样调用 Task 类型，也就是我们的任务类型 所以我们必须还要修改一下调度器的run方法（其实就是加入一段对SystemCall 的处理） 12345678910111213141516171819202122public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue(); $retval = $task-&gt;run(); // 这一段是新加的,如果出队的类型是系统调用，就在调度器里面调用它，传入任务 和 调度器 // 调用的结果是 // $task 会设置一个 Send 值 // $this(调度器) 会把这个 $task 加入到调度器的末尾 if ($retval instanceof SystemCall) &#123; $retval($task, $this); continue; &#125; //-------------------------- if ($task-&gt;isFinished()) &#123; unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task); &#125; &#125;&#125; 在xdebug 的帮助下，我们可以看到第一次 $retval = $task-&gt;run() 的返回值，会走到 Task(line: 24) 的$this-&gt;coroutine-&gt;current(); 最终取得的 getTaskId() 的返回值(类型为 SystemCall) 第二次走到$retval = $task-&gt;run() 的时候，最终是返回task 函数中的yield(); 所以返回值是null。 运行的结果就是，两个任务交替运行，知道结束。 123456789101112131415This is task 1 iteration 1.This is task 2 iteration 1.This is task 1 iteration 2.This is task 2 iteration 2.This is task 1 iteration 3.This is task 2 iteration 3.This is task 1 iteration 4.This is task 2 iteration 4.This is task 1 iteration 5.This is task 2 iteration 5.This is task 1 iteration 6.This is task 1 iteration 7.This is task 1 iteration 8.This is task 1 iteration 9.This is task 1 iteration 10. 协程堆栈协程堆栈是一个非常重要的应用，当你的项目变得越来越大的时候，会出现协程中套用另一个协程的情况。我们看下面这个例子。 123456789101112131415161718&lt;?phpfunction echoTimes($msg, $max) &#123; // 子协程 for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"$msg iteration $i\\n\"; yield; &#125;&#125; function task() &#123; echoTimes('foo', 10); // 期待打印10次foo，实际上返回的协程，并没有真实运行过 echo \"---\\n\"; echoTimes('bar', 5); // 期待打印5次bar，实际上返回的协程，并没有真实运行过 yield; // force it to be a coroutine&#125; $scheduler = new Scheduler;$scheduler-&gt;newTask(task());$scheduler-&gt;run();// 运行结果： ---\\n 最终的结果只运行了echo &quot;---\\n&quot;; 原因也很简单，当echoTimes(&#39;foo&#39;, 10) 运行后，实际上返回的协程，并没有参数去接受，也没有对协程进行进一步的处理（如 $this-&gt;current() $this-&gt;send ）自然也就不会运行了。 但是若是直接调用 echoTimes 子协程，也是无法运行 123456function task() &#123; yield echoTimes('foo', 10); // 添加了 yield 语句 echo \"---\\n\"; yield echoTimes('bar', 5); // 添加了 yield 语句 yield; // force it to be a coroutine&#125; 因为这里yield echoTimes(&#39;foo&#39;, 10);返回的是一个Generator 类型，而在我们的Task 类的run 方法里面，并没有对这一类型进行处理。而且我们需要的是进入函数内执行 yield 语句。这样来说，我们原先的方法就不适用了。如何解决？？ 解决的方法就是使用——协程栈 首先，我们对传入的 $coroutine 裸协程上写一个小小的封装，stackedCoroutine就是：“协程堆栈”。 因为它将管理嵌套的协程调用堆栈。这将使得通过生成协程来调用子协程成为可能。 注意: stackedCoroutine 中包含 yield 语句，所以它也是一个协程 1234567891011121314151617181920212223242526272829303132function stackedCoroutine(Generator $gen)&#123; $stack = new SplStack; // 新建一个栈 // 不断遍历这个传进来的生成器，作用和 while(True)一样 for (; ;) &#123; // $gen可以理解为指向当前运行的协程闭包函数（生成器） $value = $gen-&gt;current(); // 获取中断点，也就是yield出来的值 if ($value instanceof Generator) &#123; // 如果是也是一个生成器，这就是子协程了，把当前运行的协程入栈保存 $stack-&gt;push($gen); $gen = $value; // 把子协程函数给gen，继续执行，注意接下来就是执行子协程的流程了 continue; &#125; // 我们对子协程返回的结果做了封装 $isReturnValue = $value instanceof CoroutineReturnValue; // 子协程返回`$value`需要主协程帮忙处理 if (!$gen-&gt;valid() || $isReturnValue) &#123;// 协程栈没有执行完 或者 存在返回值 if ($stack-&gt;isEmpty()) &#123; return; &#125; // 如果是gen已经执行完毕，或者遇到子协程需要返回值给主协程去处理 $gen = $stack-&gt;pop(); //出栈，得到之前入栈保存的主协程 $gen-&gt;send($isReturnValue ? $value-&gt;getValue() : NULL); // 调用主协程处理子协程的输出值 continue; &#125; $gen-&gt;send(yield $gen-&gt;key() =&gt; $value); // 继续执行子协程 &#125;&#125; 我们发现这段语句中使用了到了一个我们之前没有使用到的类 CoroutineReturnValue 它的作用是接受 yield 的返回值，这个类比较简单，就是对返回的值，做了一层封装。子协程的返回的结果也需要主协程帮助处理。 在 $gen-&gt;send(yield ​$gen-&gt;key()=&gt;$value)； 调用者和当前正在运行的子协程之间扮演着简单代理的角色。 12345678910111213141516class CoroutineReturnValue &#123; protected $value; public function __construct($value) &#123; $this-&gt;value = $value; &#125; // 获取能把子协程的输出值给主协程，作为主协程的send参数 public function getValue() &#123; return $this-&gt;value; &#125;&#125;// 返回的值被封装成了一个类，这个类的话也很简单，就是存值。function retval($value) &#123; return new CoroutineReturnValue($value);&#125; 定义完了协程栈，如何去使用呢？这里需要将Task中的初始化方法改一下。 1234567public function __construct($taskId, Generator $coroutine) &#123; $this-&gt;taskId = $taskId; // $this-&gt;coroutine = $coroutine; // 换成这个，实际Task-&gt;run的就是stackedCoroutine这个函数，不是$coroutine保存的闭包函数了 $this-&gt;coroutine = stackedCoroutine($coroutine); &#125; 主程序如下 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?phpinclude (\"Task.php\");include (\"Scheduler.php\");include (\"stackedCorountine.php\");function echoTimes($msg, $max) &#123; for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"$msg iteration $i\\n\"; yield ; &#125; yield retval(\"程序运行结束\"); //我们在这里让子协程传值&#125;function task() &#123; $ret = yield echoTimes('foo', 5); // print foo ten times if ($ret)&#123; echo $ret; &#125; echo \"---\\n\"; $ret = (yield echoTimes('bar', 2)); // print bar five times if ($ret)&#123; echo $ret; &#125; yield; // force it to be a coroutine&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task());$scheduler-&gt;run();结果:foo iteration 1foo iteration 2foo iteration 3foo iteration 4foo iteration 5程序运行结束---bar iteration 1bar iteration 2程序运行结束 这个程序真的是不容易看懂，我是在xdebug 的逐步调试的过程中才看懂了一点。 解释下$gen-&gt;send(yield $gen-&gt;key()=&gt;$value)； 这个语句中send 和 yield 交叉，而且用了 $gen-&gt;key =&gt; $value 这样的用法。 yield 有三种用法 参考：php manual: yield 123yield; // 相当于 (yield null);$data = (yield $value); // 必须使用圆括号把yield申明包围起来$data = (yield $key =&gt; $value); //返回的是键值对，迭代的时候用 foreach($data as $key =&gt; $value) 首先我们找到 (yield $gen-&gt;key()=&gt;$value)； 返回的地方 12345678910public function run() &#123; if ($this-&gt;beforeFirstYield) &#123; $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); // &lt;-- 返回的是这里 &#125; else &#123; $retval = $this-&gt;coroutine-&gt;send($this-&gt;sendValue); // &lt;-- 返回的是这里 $this-&gt;sendValue = null; return $retval; &#125; &#125; 这里会让人很奇怪，因为我们返回的是键值对，这里直接调用current() 。经过实践可知 最终的值是$value ，也就是说，我们直接把语句改成 (yield $value) 也是正确的。 我的第二个疑问是$gen-&gt;send(yield $gen-&gt;key()=&gt;$value)； 中 send 方法到低发送出去了什么❓ send 方法中是一个yield 语句。那我们就可以找找在这个协程中有没有对应的send 方法即可。 最后，我们找到了这个协程的send 方法，但是$this-&gt;sendValue 我们是一直都没有设置过，始终是null。 协程堆栈小结这个协程堆栈实现起来比较费脑子，特别是主协程和子协程之间的沟通方式。可能现实情况下动手写的情况很少（我感觉是框架已经实现完毕，我们只需要简单的使用 $ret = (yield readfile()); 语句就可以）。但是如果能自己实现一遍协程堆栈，对yield 的用法肯定掌握的更好。 这篇教程参考了很多博客 PHP7下的协程实现 我是这么理解协程yield异步IO的 TO DO LIST yield from 教程中的 非阻塞IO 案例 代码分析 测试 配合我是这么理解协程yield异步IO的 程序附录程序一： 与调度器之间的通讯Index.php 123456789101112131415161718192021222324252627&lt;?phpinclude (\"Task.php\");include (\"Scheduler.php\");include (\"SystemCall.php\");function getTaskId() &#123; return new SystemCall(function(Task $task, Scheduler $scheduler) &#123; $task-&gt;setSendValue($task-&gt;getTaskId()); $scheduler-&gt;schedule($task); &#125;);&#125;function task($max) &#123; $tid = (yield getTaskId()); // &lt;-- here's the syscall! for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"This is task $tid iteration $i.\\n\"; yield; &#125;&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task(10));$scheduler-&gt;newTask(task(5));$scheduler-&gt;run();?&gt; Scheduler.php 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?phpclass Scheduler &#123; protected $maxTaskId = 0; protected $taskMap = []; // taskId =&gt; task protected $taskQueue; public function __construct() &#123; $this-&gt;taskQueue = new \\SplQueue(); &#125; public function newTask(Generator $coroutine) &#123; $tid = ++$this-&gt;maxTaskId; $task = new Task($tid, $coroutine); $this-&gt;taskMap[$tid] = $task; $this-&gt;schedule($task); return $tid; &#125; public function schedule(Task $task) &#123; $this-&gt;taskQueue-&gt;enqueue($task); &#125; public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue(); $retval = $task-&gt;run(); if ($retval instanceof SystemCall) &#123; $retval($task, $this); continue; &#125; if ($task-&gt;isFinished()) &#123; unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task); &#125; &#125; &#125;&#125;?&gt; SystemCall.php 12345678910111213&lt;?phpclass SystemCall &#123; protected $callback; public function __construct(callable $callback) &#123; $this-&gt;callback = $callback; &#125; public function __invoke(Task $task, Scheduler $scheduler) &#123; $callback = $this-&gt;callback; return $callback($task, $scheduler); &#125;&#125; Task.php 123456789101112131415161718192021222324252627282930313233343536&lt;?phpclass Task &#123; protected $taskId; protected $coroutine; protected $sendValue = null; protected $beforeFirstYield = true; public function __construct($taskId, Generator $coroutine) &#123; $this-&gt;taskId = $taskId; $this-&gt;coroutine = $coroutine; &#125; public function getTaskId() &#123; return $this-&gt;taskId; &#125; public function setSendValue($sendValue) &#123; $this-&gt;sendValue = $sendValue; &#125; public function run() &#123; if ($this-&gt;beforeFirstYield) &#123; $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); &#125; else &#123; $retval = $this-&gt;coroutine-&gt;send($this-&gt;sendValue); $this-&gt;sendValue = null; return $retval; &#125; &#125; public function isFinished() &#123; return !$this-&gt;coroutine-&gt;valid(); &#125;&#125;?&gt; 程序二： 协程堆栈index.php 123456789101112131415161718192021222324252627282930&lt;?phpinclude (\"Task.php\");include (\"Scheduler.php\");include (\"stackedCorountine.php\");function echoTimes($msg, $max) &#123; for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"$msg iteration $i\\n\"; yield ; &#125; yield retval(\"程序运行结束\\n\");&#125;function task() &#123; $ret = yield echoTimes('foo', 5); // print foo ten times if ($ret)&#123; echo $ret; &#125; echo \"---\\n\"; $ret = (yield echoTimes('bar', 2)); // print bar five times if ($ret)&#123; echo $ret; &#125; yield; // force it to be a coroutine&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task());$scheduler-&gt;run(); stackedCoroutine.php 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?phpfunction stackedCoroutine(Generator $gen) &#123; $stack = new SplStack; for (;;) &#123; $value = $gen-&gt;current(); if ($value instanceof Generator) &#123; $stack-&gt;push($gen); $gen = $value; continue; &#125; $isReturnValue = $value instanceof CoroutineReturnValue; if (!$gen-&gt;valid() || $isReturnValue) &#123; if ($stack-&gt;isEmpty()) &#123; return; &#125; $gen = $stack-&gt;pop(); $gen-&gt;send($isReturnValue ? $value-&gt;getValue() : NULL); continue; &#125; $gen-&gt;send( (yield $gen-&gt;key() =&gt; $value)); &#125;&#125;class CoroutineReturnValue &#123; protected $value; public function __construct($value) &#123; $this-&gt;value = $value; &#125; // 获取能把子协程的输出值给主协程，作为主协程的send参数 public function getValue() &#123; return $this-&gt;value; &#125;&#125;function retval($value) &#123; return new CoroutineReturnValue($value);&#125; Task.php 和 Scheduler.php 不变","categories":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/tags/php/"},{"name":"协程","slug":"协程","permalink":"http://ppsteven.github.io/tags/%E5%8D%8F%E7%A8%8B/"}]},{"title":"如何利用SSH连接家中的服务器:ngrok","slug":"如何利用SSH连接家中的服务器","date":"2019-12-01T05:23:30.000Z","updated":"2020-01-20T17:47:59.749Z","comments":false,"path":"2019/12/01/如何利用SSH连接家中的服务器/","link":"","permalink":"http://ppsteven.github.io/2019/12/01/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8SSH%E8%BF%9E%E6%8E%A5%E5%AE%B6%E4%B8%AD%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"家中闲置了一台电脑，准备用来当做服务器。一方面也是作为linux 学习练练手，二是可以运行一些爬虫小程序或者是网页服务。 这里我用的manjaro，这是目前比较流行的linux 发行版，最热门的linux桌面发行版之一。 我选择manjaro也是想作为替代windows 来用。manjaro拥有一个非常方便的软件仓库，利用pacman和yay等命令可以十分方便的安装软件。","text":"家中闲置了一台电脑，准备用来当做服务器。一方面也是作为linux 学习练练手，二是可以运行一些爬虫小程序或者是网页服务。 这里我用的manjaro，这是目前比较流行的linux 发行版，最热门的linux桌面发行版之一。 我选择manjaro也是想作为替代windows 来用。manjaro拥有一个非常方便的软件仓库，利用pacman和yay等命令可以十分方便的安装软件。 家中的电脑，由于没有公网ip，只能在家中用ssh 访问，一旦出门，就无法访问服务器了。这非常不方便，因为可能要从电脑上获取资料，访问数据库，修改代码等等操作，一旦离开本地环境，也太不方便了。 经过百度后发现，需要利用 内网穿透 技术实现。 原因是我们的ip资源是稀缺的，我们普通家庭中使用的ip都是动态分配的ip地址。没有固定的ip的服务器是无法与外网连接的，所以我们至少需要一个公网ip。 内网穿透技术有很多了，我这里选择的是ngrok 这个方案。我试了一下两种方案，第一个是外国的ngrok，没有尝试成功，而且免费版本每次断开后，生成的url 是随机的。所以没有采用。第二个是国内的Sunny-Ngrok，有免费版的。先尝试一波。 ngrok ngrok.cc （Sunny-Ngrok） 使用Sunny-Ngrok一个很大的好处就是在当你没有服务器和公网ip的时候，它会是一个很不错的解决方案。当然若是你有服务器的话，自己搭一个ngrok未尝不是一个很好的选择。 局域网连接服务器这里先给出用局域网连接服务器的方法 1234# linux 查看ip 地址一般是下面三种方法（不同系统不一样）$ ifconfig$ ipconfig$ ip addr # &lt;--manjaro 运行如下 123456$ ip addr | grep inet inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host inet 192.168.1.102/24 brd 192.168.1.255 scope global dynamic noprefixroute wlp2s0 inet6 fe80::1bd5:9435:6572:ffc7/64 scope link noprefixroute# ip地址是 192.168.1.102 局域网中使用 12ssh -p 22 ppsteven@192.168.1.l02# -p 22 也可以省略，因为ssh 的默认端口号就是22 Sunny-Ngrok教程教程基本上都在 ngrok.cc官方文档 写的很清楚了，但是有一些还是需要注意的。 开通隧道 如果你是想用ssh，开通的就是TCP转发。记得要把本地端口换成22（当然不换也是可以的，只要你最后连ssh 的时候设置好端口就行了） 最后看到的结果是这样的 1$ ssh -p 10568 yourname@free.aa.com 就可以连接上你的服务器了 Ngrok 启动上图可以看到，在状态栏显示 是否成功开启ngrok 启动的方法，官网教程里面也有写，本人按照流程走一遍。 下载客户端我用的是Mac 下载zip文件，然后上传到服务器的操作。有图形界面的同学，可以直接按照官网操作。 1234$ scp ~/Downloads/linux_amd64.zip ppsteven@192.168.1.102:~/Documents$ ssh 192.168.1.102$ cd ~/Documents$ unzip linux_amd64.zip 启动ngrok 服务123# 当前目录在linux_amd64 下$ ./sunny clientid 隧道id # 启动隧道服务$ setsid ./sunny clientid 743acXXXX &amp; # 在后台启动隧道服务 启动服务后，我们在官网的后端就可以看到结果。为了让我们的服务器能不断的在后台运行，我们需要登录服务器后，运行第二行的命令 &amp; 作用是后台运行程序 setsid 作用是当终端关闭的时候命令一直不会关闭 高级教程——开机自动运行官网中已经给出了 Ngrok开机自启动 的教程，我们这里由于使用的是manjaro，官网的教程无法直接参考，我们这里给出自己的解决方案。 第一步：移动命令，并使之可执行12sudo mv sunny /usr/local/bin/sunnysudo chmod +x /usr/local/bin/sunny 第二步：编写启动脚本我们这里直接上手修改官网的shell语言 sunny_auto.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/bash -e### BEGIN INIT INFO# Provides: ngrok.cc# Required-Start: $network $remote_fs $local_fs# Required-Stop: $network $remote_fs $local_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: autostartup of ngrok for Linux### END INIT INFONAME=sunnyDAEMON=/usr/local/bin/$NAMEPIDFILE=/var/run/$NAME.pid# 判断 sunny 是否可执行[ -x \"$DAEMON\" ] || exit 0case \"$1\" in start) # 根据/var/run/sunny.pid 文件判断sunny是否正在运行 if [ -f $PIDFILE ]; then echo \"$NAME already running...\" echo -e \"\\033[1;35mStart Fail\\033[0m\" else echo \"Starting $NAME...\" # start-stop-daemon -S -p $PIDFILE -m -b -o -q -x $DAEMON -- clientid 隧道id || return 2 # 不使用start-stop-daemon，使用常规的方法后台运行 setsid sunny clientid 1cb52410136cfe34 &amp; echo -e \"\\033[1;32mStart Success\\033[0m\" fi ;; stop) echo \"Stoping $NAME...\" # start-stop-daemon -K -p $PIDFILE -s TERM -o -q || return 2 # pkill 是 kill 和 pgrep 的结合，删除所有中带sunny的进程 pkill -9 sunny rm -rf $PIDFILE echo -e \"\\033[1;32mStop Success\\033[0m\" ;; restart) $0 stop &amp;&amp; sleep 2 &amp;&amp; $0 start ;; *) echo \"Usage: $0 &#123;start|stop|restart&#125;\" exit 1 ;;esacexit 0 写完之后，我们需要测试一下 12345chmod a+x sunny_auto.sh./sunny_auto.sh # 会输出使用方法./sunny_auto.sh start ./sunny_auto.sh stop./sunny_auto.sh restart 测试成功后，我们需要让系统自己启动。我看了一下，目前网上大部分教程都是直接给了代码，并没有解释清楚自启动的原理。我认为这是可以通过查看官方教程一步步讲清楚的。抱着“授人以鱼不如授人以渔” 的态度，我准备写的仔细一点。 第三步：自动跑起来我们的系统是manjaro，是arch linux 的衍生版本，所以我们第一想到的就是去 https://wiki.archlinux.org/ 上找。 archlinux 上，在如下九个方面，我们可以完成”autostart” 操作 开关机 登录登出 插入拔出设备 计时事件 文件系统事件 shell登录登出 Xorg 桌面环境 窗口管理启动 这里，我们需要第一项开关机 Systemd 作为我们自启动的方式，其实很多教程中也是采用的这个方式。 单元文件一个服务可以看做是一个unit，每个unit需要编写自己的单元文件。systemd 单元文件的语法来源于 XDG 桌面项配置文件.desktop文件，最初的源头则是Microsoft Windows的.ini文件。 单元文件操作立即激活单元： 1# systemctl start &lt;单元&gt; 立即停止单元： 1# systemctl stop &lt;单元&gt; 重启单元： 1# systemctl restart &lt;单元&gt; 重新加载配置： 1# systemctl reload &lt;单元&gt; 输出单元运行状态： 1$ systemctl status &lt;单元&gt; 检查单元是否配置为自动启动： 1$ systemctl is-enabled &lt;单元&gt; 开机自动激活单元： 1# systemctl enable &lt;单元&gt; 设置单元为自动启动并立即启动这个单元: 1# systemctl enable --now unit 取消开机自动激活单元： 1# systemctl disable &lt;单元&gt; 编辑我们的单元文件单元文件的语法，可以参考系统已经安装的单元，也可以参考 systemd.service(5) 中的EXAMPLES章节。英文不好的同学，有一位热心的大牛，已经写好了中文教程 systemd.index 中文手册 单元文件的地址如下 /usr/lib/systemd/system/ ：软件包安装的单元 /etc/systemd/system/ ：系统管理员安装的单元 从网上的教程看下来，大家最喜欢的一个做法就是创建一个rc.local 文件，和一个rc-local.service 服务。然后把我们需要运行的脚本加入rc.local中。 我认为这样的做法很省事，也比较简单，不过缺点是所有的开机自启服务都放一起了，比较乱不好管理。这里我准备按照自己的想法来创建一个服务，我这里借鉴了docker.service。 sunny.service 1234567891011121314151617[Unit]Description=ngrok sunny[Service]Type=forkingUser=ppsteven# 自动重启服务# Restart=always# RestartSec=30# 执行命令Restart=on-failureExecStart=/etc/sunny.sh startExecStop=/etc/sunny.sh stop# ExecReload=/bin/kill -s HUP $MAINPID[Install]WantedBy=multi-user.target 连接远程服务器ngrok 的作用直观的来说，就是给我们提供了一个公网ip，使我们可以访问内网地址。ngrok的作用就是，将我们传给www.abc.com:12345 的端口转发给我们本地服务器127.0.0.1:22端口上，实现了ssh功能。 1$ ssh -p 12345 yourname@www.abc.com .zshrc 配置小结12$ alias localDell=\"ssh ppsteven@192.168.1.102\"$ alias remoteDell=\"ssh -p 10568 yourname@free.aa.com\" 参考资料有了内网穿透神器 ngrok ，个人电脑也能做服务器","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ppsteven.github.io/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://ppsteven.github.io/tags/ssh/"},{"name":"sunny-ngrok","slug":"sunny-ngrok","permalink":"http://ppsteven.github.io/tags/sunny-ngrok/"}]},{"title":"Docker安装及基础命令","slug":"docker-installation-and-basic-command","date":"2019-11-21T12:22:30.000Z","updated":"2020-01-26T09:04:45.259Z","comments":false,"path":"2019/11/21/docker-installation-and-basic-command/","link":"","permalink":"http://ppsteven.github.io/2019/11/21/docker-installation-and-basic-command/","excerpt":"最近的工作 php 学习，设计到LAMP的环境搭建。虽然是Mac上Apache 和 php 都是自带的，但是环境上还是不足，所以要用Docker。DAMP 爬虫ip 池搭建，发现别人造好的轮子上需要如redis，flask等环境。而且配置完了，最终也是要部署到服务器上去的，所以docker 是必不可少的 最近的工作，让我感到Docker的学习一定要提前了。因为只是先用起来，首先记录一些常用的命令，争取一天搞定。","text":"最近的工作 php 学习，设计到LAMP的环境搭建。虽然是Mac上Apache 和 php 都是自带的，但是环境上还是不足，所以要用Docker。DAMP 爬虫ip 池搭建，发现别人造好的轮子上需要如redis，flask等环境。而且配置完了，最终也是要部署到服务器上去的，所以docker 是必不可少的 最近的工作，让我感到Docker的学习一定要提前了。因为只是先用起来，首先记录一些常用的命令，争取一天搞定。 Docker 安装我的主力机子是Mac，家里用旧电脑搭了 manjaro ，所以我需要两个安装教程 Mac Docker安装Mac 上配置docker最为方便 这里参考 菜鸟教程:MacOS Docker 安装 1234$ brew cask install docker # 查看是否安装成功$ docker info $ docker -v 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。还有 https://registry.docker-cn.com 是官方的中国站点。这些站点存储的是docker hub 的官方热门镜像，如果是私人的镜像，还是需要去美国站点下载。 在任务栏点击 Docker for mac 应用图标 -&gt; Perferences… -&gt; Daemon -&gt; Registry mirrors。在列表中填写加速器地址即可。修改完成之后，点击 Apply &amp; Restart 按钮，Docker 就会重启并应用配置的镜像地址了。 Manjaro docker 安装Manjaro 也拥有非常强大的包管理软件 pacman 和 yay这里我们使用pacman，这里面的软件都是来自官方库 12345678# 安装docker$ sudo pacman -S docker# 启动docker 服务$ sudo systemctl start docker # 查看docker服务状态$ sudo systemctl status docker# 设置docker开启启动服务$ sudo systemctl enable docker 这里Linux 有一个比Mac 麻烦一点的地方，就是每次使用docker 需要用sudo 超级管理员权限 12345678# 如果还没有 docker group 就添加一个sudo groupadd docker# 将自己的登录名($&#123;USER&#125; )加入该 group 内。然后退出并重新登录就生效啦sudo gpasswd -aG $&#123;USER&#125; docker# 重启 docker 服务sudo systemctl restart docker Linux 镜像加速 12345678910111213141516# 新建配置文件$ sudo touch /etc/docker/daemon.json # 添加国内站点&#123; \"registry-mirrors\": [\"https://registry.docker-cn.com\",\"http://hub-mirror.c.163.com\"]&#125;# 重启docker daemon$ sudo systemctl restart docker # 查看是否有修改成功$ docker info # 查看Register Mirrors的信息Registry Mirrors: https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ Docker 镜像使用12345678910111213141516171819202122232425# 列出本地的镜像 images$docker images$docker image ls REPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest 775349758637 2 weeks ago 64.2MB# 标签的含义- REPOSTITORY：表示镜像的仓库源- TAG：镜像的标签- IMAGE ID：镜像ID- CREATED：镜像创建时间- SIZE：镜像大小# 获取镜像$docker pull ubuntu:13.10# 查找镜像$docker search ubuntu- NAME:镜像仓库源的名称- DESCRIPTION:镜像的描述- OFFICIAL:是否docker官方发布# 删除镜像$docker rmi# 删除所有镜像 创建并启动容器docker run 是docker 命令中比较复杂的一个命令 12345678$docker run &lt;images&gt; &lt;command&gt;$docker run busybox echo hello world$docker run Ubuntu:16.01 /bin/bash$docker run -t-i Ubuntu:16.01 /bin/bash-t-i: 交互式会话-d: 后台方式--rm: 运行完成后就会删除$docker exec -ti &lt;CONTAINER ID&gt; /bin/bash 容器信息12345# 下面所有的&lt;CONTAINER ID&gt; 都可以用容器的NAME 替代# docker 很贴心的为我们的容器起了名字# 列出运行容器$docker ps $docker ps -a # 包含停止但没有消失的容器 容器管理12345678910111213141516# 停止正在运行的容器$docker kill &lt;CONTAINER ID&gt;$docker stop &lt;CONTAINER ID&gt; # 两个命令都是会停止容器运行# 停止没有消失的容器$docker restart &lt;CONTAINER ID&gt;$docker start &lt;CONTAINER ID&gt;# 启动并进入交互界面$docker start -it &lt;CONTAINER ID&gt; /bin/bash# 删除无用的容器$docker rm &lt;CONTAINER ID&gt;# 删除所有已停止的容器$docker rm -v $(docker ps -aq -f status=exited)# 删除所有容器$docker rm $(docker ps -a) 查看docker输出用于查看docker 的输出，对于没有交互(-ti)的容器的时候，需要用这个命令查看容器输出 1$docker logs &lt;CONTAINER ID&gt; 文件拷贝1$docker cp &lt;CONTAINER ID&gt;:[/path/to/file] 参考资料 DockerCheatSheetLinux(Manjaro) -Docker 安装及基本配置","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Docker","slug":"Docker","permalink":"http://ppsteven.github.io/tags/Docker/"}]},{"title":"Github 搜索技巧","slug":"github-search-tips","date":"2019-11-21T12:12:42.000Z","updated":"2020-02-18T18:39:29.477Z","comments":false,"path":"2019/11/21/github-search-tips/","link":"","permalink":"http://ppsteven.github.io/2019/11/21/github-search-tips/","excerpt":"前言因为最近手头上的东西很多，要最快的在很短的时间内完成一个项目，需要多多参考别人的优秀的代码。很多东西，在github 上都开源了，反复造轮子浪费时间，用好别人东西才是最高效的方法。","text":"前言因为最近手头上的东西很多，要最快的在很短的时间内完成一个项目，需要多多参考别人的优秀的代码。很多东西，在github 上都开源了，反复造轮子浪费时间，用好别人东西才是最高效的方法。 瞎逛逛 GitHub Trend 页面总结了每天/每周/每月周期的热门 Repositories 和 Developers，你可以看到在某个周期处于热门状态的开发项目和开发者。 GitHub Topic 展示了最新和最流行的讨论主题，在这里你不仅能够看到开发项目，还能看到更多非开发技术的讨论主题，比如 Job、Chrome 浏览器等。 搜索技巧12345678910in:name xx //搜索名字中带有&quot;xx&quot;的in:readme xx //搜索readme中带有&quot;xx&quot;的in:description xx //搜索描述中带有&quot;xx&quot;的stars:&gt;1000 //搜索stars&gt;1000的forks:&gt;1000 //搜索forks&gt;1000的pushed:&gt;2019-09-01 //搜索最近更新于2019年9月1日之后的language:xx //搜索xx的项目pushed:&gt;2019-09-01 //2019年9月1日后有更新的language:java //用Java编写的项目user:ppsteven forks:&gt;100 //ppsteven用户下forks&gt;100 的项目 有影响力的项目 free-programming-books：整理了所有和编程相关的免费书籍，同时也有 中文版项目。 github-cheat-sheet：集合了使用 GitHub 的各种技巧。 后续会逐步更新添加 参考 掌握 3 个搜索技巧，在 GitHub 上快速找到实用软件资源","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://ppsteven.github.io/tags/Github/"}]},{"title":"PHP学习笔记","slug":"php学习笔记","date":"2019-11-19T11:17:08.000Z","updated":"2020-02-15T18:02:05.494Z","comments":false,"path":"2019/11/19/php学习笔记/","link":"","permalink":"http://ppsteven.github.io/2019/11/19/php%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"php 入门教程，主要来自于菜鸟教程，入门级别，日常学习笔记。找了一个 php 的实习，必须马上掌握啊。","text":"php 入门教程，主要来自于菜鸟教程，入门级别，日常学习笔记。找了一个 php 的实习，必须马上掌握啊。 示例123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;My first PHP page&lt;/h1&gt;&lt;?phpecho \"Hello World!\";?&gt;&lt;/body&gt;&lt;/html&gt; 注释123456&lt;?php// php 代码？&gt;// 单行注释/**/ 多行注释 echo/printecho // 多个print // 一个 12345&lt;?php //两行是相同效果，&lt;br&gt; 看做回车 echo \"Hello world! from:\",\"Elen\",\"&lt;br&gt;\"; print \"Hello world! from:\".\"Elen\".'&lt;br&gt;'; ?&gt; Echo,print,print_r,var_dump 区别 1.echo 输出一个或者多个字符串。 2.print 和 echo 最主要的区别： print 仅支持一个参数，并总是返回 1。 3.print_r 打印关于变量的易于理解的信息,如果给出的是 string、integer 或 float，将打印变量值本身。如果给出的是 array，将会按照一定格式显示键和元素。object 与数组类似。 记住，print_r() 将把数组的指针移到最后边。使用 reset() 可让指针回到开始处。 4.var_dump 此函数显示关于一个或多个表达式的结构信息，包括表达式的类型与值。数组将递归展开值，通过缩进显示其结构。 5.var_dump 和 print_r 的区别 var_dump 返回表达式的类型与值而 print_r 仅返回结果，相比调试代码使用 var_dump 更便于阅读。 EOF 定义字符串1234567&lt;?php$name=\"Sally\";$a= &lt;&lt;&lt;EOF \"hername : \" $name \"123\"EOF;echo $a; output: 1&quot;hername : &quot; Sally &quot;123&quot; 结束需要独立一行且前后不能空格 $name 经过了计算 空格和换行都被处理为一个空格 PHP 类型String（字符串）, Integer（整型）, Float（浮点型）, Boolean（布尔型）, Array（数组）, Object（对象）, NULL（空值） 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?php// String$a = \"Hello world\";// Integer $b = 3;// Float$c = 3.0;$d = (float)$a;// Boolean$e = '3.0'==3; //$e 的值应该是为true，因为== 是弱比较，不关心等式左右的类型$f = true; // Array$g = array('name'=&gt;'wang','year'=&gt;2000);// Objectclass Car&#123; var $color; function __construct($color=\"green\") &#123; $this-&gt;color = $color; &#125; function what_color() &#123; return $this-&gt;color; &#125;&#125;$h = new Car();// NULL$i = null;function print_($obj) &#123; echo $obj,'=&gt;',var_dump($obj),'&lt;br&gt;';&#125;// 输出print_($a);print_($b);print_($c);print_($d);print_($e);print_($f);print_($g);var_dump($h);echo \"&lt;br&gt;\";print_($i);?&gt; 结果如下 123456789Hello world=&gt;string(11) &quot;Hello world&quot;3=&gt;int(3)3=&gt;float(3)0=&gt;float(0)1=&gt;bool(true)1=&gt;bool(true)Array=&gt;array(2) &#123; [&quot;name&quot;]=&gt; string(4) &quot;wang&quot; [&quot;year&quot;]=&gt; int(2000) &#125;object(Car)#1 (1) &#123; [&quot;color&quot;]=&gt; string(5) &quot;green&quot; &#125;=&gt;NULL 常量1234bool define ( string $name , mixed $value [, bool $case_insensitive = false ] )$name:常量名$value:值$case_insensitive:是否对大小写敏感,true 代表不敏感 define(“GREETING”, “欢迎访问 Runoob.com”);echo GREETING; // 输出 “欢迎访问常量默认是全局变量 字符串相关123456//字符串合并$txt .&quot;+&quot;.$txt2 //字符串长度strlen()//字符串查找，未找到返回Falsestrpos(&quot;文本&quot;,&quot;查找字符&quot;) // 返回字符串位置，从0开始 条件语句1234567891011121314151617181920212223242526272829303132&lt;?php$age = 18;$stage = array('青少年','成年','老年');if ($age &gt;=60)&#123; $title = $stage[2];&#125;elseif ($age &gt;=18)&#123; $title = $stage[1];&#125;else&#123; $title = $stage[0];&#125;echo $title,'&lt;br&gt;&lt;br&gt;';$favcolor=\"red\";switch ($favcolor)&#123;case \"red\": echo \"你喜欢的颜色是红色!\"; break;case \"blue\": echo \"你喜欢的颜色是蓝色!\"; break;case \"green\": echo \"你喜欢的颜色是绿色!\"; break;default: echo \"你喜欢的颜色不是 红, 蓝, 或绿色!\";&#125;?&gt; 循环while/do while/for /foreach while/do while123456789101112131415&lt;?php// while echo \"while &lt;br&gt;\";$x = 5;while ($x) &#123; echo $x--,'&lt;br&gt;';&#125;// do .. while echo \"do..while &lt;br&gt;\";$x = 5;do echo $x,'&lt;br&gt;';while ($x--)?&gt; 输出： 12345678910111213while54321do..while543210 for/ foreach123456789101112&lt;?phpfor ($i=1; $i&lt;=5; $i++)&#123; echo \"The number is \" . $i . \"&lt;br&gt;\";&#125;$x=array(\"one\"=&gt;1,\"two\"=&gt;2,\"three\"=&gt;3);foreach ($x as $key =&gt; $value)&#123; echo $key,\" : \",$value,\"&lt;br&gt;\";&#125;?&gt; 输出 12345678The number is 1The number is 2The number is 3The number is 4The number is 5one : 1two : 2three : 3 魔术常量12345678__LINE__: 语句所处的行号__FILE__: 文件的完整路径（含文件名）__DIR__: 文件的目录__FUNCTION__: 函数名__CLASS__: 类名__TRAIT__: Trait 名__METHOD__:类的方法名__NAMESPACE__:命名空间 1234567891011121314151617181920&lt;?phpnamespace MyProject;// 必须是在首行// 魔术常量echo &apos;这是第 &quot; &apos; . __LINE__ . &apos; &quot; 行&apos;,&apos;&lt;br&gt;&apos;;echo &apos;该文件位于 &quot; &apos; . __FILE__ . &apos; &quot; &apos;,&apos;&lt;br&gt;&apos;;echo &apos;该文件位于 &quot; &apos; . __DIR__ . &apos; &quot; &apos;,&apos;&lt;br&gt;&apos;;echo &apos;命名空间为：&quot;&apos;, __NAMESPACE__, &apos;&quot;&apos;; // 输出 &quot;MyProject&quot;class test &#123; function _print() &#123; echo &apos;类名为：&apos; . __CLASS__ . &quot;&lt;br&gt;&quot;; echo &apos;函数名为：&apos; . __FUNCTION__ .&quot;&lt;br&gt;&quot;; echo &apos;类的方法名：&apos; . __METHOD__ ; &#125;&#125;$t = new test();$t-&gt;_print();?&gt; 输出 123456这是第 &quot; 4 &quot; 行该文件位于 &quot; /Library/WebServer/Documents/a.php &quot;该文件位于 &quot; /Library/WebServer/Documents &quot;命名空间为：&quot;MyProject&quot;类名为：MyProject\\test函数名为：_print类的方法名：MyProject\\test::_print 注：PHP中的命名空间，可以解决的问题： 用户编写的代码与PHP内部的类/函数/常量名字冲突 为很长的标识符创建一个更加可读的别名 数组数组定义 自动分配id 1$cars = array(\"Volvo\",\"BMW\",\"Toyota\"); 12345$a = array( 'a',3 =&gt; 'b',1 =&gt; 'c', 'd');var_dump($a)// 输出//array(4) &#123; [0]=&gt; string(1) \"a\" [3]=&gt; string(1) \"b\" [1]=&gt; string(1) \"c\" [4]=&gt; string(1) \"d\" &#125; 关联数组 1$age = array(\"Peter\"=&gt;\"35\",\"Ben\"=&gt;\"37\",\"Joe\"=&gt;\"43\"); 遍历数组 123456&lt;?php$age = array(\"Peter\"=&gt;\"35\",\"Ben\"=&gt;\"37\",\"Joe\"=&gt;\"43\");foreach ($age as $key =&gt; $value) &#123; echo $key,' =&gt; ',$value,' type: ',var_dump($key),'&lt;br&gt;';&#125;?&gt; 数组排序 sort() &lt;–&gt; rsort()asort() &lt;–&gt; arsort() //关联数组ksort() &lt;–&gt; krsort() //关联数组 1234567891011121314151617&lt;?php$age=array(\"a\"=&gt;\"5\",\"c\"=&gt;\"37\",\"b\"=&gt;\"-1\",\"e\"=&gt;\"1\");echo \"原始数组:\";print_r($age);echo \"&lt;br&gt;\";echo \"按key 排序\";ksort($age);print_r($age);echo \"&lt;br&gt;\";echo \"按value 排序\";asort($age);print_r($age);echo \"&lt;br&gt;\";?&gt; PHP 面向对象123456789101112131415161718192021222324252627282930313233343536373839&lt;?phpclass Site &#123; /* 成员变量 */ var $url; var $title; function __construct($par1,$par2)&#123; $this-&gt;url = $par1; $this-&gt;title = $par2; &#125; function __destruct()&#123; echo __FUNCTION__.\" 已经运行\"; &#125; /* 成员函数 */ function setUrl($par)&#123; $this-&gt;url = $par; &#125; function getUrl()&#123; echo $this-&gt;url . PHP_EOL; &#125; function setTitle($par)&#123; $this-&gt;title = $par; &#125; function getTitle()&#123; echo $this-&gt;title . PHP_EOL; &#125;&#125;$siteobj = new Site('www.baidu.com','baidu');print $siteobj-&gt;url;$siteobj-&gt;setUrl('ppsteven.github.io');$siteobj-&gt;setTitle('learnPHP');$siteobj-&gt;getUrl();$siteobj-&gt;getTitle();?&gt; 函数作用域12345678910111213141516171819202122232425262728&lt;?php$y = \"globals varibale\"; //全局变量function myTest($z=null)&#123; global $y; // $y 为全局变量，有两种方式使用 echo $y,'&lt;br&gt;'; echo $GLOBALS['y'],'&lt;br&gt;'; echo '参数作用域',$z; static $x1=0; $x2 = 0; // 局部变量 echo $x1.'('.$x2.\"）\";// 静态变量是不会随着函数完成而删除 $x1++; $x2++;&#125; myTest();myTest();myTest();/*x2(x1)0(0)0(1)0(2)*/?&gt; 其他包含一些小的知识点和未系统整理的知识 三元：expr1 ? expr2 : expr3 12345678&lt;?php $var = true ? 1 : false ? 2 : 3; $varx = (true ? 1 : false)? 2 : 3; $vary = true ? 1 : (false ? 2 : 3);echo $var.'&lt;br&gt;';echo $varx.'&lt;br&gt;';echo $vary.'&lt;br&gt;';// 结果是 2 2 1 , 这里的三元运算需要注意执行的顺序 null == false : 返回的是false 1/2 (0.5) PHP中没有整除算法，有整除函数intdiv(1/2) php 作用域 local global static parameter // 参数作用域 1234567891011121314&lt;?phpfunction myTest()&#123; static $x=0; echo $x; $x++; echo PHP_EOL; // 换行符&#125;// 这里的 static 使得$x 的值会一直累加myTest(); // 0 myTest(); // 1myTest(); // 2?&gt; echo PHP_EOL; // 换行符 == 弱比较=== 强比较","categories":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/tags/php/"},{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"git cheetsheet","slug":"git-cheetsheet","date":"2019-11-14T11:20:00.000Z","updated":"2020-02-15T18:09:58.285Z","comments":true,"path":"2019/11/14/git-cheetsheet/","link":"","permalink":"http://ppsteven.github.io/2019/11/14/git-cheetsheet/","excerpt":"cheetsheet入门级别的git 基础操作，仅仅收录理解了的，常用的命令。负责的命令，在附录的大全里面可以找到 git configGit 有三层的配置文件 仓库级的配置文件：在仓库的 .git/config 目录下，只对本仓库有效 全局级的配置文件：Mac在 ~/.gitconfig 目录 系统级的配置文件：在Git 的 安装目录下 (经过查找，我的目录为/usr/local/Cellar/git/2.23.0_1/.bottle/etc)","text":"cheetsheet入门级别的git 基础操作，仅仅收录理解了的，常用的命令。负责的命令，在附录的大全里面可以找到 git configGit 有三层的配置文件 仓库级的配置文件：在仓库的 .git/config 目录下，只对本仓库有效 全局级的配置文件：Mac在 ~/.gitconfig 目录 系统级的配置文件：在Git 的 安装目录下 (经过查找，我的目录为/usr/local/Cellar/git/2.23.0_1/.bottle/etc) 12345678910111213141516171819# --local: 仓库级 , --glocal: 全局级 , --system: 系统级# 添加配置$ git config --global user.name \"Name\" # 添加用户名 --global 代表配置的全局的参数$ git config --global user.email \"email@example.com\" # 添加邮箱# 查看配置$ git config --list/ -l # 查看全部git配置$ git config --get user.name/user.email # 查看单个配置# 删除配置$ git config --unset user.name# 编辑配置$ git config -e --global# 添加别名，对于一些比较长的别名，可以简化# 也可以通过git config $ git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit\"$ git config --global alias.graph \"log --graph --oneline\" git init12$ git init # 创建空的git代码库$ git init Myfolder # 创建文件夹Myfolder，并创建git代码库 文件（增删改提）git add 增123456789101112131415# 把指定的文件添加到暂存区中$ git add &lt;文件路径&gt;# 添加所有修改、已删除的文件到暂存区中$ git add -u [&lt;文件路径&gt;]$ git add --update [&lt;文件路径&gt;]# 添加所有修改、已删除、新增的文件到暂存区中，省略 &lt;文件路径&gt; 即为当前目录$ git add -A [&lt;文件路径&gt;]$ git add --all [&lt;文件路径&gt;]$ git add . # 当前目录（递归子目录）# 查看所有修改、已删除但没有提交的文件，进入一个子命令系统$ git add -i [&lt;文件路径&gt;]$ git add --interactive [&lt;文件路径&gt;] git commit 提交123456789101112131415# 把暂存区中的文件提交到本地仓库，调用文本编辑器输入该次提交的描述信息$ git commit# 把暂存区中的文件提交到本地仓库中并添加描述信息$ git commit -m \"&lt;提交的描述信息&gt;\"# 把所有修改、已删除的文件提交到本地仓库中# 不包括未被版本库跟踪的文件，等同于先调用了 \"git add -u\"$ git commit -a -m \"&lt;提交的描述信息&gt;\"# 修改上次提交的描述信息$ git commit --amend -m \"desc\"# 拿372a* 提交的信息（作者、提交者、注释、时间戳等）来提交当前修改$ git commit -c 372a git reset 还原12345678910111213141516# 重置暂存区，但文件不受影响# 相当于将用 \"git add\" 命令更新到暂存区的内容撤出暂存区，可以指定文件# 没有指定 commit ID 则默认为当前 HEAD# 丢弃暂存区中的所有文件的修改（工作区不受影响）$ git reset $ git reset --mixed $ git reset &lt;文件路径,commit ID&gt;$ git reset --mixed &lt;文件路径,commit ID&gt;$ git reset --hard HEAD^ # 回到上一个版本（HEAD: 当前版本，HEAD^: 上一个版本，HEAD~100: 往上100个版本）$ git reset --hard 1234567 # 回到指定版本号commit id（此处：commit id 假设为1234567******，Git会根据commit id的前几位自动寻找对应的版本）$ git reset --soft HEAD~ # hard 和 soft 的区别在与 soft（暂存区和工作区中的所有文件的修改都不丢弃）$ git reset --merge &lt;commit&gt; // 在被污染的工作区中回滚merge或者$ git reflog # 查看命令历史 git revert 反做12# 生成一个新的提交来撤销某次提交，此次提交之前的所有提交都会被保留。$ git revert &lt;commit ID&gt; 比较一下 git revert 和 git reset 的区别： git reset是把HEAD向后移动来删除提交，而git revert是用一次新的提交来回滚之前的提交（HEAD会继续前进）。下面一幅图比较形象生动。 关于git 的版本回退的问题，廖雪峰的博客：时光穿梭机已经讲的很好了，我们可以通过git log 查看“当前”版本库的状态，但是如何查看“未来”的版本库呢？可以通过git reflog 查看。 git remove 删除1234$ git rm &lt;文件路径&gt; # 删除工作区文件，若文件在工作区或缓存区中有修改，会失败。有两种解决方式：1、强制删除 2、只删除暂存区的文件$ git rm -f &lt;文件路径&gt; # 1.无论有没有在工作区或暂存区修改，强制删除$ git rm --cached &lt;文件路径&gt; # 2.移除暂存区的文件，在本地仓库的文件夹中保留该文件$ git rm -r &lt;文件夹路径&gt; # 移除文件夹 git diff12345678910111213141516171819# 比较当前文件和暂存区中文件的差异，显示没有暂存起来的更改$ git diff# 比较暂存区中的文件和上次提交时的差异$ git diff --cached$ git diff --staged# 比较当前文件和上次提交时的差异$ git diff HEAD# 查看从指定的版本之后改动的内容$ git diff &lt;commit ID&gt;# 比较两个分支之间的差异$ git diff &lt;分支名称&gt; &lt;分支名称&gt;# 查看两个分支分开后各自的改动内容$ git diff &lt;分支名称&gt;...&lt;分支名称&gt;# 可以使用 Beyond Compare4 软件 * git checkout 恢复12345678910# 当在暂存区中有修改时，使用暂存区中的修改覆盖工作区中的 &lt;文件路径&gt;# 当不在暂存区中时，使用本地版本库中的HEAD指针处的修改覆盖工作区中的&lt;文件路径&gt;$ git checkout -- &lt;文件路径&gt;# 用本地版本库中 HEAD处提交的文件，覆盖 暂存区和工作区的文件$ git checkout HEAD &lt;文件路径&gt;# 用本地版本库中 93ef处提交的文件，覆盖 暂存区和工作区的文件$ git checkout 93ef &lt;文件路径&gt;# 替换掉本地的改动，新增的文件和已经添加到暂存区的内容不受影响$ git checkout &lt;文件路径&gt; 恢复文件举例 a 文件被修改过，checkout 去除修改 123456789$ cat a Hello worldorphan`$ git checkout aUpdated 1 path from the index$ cat aHello worldadd a line git 日志与文件状态git status 状态12345678910# 查看当前所处的分支暂存区和工作区的文件（会显示当前所处分支）# 注1：处于暂存区的文件状态:：staged(已暂存)；处于工作区的文件状态:：untrack(未跟踪)、modified(已修改)# 注2：工作区中的空目录不会被git追踪$ git status$ git status &lt;branch name&gt;# 以简短模式查看暂存区和工作区的文件# 会显示两列，第一列是文件的状态，第二列是对应的文件# 文件状态：A 新增，M 修改，D 删除，?? 未添加到Git中$ git status -s git log 日志12345678910111213141516171819202122# 打印所有的提交记录$ git log# 打印从第一次提交到指定的提交的记录$ git log &lt;commit ID&gt;$ git log -- &lt;文件&gt;# 打印指定数量的最新提交的记录$ git log -&lt;指定的数量&gt;# 高级功能# 记不住可以设置别名$ git log -p &lt;文件&gt; # 显示出每次修改的内容$ --graph # 图形化的方式显示$ --graph --oneline # 图形化简洁模式$ --graph --oneline --name-only # 图像化简洁模式（只显示文件名清单）$ --author = leon # 限定作者leon$ --grep = \"test\" # 限定注释$ --since=\"2018-10-7\" --until='2019-10-12'# since,until 标记对和 after，before 标记对是等价的$ --after=\"2018-10-7\" --before='2018-10-12'$ --since=2.weeks # 最近2周的提交记录 git show 显示修改1234567# 统计各个提交者的次数$ git shortlog -sn # 显示修改内容(详细)$ git show 3a6c$ git show HEAD# 显示最近一次提交的修改内容（不显示具体的修改内容）$ git show --name-only HEAD 分支管理git branch1234567891011121314151617181920212223242526272829303132# 列出本地的所有分支，当前所在分支以 \"*\" 标出$ git branch# 列出本地的所有分支并显示最后一次提交，当前所在分支以 \"*\" 标出$ git branch -v$ git branch -r # 列出所有远程分支 cache$ git branch -a # 列出所有本地分支和远程分支cache$ git branch -av # 列出所有本地分支和远程分支cache（含简单说明）$ git branch -vv # 查看本地分支和远程分支cache的追踪关系# 创建新分支，新的分支基于上一次提交建立$ git branch &lt;分支名&gt;# 修改分支名称# 如果不指定原分支名称则为当前所在分支$ git branch -m [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 强制修改分支名称$ git branch -M [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 删除指定的本地分支# 删除的时候需要从被删除的分区切换出去$ git branch -d &lt;分支名称&gt;# 强制删除指定的本地分支$ git branch -D &lt;分支名称&gt;# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream hexo origin:hexo ??# 如果在本地新建了分支，远程没有分支的情况$ git branch --set-upstream origin master # 建立联系$ git branch -vv # 查看本地和远程的追踪关系 git checkout 分支切换123456# git 提交流程 工作区-&gt; 暂存区 -&gt; 版本库$ git checkout &lt;分支名称&gt; # 切换分支$ git checkout -- &lt;file&gt; # 撤销修改：1. 文件在添加到缓存区前修改，则回退到原工作区状态；2. 文件在添加到缓存区后修改，则回退到原缓存区状态。也即是将&lt;file&gt;撤回到最近一次git add或git commit状态（注：--表示在当前分支，如果没有，则切换到另一个分支）$ git checkout -b &lt;分支名称&gt; # 创建并切换$ git checkout --orphan &lt;分支名称&gt;# 创建并切换到指定的分支，删除所有的提交记录$ git checkout -# 切换到上一次分支 git merge/rebase 分支合并 12345678# 把指定的分支合并到当前所在的分支下$ git merge &lt;分支名称&gt; # 无冲突时会直接提交$ git merge --no-commit &lt;分支名称&gt; # 不自动提交$ git merge --no-ff -m \"merge with no-ff\" &lt;name&gt; # 合并后的分支有历史记录，而Fast-Forward合并之后，分支没有历史记录# Fast-Forwar 的合并的方法是指针的移动。$ git rebase &lt;分支名称&gt; # rebase 能保持清晰的提交记录，但是合并的操作没有记录下来（merge 则是会新建一个提交） 远程操作git clone 克隆12345678910111213141516# 克隆文件# Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快，https 每次推送都必须输入口令。git clone https://github.com/XXX/learngit.git Yourfilepath # httpsgit clone git@github.com:XXX/learngit.git ./lesson01 # ssh（推荐）# 默认在当前目录下创建和版本库名相同的文件夹并下载版本到该文件夹下$ git clone &lt;远程仓库的网址&gt;# 指定本地仓库的目录$ git clone &lt;远程仓库的网址&gt; &lt;本地目录&gt;# -b 指定要克隆的分支，默认是master分支$ git clone -b &lt;分支名称&gt; &lt;远程仓库的网址&gt; &lt;本地目录&gt;# -o 设置远程仓库为origin$ git clone -o &lt;orgin name&gt; https://github.com/kekec/Test.git git remote1234567891011121314151617181920212223242526272829303132333435363738# 列出已经存在的远程仓库$ git remoteorigin # 列出远程仓库的详细信息，在别名后面列出URL地址$ git remote -v$ git remote --verboseorigin https://github.com/kekec/Test.git (fetch)origin https://github.com/kekec/Test.git (push)# 添加远程仓库$ git remote add &lt;远程仓库的别名&gt; &lt;远程仓库的URL地址&gt;# 修改远程仓库的别名$ git remote rename &lt;原远程仓库的别名&gt; &lt;新的别名&gt;# 删除指定名称的远程仓库$ git remote remove/rm &lt;远程仓库的别名&gt;# 修改/显示远程仓库的 URL 地址$ git remote set-url &lt;远程仓库的别名&gt; &lt;新的远程仓库URL地址&gt;$ git remoter get-url &lt;远程仓库的别名&gt;# 显示远程仓库的信息（举例）$ git remote show origin * remote origin Fetch URL: https://github.com/kekec/Test.git Push URL: https://github.com/kekec/Test.git HEAD branch: master Remote branches: master tracked v3.1 trackedLocal branch configured for 'git pull': master merges with remote masterLocal refs configured for 'git push': master pushes to master (fast-forwardable) v3.1 pushes to v3.1 (up to date)# 可以查看 git pull 和 git push 的具体信息 git fetch 从远程仓库获取最新的版本到本地分支上 12345# 将远程仓库所有分支的最新版本全部取回到本地$ git fetch origin# 将远程仓库指定分支的最新版本取回到本地$ git fetch orgin master/dev * git pull git pull &lt;远程仓库名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 从远程仓库获取最新版本并合并到本地。首先会执行 git fetch，然后执行 git merge，把获取的分支的 HEAD 合并到当前分支。 1234# 先执行fetch，然后将远程origin/master分支merge合并到当前分支（最后会更新origin/master, origin/HEAD指针到最新提交）$ git pull origin master$ git pull -r origin master # 先执行fetch，然后将远程origin/master分支rebase合并到master分支$ git pull origin master:dev # 先执行fetch，然后将远程origin/master 分支merge合并到本地dev分支 * git push 把本地仓库的提交推送到远程仓库。 git push &lt;远程仓库的别名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 1234567891011# 将本地仓库的修改push到origin所指向的远程仓库URL的master分支上，并在.git/config文件中记录当前分支与远程分支master的对应关系$ git push -u origin master # -u 在第一次push的时候使用即可$ git push origin -f # 当合入对应的远端仓库有冲突的时候，使用当前分支更新$ git push origin --all # 推送本地的所有的分支到各自的远端分支# 删除指定的远程仓库的分支$ git push &lt;远程仓库的别名&gt; :&lt;远程分支名&gt;$ git push &lt;远程仓库的别名&gt; --delete/-d &lt;远程分支名&gt;$ git push origin:dev # 删除远端分支 dev$ git push origin -d dev # 效果同上 存储文件的区块贮藏区 git stash123456789101112131415161718$ git stash # 将工作区中所有文件的修改备份压栈到储藏区，然后丢弃工作区与暂存区的所有文件的修改。# 经过试验，git stash 会丢弃已有文件的修改的，不会删除新建的文件。$ git stash pop # 恢复工作区，并将贮藏区的备份删除$ git stash list # 查看贮藏区stash@&#123;0&#125;: WIP on master: 30e5191 add a$ git stash show -p stash@&#123;0&#125; # 查看栈顶文件的修改diff --git a/a b/aindex 11817a2..399e9b0 100644--- a/a+++ b/a@@ -1,3 +1,4 @@ Hello world add a line+add a line$ git stash drop # 直接移除储藏区的栈顶处备份（不用于恢复当前分支的工作区）$ git stash clear # 清除储藏区栈列表$ git stash apply stash@&#123;0&#125; # 使用stash@&#123;0&#125;来恢复当前分支的工作区，但不移除储藏区中任何备份 工作区 git clean12$ git clean -nd # 探测工作区中有哪些未追踪状态的文件和目录$ git clean -fd # 删除工作区中未追踪状态的文件和目录 暂存区 git ls-files1234$ git ls-files # 查询暂存区中的文件列表（递归子目录）# 下面是抄的$ git ls-files -s // 查看暂存区中所有文件的blob数据块信息$ git ls-files -s -- README.md // 查看暂存区中的README.md文件的blob数据块信息 打包 git archive12# 将当前master分支所有文件使用zip压缩方式打包到d:/file.zip$ git archive --format zip --output ./file.zip master 团队合作分支 TO DO LIST 看完教程git 教程 补充 参考资料 廖雪峰git教程 Git原理与命令大全 Git命令大全","categories":[{"name":"cheetsheet","slug":"cheetsheet","permalink":"http://ppsteven.github.io/categories/cheetsheet/"}],"tags":[{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"},{"name":"cheetsheet","slug":"cheetsheet","permalink":"http://ppsteven.github.io/tags/cheetsheet/"}]},{"title":"Pine Script 学习笔记(二)——基本特点","slug":"Pine Script 学习笔记(二)","date":"2019-11-04T13:45:13.000Z","updated":"2020-02-15T18:07:54.202Z","comments":false,"path":"2019/11/04/Pine Script 学习笔记(二)/","link":"","permalink":"http://ppsteven.github.io/2019/11/04/Pine%20Script%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/","excerpt":"前言这是Pine Script 学习笔记的第二篇，简单挑教程上重要的记录了一下。","text":"前言这是Pine Script 学习笔记的第二篇，简单挑教程上重要的记录了一下。 Context switching and the security functionsecurity 函数可以用于按照特定要求请求数据 1234//@version=4study(&quot;Example security 1&quot;, overlay=true)ibm_15 = security(&quot;NYSE:IBM&quot;, &quot;15&quot;, close)plot(ibm_15) 1security(symbol, resolution, expression, gaps, lookahead) symbol (string) 商品代码。 商品代码可以包含数据提供商信息，也可以不含 如 “NYSE:IBM”,”BATS:IBM”,”IBM”(如不提供，默认使用BATS) syminfo.ticker and syminfo.tickerid是表示当前图标上的商品代码，syminfo.ticker是不含数据供应商信息，syminfo.tickerid是包含供应商信息。Pine教程建议使用后者，为了避免数据的模糊性 resolution (string) 分辨率/ timeframe时间周期 分钟级：1，5，10，21，60，120，等等 日级: D,1D,2D 等等 周级：W，1W，2W 月级：M，1M，2M timeframe.period 记录当前图标时间周期 expression (series) 计数并从 security调用返回的表达式。 如果仅仅是获取收盘价数据，我们可以用security(&#39;EURUSD&#39;,&#39;D&#39;,close) 但是，expression能给我们提供更加丰富的操作，比如，我们需要知道，EURUSD相对于GBPUSD 上涨的幅度 1234567//@version=4study(title = &quot;Advance Decline Ratio&quot;, shorttitle=&quot;ADR&quot;)ratio(t1, t2, source) =&gt; s1 = security(t1, timeframe.period, source) s2 = security(t2, timeframe.period, source) s1 / s2plot(ratio(&quot;GBPUSD&quot;, &quot;EURUSD&quot;, close-open)) 如上图所以，GBPUSD上涨幅度/EURUSD 的上涨幅度我们可以很轻松的通过7行代码实现。在绝大多数情况下，两者是同比例变动，但是在某些特等情况下，变化是相反的。这对于研究这两种货币对的走势关系有很大的帮助。 在security数据应用到当前图表上的时候，有两个控制，一个是gaps，另一个是lookahead gaps (const bool) 默认值为barmerge.gaps_off。可以理解为数据平滑的操作，因为数据中会存在空值（na），在gaps_off的情况下，na会被离它最近的非空值所替代，也就不会出现间隔（gap）的情况 lookahead (const bool) 默认值为barmerge.lookahead_off。 合并所请求数据位置的策略。 请求的条形图与当前的条形图按照k线开盘时间合并。 这种合并策略可能导致从“未来”获取数据计算历史的不良影响。 这在回溯测试策略中不被接受，但在指标中可使用。 123456//@version=4study(&apos;My Script&apos;, overlay=true)a = security(syminfo.tickerid, &apos;60&apos;, low, lookahead=barmerge.lookahead_off)plot(a, color=color.red)b = security(syminfo.tickerid, &apos;60&apos;, low, lookahead=barmerge.lookahead_on)plot(b, color=color.lime) 红色是lookahead_off，绿色是lookahead_on。 我们发现开启了lookahead功能后，所产生的最低价是整个时间段的最低价，而原先是开盘K点的最低价。 bar state.* 变量 barstate.isfirst 当前k线为k线组的第一条k线 barstate.islast 当前k线为k线组的最后一条k线 barstate.ishistory 当前k线为历史k线 batstate.isrealtime 当前k线为实时k线 barstate.isnew 新K线的第一次更新 batstate.isconfirmed =当前k线的最后(关闭)更新 不建议在security表达式中使用barstate.isconfirmed 所有的历史柱线都曾被认为是新的柱线，因为脚本是依次执行的。当柱线第一更开盘价生成的时候，认为此柱线是新的。 会话和时间信息Pine 提供方法来生成 交易区间，时间和日期的信息。 time(变量): 返回的是时间戳格式 time(函数)：time(resolution, session) → series 返回的是按照session 格式返回的时间，如果不在session时间段的话便会返回na值 1234//@version=4study(&quot;Time&quot;, overlay=true)t1 = time(timeframe.period, &quot;0000-0000&quot;)bgcolor(t1 ? color.blue : na) session = “0000-0000:23456” 即24h，去除周六日，运行结果如下 可以看到，周一至周五背景都变成了蓝色，因为t1 不在session的范围内的时候返回na值 交易区间的格式有 0000-0000:1234567 24小时交易，时间从午夜0点开始 0000-0000:23456 工作日24小时交易 1700-1700：24小时交易，时间从17点开始 0930-1700:146 交易时间为09:30~17:00，交易时间在周日（1），周三（4），周五（6） 24x7 等价于 0000-0000:1234567 1234567// 判断是否为30min的新柱线//@version=4study(&quot;new 30 min bar&quot;)is_newbar(res) =&gt; t = time(res) not na(t) and (na(t[1]) or t &gt; t[1])plot(is_newbar(&quot;30&quot;) ? 1 : 0) 用到的函数变量和类型 time：UNIX格式的当前k线时间 timenow：UNIX格式的当前时间 syminfo.timezone：时区 当前K线用到的变量 year/month/weekofyear dayofmonth dayofweek（sunday,monday 等） hour/minute/second 创建时间 timestamp(year, month, day, hour, minute) 策略编写backtesting &amp; forwardtestingstrategy脚本是可以产生交易订单的Pine 脚本。利用strategy 可以做策略回测（backtesting）和 模拟交易（forwardtesting） 无论backtesting 还是forwardtesting，计算都是默认发生在K线收盘的时候，但是在forwardtesting 的时候，可以选择在每一个tick发生的时候，都运行一次。 做法一是调整strategy的 Setting/Properties，或者修改代码，添加strategy(... ,calc_on_every_tick=true ) ，此外还可以选择在每笔订单完成之后计算strategy(... , calc_on_order_fills=true) 经纪商模拟仅仅只有OHLC数据的话，K线内数据的生成有一套逻辑，如果最高价更接近开盘价，生成顺序是 open-&gt;high-&gt;low-&gt;close，此外还假设价格是没有gaps的 订单生成命令strategy.entry 订单生成函数这是进入市场的命令。 如果具有相同ID的订单已经挂起，则可修改订单。 如果没有指定ID的订单，则会发出新的订单。 要取消/停用预挂单，应使用命令strategy.cancel或strategy.cancel_all。 与函数strategy.order相比，strategy.entry功能受金字塔影响，可以正确反转市场位置。 如果“Limit”和“stop”参数均为“NaN”，则订单类型为市场订单。 1strategy.entry(id, long, qty, limit, stop, oca_name, oca_type, comment, when) → void strategy.exit 订单退出函数1strategy.exit(id, from_entry, qty, qty_percent, profit, limit, loss, stop, trail_price, trail_points, trail_offset, oca_name, comment, when) → void 这是一个退出指定进场或整个市场地位的命令，重点区分它和strategy.close 的不同 id(string): 订单的标识符。 from_entry(string): 这里填入要平仓的订单的标识符，默认为空。 qty: 平仓手数(弄清楚合约的大小) qty_percent: 平台的比例 profit: 获利点数(一定搞清楚单位是点还是步) limit: 与profit 相似，limit约定获利的价格 loss:止损点数 stop:与loss 相似，stop约定止损的价格 tail.*: 指明跟踪指数 strategy.order这条命令可以生成开仓也可以生成平仓命令，但是它不受金字塔影响。它的作用就是弥补strategy.entry 和 strategy.exit 函数的不灵活星。 实例下面是几个例子，可以帮助我们理解strategy函数 例1123456//@version=4strategy(&quot;revers demo&quot;)if bar_index &gt; 4000 strategy.entry(&quot;buy&quot;, strategy.long, 4, when=strategy.position_size &lt;= 0) strategy.entry(&quot;sell&quot;, strategy.short, 6, when=strategy.position_size &gt; 0)plot(strategy.equity) 当仓位为空头或者无头寸的话，买4。当仓位为多头的话，卖6。 我们可以看到entry中buy 或sell 在交易的时候，会自动平仓，平掉反向的仓位。仓位在+4 –&gt; -6 变化。 例21234567//@version=4strategy(&quot;Partial exit demo&quot;)if bar_index &gt; 6500 and bar_index &lt;6550 strategy.entry(&quot;buy&quot;, strategy.long, 40000, when=strategy.position_size &lt;= 0)strategy.exit(&quot;bracket1&quot;, &quot;buy&quot;, 20000, profit = 3000,loss = 3000)strategy.exit(&quot;bracket2&quot;, &quot;buy&quot;, profit=2000, loss=2000)plot(strategy.equity) 盈亏曲线 交易逻辑 buy：当空仓时候买入，40000笔合约（40000美金） bracket1：设定平仓对象为buy标识的交易，平仓2000美金，止盈300点（单位为步，3000步=300点）。止损300点 bracket2：止盈止损200点 下面结合交易清单具体分析 1：空仓买入4000美金 2：止损200点，亏损20000 * 200 * 0.0001 = $ 400，从图中可以看到是bracket2 先止损 3：价格继续向下，亏损300点，bracket1策略触发，亏损$ 600 4,5,6:同上逻辑 风险管理strategy.risk.* 一系列函数，可以帮助进行风险管理。当风险管理规则被激活的时候，没有订单会生成。 123456//@version=4strategy(&quot;multi risk demo&quot;, overlay=true, pyramiding=10, calc_on_order_fills = true)if year &gt; 2014 strategy.entry(&quot;LE&quot;, strategy.long)strategy.risk.max_intraday_filled_orders(5)strategy.risk.max_intraday_filled_orders(2) strategy.risk.max_intraday_filled_orders(2) 限制一天成交的最大的交易单数，一旦达到，所有未成交订单全部取消，成交订单关闭。并且一直关闭交易直到本交易日结束。 上图中，当第二笔交易生成的时候，同时也是两笔交易关闭的时间。 其余的函数参考手册 指标重绘历史数据仅仅包含OHLC，不包含线内的运动。这会导致的问题是，历史数据上的回测和实时数据不一致的情况。 另外一个担心是，未来函数的使用。这里尤其要关注security 函数，此函数可能会错误的引入未来的信息。 绘图Pine V4 中存在两种绘图类型：label 和 line。 注：用户的绘图和 编程绘图是不一样的，编程得到的绘图是不能用鼠标修改的。 和指标绘图函数(plot,plotshape,plotchar) 不一样的是，绘图函数可以在图表右侧没有K线的地方。 label1label.new(x, y, text, xloc, yloc, color, style, textcolor, size) → series[label] 1234//@version=4study(&quot;My Script&quot;, overlay=true)label.new(bar_index, high, style=label.style_none, text=&quot;x=&quot; + tostring(bar_index) + &quot;\\ny=&quot; + tostring(high)) x的位置是用bar_index 标识的，此时xloc 的默认值为xloc.barindex y的位置是最高价 xloc取值：xloc.bar_index(默认) 和 xloc.bar_time yloc取值： yloc.price 传入此函数，需要输入y值 yloc.abovebar,yloc.belowbar 启动时，y值会失效。标签在图表上部或者下部 style: 很多种，可能用到比较多的有label.style_none，无底色 label.set_* 一系列函数可以用来对对象进一步的修改。 line1line.new(x1, y1, x2, y2, xloc, extend, color, style, width) → series[line] extend: extend.none/extend.right/extend.left","categories":[{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/"},{"name":"Pine","slug":"量化/Pine","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/Pine/"}],"tags":[{"name":"Pine","slug":"Pine","permalink":"http://ppsteven.github.io/tags/Pine/"},{"name":"TradingView","slug":"TradingView","permalink":"http://ppsteven.github.io/tags/TradingView/"},{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/tags/%E9%87%8F%E5%8C%96/"}]},{"title":"Pine Script 学习笔记","slug":"Pine Script 学习笔记","date":"2019-10-31T14:03:08.000Z","updated":"2020-02-15T18:08:45.074Z","comments":false,"path":"2019/10/31/Pine Script 学习笔记/","link":"","permalink":"http://ppsteven.github.io/2019/10/31/Pine%20Script%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"Pine Script 学习笔记——基础语法篇（一）简介量化交易平台 TrendingView 是一个支持多种资产的投资平台，很多人在上面分享对于股票，外汇，数据货币等资产的投资观点，难得的是在上面能找到很多人的交易策略。 TrendingView 使用的是自己开发的Pine 语言作为脚本，这一点和MT4 开发的mql4 很像。用户可以自己编写脚本和策略，并与其他人分享。Pine 直观给我的印象比Mql4 更加简单，更加关注于策略本身，而不是编程技巧。 此外，Pine语言编辑器没有那么强大的debug 功能，这对于一开始上手练习来说，不是那么方便。不过它一直在更新，发展的很快。 TrendingView 对接了很多经纪商，使得它支持的交易品种很丰富，而且它的图表功能很强大。 下面记录一下自己学习Pine 脚本的一些基础的笔记，权当备忘。主要内容都参考自Pine 的脚本文档","text":"Pine Script 学习笔记——基础语法篇（一）简介量化交易平台 TrendingView 是一个支持多种资产的投资平台，很多人在上面分享对于股票，外汇，数据货币等资产的投资观点，难得的是在上面能找到很多人的交易策略。 TrendingView 使用的是自己开发的Pine 语言作为脚本，这一点和MT4 开发的mql4 很像。用户可以自己编写脚本和策略，并与其他人分享。Pine 直观给我的印象比Mql4 更加简单，更加关注于策略本身，而不是编程技巧。 此外，Pine语言编辑器没有那么强大的debug 功能，这对于一开始上手练习来说，不是那么方便。不过它一直在更新，发展的很快。 TrendingView 对接了很多经纪商，使得它支持的交易品种很丰富，而且它的图表功能很强大。 下面记录一下自己学习Pine 脚本的一些基础的笔记，权当备忘。主要内容都参考自Pine 的脚本文档 脚本结构指明用的Pine 脚本版本 1//@version=4 Pine 可以分为study脚本 和 strategy 脚本（指标&amp;策略）study 脚本必须包含 plot,plotshape,barcolor,line.new 等输出strategy 脚本包含 strategy.* 即交易函数 换行 Line wrapping1234567891011//例子1 换行需要空格a = open+ high+ low// 例子2 换行中不能有注释a = open+ high // 此处加注释会出问题// 例子3 函数内换行，空行必须要超过一个Tab（或者4个空格）label.new(bar_index, na, yloc=yloc.abovebar, text=t, color=hist ? color.green : color.red)// 这里空格必须超过4个 运算符 算术： + - * / % 1/2 = 01/2.0 = 0.5 比较: == != 逻辑: not and or 三元运算符： condition ? result1 : result2 iff(condition, result1, result2) 1有房？嫁:有车？: 嫁:帅？嫁: 不嫁 [] 运算符(History reference operator)close 代表最新的价格，close[1]代表了历史价格。 1close = close[0] //显示的是最新的收盘价 除此之外，Pine脚本里面还有一个变量 bar_index，记录着bar的数目，编号自左向右，从0开始。bar_index = (bar数量)N-1。 为什么运行close[bar_index-1] ≠ close[0] ?而close[bar_index-1] 会出错 函数Pine 脚本中包含了大量的自建函数，用户还可以自定义函数、 单行函数 1f(x,y) =&gt; x+y Pine Script 的函数不支持递归 即，不允许在函数中再次调用自己本身 多行函数 1234geom_average(x, y) =&gt; a = x*x b = y*y sqrt(a + b) Pine Script 需要（一个Tab 或者4空格，TrendingView 会自动用4个空格来替换掉Tab）来划定函数的范围 最后一行的表达式或 变量作为函数的输出结果 输出&gt;=2 123456fun(x,y) =&gt; a = x+y b = x-y retrun [a,b]// 调用函数[a,b] =fun(3,2) 函数的注意事项当在函数块中使用函数或者历史数据信息的时候要注意。因为所使用的历史信息是每一次连续调用生成的。 如果函数并不是在每一根柱线上都调用，那么数据生成就会出现错误。 例1 123456// 定义两个函数f1,f2f1(a) =&gt; a[1]f2() =&gt; close[1]// 说明下列用法的实际意义f1(close) 等价于 close[2]f2() 等价于 close[1] f1 传入的close 序列，需要在第一次调用后才能生成，所以f1 的 价格信息实际上比f2 晚一天 变量声明&amp;语句statementvar Pine 语言中变量定义的方式有两种： = 和 var 12345a = 1 // a为整形float a = 1 // a为浮点型var a = 0var int a = 0b = na //出错 变量定义的时候，需要指明变量的类型(或者 等式右侧表达式能指明类型亦可) na 没有特定的类型，所以赋值时会出错 var 关键词 var 是用于分配和一次性初始化变量的关键词。 不含var 关键词的变量在每次数据更新的时候都会覆盖变量的值。使用了var 关键词的变量，在数据更新中，可以“保持状态”。举例 12345678910111213141516//@version=4study(&quot;Var keyword example&quot;)var a = closevar b = 0.0var c = 0.0var green_bars_count = 0if close &gt; open var x = close b := x green_bars_count := green_bars_count + 1 if green_bars_count &gt;= 10 var y = close c := yplot(a)plot(b)plot(c) 变量 ‘a’ 保持系列中每个柱线的第一根柱线的收盘价。 变量 ‘b’保持系列中第一个“绿色”价格棒的收盘价。 变量 ‘c’保持系列中第十个“绿色”条的收盘价。 即a,b,c 都是一个常数。 去除var 的话，a,b,c 会随着价格变化而变化 if 语句 12345678910// This code compilesx = if close &gt; open closeelse open// This code doesn&apos;t compilex = if close &gt; open closeelse &quot;open&quot; 需要注意的是，与python不同，Pine要求，then 和 else语句返回的值的类型是相同的。在上面的第二个例子中，close 和 “open” 一个是float Series，另一个是string，不同类型的话，编译会出错。 1234 x = if close &gt; open close// If current close &gt; current open, then x = close.// Otherwise the x = na. if 语句中可以忽略else，但是系统会默认赋值（na,false,””） for 语句12for i = 1 to length-1 sum := sum + price[i] 执行模型Pine代码是根据价格信息计算的。但是价格信息并不是完整加载的，用户可以一直向左滑动图表，直到最早的一根柱子（Pro 用户可以在图表上加载10000左右，免费用户可以加载5000根柱子） 实时数据的计算Pine指标计算实时数据的时候和计算历史数据略有不同，因为实时数据会有addtional commit(?)和rollback action(?) 在实时数据的处理过程中，柱线的每一次变动都会引起Pine 指标的计算 rollback : 在每一根柱线更新时发生 commit : 在每一根柱线关闭时发生 对于判断柱线的状态，Pine中有一系列的自建函数 barstate.* 来显示当前柱线的状态。","categories":[{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/"},{"name":"Pine","slug":"量化/Pine","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/Pine/"}],"tags":[{"name":"Pine","slug":"Pine","permalink":"http://ppsteven.github.io/tags/Pine/"},{"name":"TradingView","slug":"TradingView","permalink":"http://ppsteven.github.io/tags/TradingView/"},{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/tags/%E9%87%8F%E5%8C%96/"}]},{"title":"Hexo 博客搭建:个性篇","slug":"hexo-blog-build-advanced","date":"2019-10-27T13:46:00.000Z","updated":"2020-01-21T09:09:01.089Z","comments":true,"path":"2019/10/27/hexo-blog-build-advanced/","link":"","permalink":"http://ppsteven.github.io/2019/10/27/hexo-blog-build-advanced/","excerpt":"通过上一篇文章，我们已经搭建好了一个博客的基本功能，已经可以开始编写博客了。下面我们简单写一点Hexo的美化配置","text":"通过上一篇文章，我们已经搭建好了一个博客的基本功能，已经可以开始编写博客了。下面我们简单写一点Hexo的美化配置 文章页个性配置主题目录下的 themes\\next_config.yml 文件负责与主题相关的配置，用户可以通过修改该文件来自定义与主题相关的内容或功能，修改后刷新浏览器即可即时生效。 目录导航设置基础配置themes\\next\\_config.yml 123456789# Table Of Contents in the Sidebartoc: enable: true # Automatically add list number to toc. number: true # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false 展开/隐藏目录层级默认情况下，next 的目录是多级折叠的，阅读时只会展开当前目录分支。我们希望目录完全展开，同时为了避免长目录结构，约定只展开到三级目录。三级以下的目录会被隐藏，只有当文章阅读到的时候才会展开。 themes\\next\\source\\css_custom\\custom.styl 1234//TOC目录默认展开三级，这里是指Markdown标签的h3.post-toc .nav .nav-level-2&gt;.nav-child &#123; display: block;&#125; 若是希望三级以下的目录完全被隐藏 1234//TOC目录默认只显示两级目录.nav-level-2 &gt; .nav-child &#123; display: none !important;&#125; 美化字体美化在 Google Fonts 上找到心仪的字体，然后在主题配置文件中为不同的应用场景配置字体，我们这里直接使用别人配置好的字体：别人的字体 12345678910111213141516171819202122232425262728293031# themes\\next\\_config.ymlfont: enable: true # 外链字体库地址，例如 //fonts.googleapis.com (默认值) host: # 全局字体，应用在 body 元素上 global: external: true family: Monda # 标题字体 (h1, h2, h3, h4, h5, h6) headings: external: true family: Roboto Slab # 文章字体 posts: external: true family: # Logo 字体 logo: external: true family: # 代码字体，应用于 code 以及代码块 codes: external: true family: 标签图标美化默认情况下标签前缀是 # 字符，用户可以通过修改主题源码将标签的字符前缀改为图标前缀 在文章布局模板中找到文末标签相关代码段，将 # 换成 &lt;i class=&quot;fa fa-tags&quot;&gt;&lt;/i&gt; 即可： 1234567891011# themes\\next\\layout\\_macro\\post.swig &lt;footer class=\"post-footer\"&gt; &#123;% if post.tags and post.tags.length and not is_index %&#125; &lt;div class=\"post-tags\"&gt; &#123;% for tag in post.tags %&#125;- &lt;a href=\"&#123;&#123; url_for(tag.path) &#125;&#125;\" rel=\"tag\"&gt;# &#123;&#123; tag.name &#125;&#125;&lt;/a&gt;+ &lt;a href=\"&#123;&#123; url_for(tag.path) &#125;&#125;\" rel=\"tag\"&gt;&lt;i class=\"fa fa-tags\"&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;% endfor %&#125; &lt;/div&gt; &#123;% endif %&#125; ... &lt;/footer&gt;","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"}]},{"title":"Hexo 博客搭建：基础篇","slug":"hexo-blog-build-basic","date":"2019-10-27T13:46:00.000Z","updated":"2020-01-21T04:15:46.698Z","comments":true,"path":"2019/10/27/hexo-blog-build-basic/","link":"","permalink":"http://ppsteven.github.io/2019/10/27/hexo-blog-build-basic/","excerpt":"Hexo 是一款基于node.js 的静态博库框架，而且可以方便的托管在Github 上， 这里简单记录一下Hexo 的安装配置过程。 本篇博客算是Hexo博客搭建的第一篇文章，以后会陆续写几篇优化的文章。","text":"Hexo 是一款基于node.js 的静态博库框架，而且可以方便的托管在Github 上， 这里简单记录一下Hexo 的安装配置过程。 本篇博客算是Hexo博客搭建的第一篇文章，以后会陆续写几篇优化的文章。 从0到1，快速搭建hexo博客下载node.js 官网下载LTS版本，直接安装。Hexo 是依赖于Node.js 和 git 工具，我们首先需要安装node.js ，然后利用npm去安装一些必要的插件。 安装hexo注意：切换为 root 账号操作，切换淘宝源 cnpm,会更加快npm的速度 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装hexo cnpm install hexo-cli -g 安装完后用hexo -v 查看一下是否安装成功 启动hexo在目录下创建 blog 文件夹 mkdir blog ,进入 cd blog 初始化hexo 1hexo init 出现 INFO Start blogging with Hexo! 表示安装完成 启动hexo 本地启动的博客会在localhost:4000中启动，用户在本地是找不到相对应的Web资源目录。markdown文件修改完后即会调用hexo中的引擎自动渲染。 1hexo server/s 清空hexo 1hexo 生成hexo 这一步会生成对应public文件夹，其中包含了页面对应的HTML文件，未来我们部署到服务器上看到的就是public文件夹中的内容。 1hexo generate / hexo g 第一篇博客1hexo new post &apos;my first blog&apos; 该命令会在 /Users/YourUserName/blog/source/_posts/ 文件夹下生成对应的 md文件 模板文件在./scaffolds/post.md中找到。 Github Page 部署传统的博客搭建成本非常高，因为我们需要自己租用服务器，购买域名。现在我们可以将我们的代码托管到github仓库中，并利用Github Page 作为我们博客的页面（同样Github也提供了对应的域名） 第一步：新建仓库 名字必须为自己的用户名+.github.io 如 PPsteven.github.io 第二步：安装git 插件git 插件可以帮助我们方便的把我们的修改提交到我们的仓库中，是一个很方便的插件。 1cnpm install --save hexo-deployer-git 第三步：在配置文件中添加仓库信息在配置文件_config.yml中找到如下代码，添加repo 信息和 branch 信息 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/PPsteven/PPsteven.github.io.git # github 仓库地址 branch: master # 提交到的分支 第四步：部署hexo123hexo clean #会清除缓存文件db.json及之前生成的静态文件夹public；hexo g #会重新生成静态文件夹public；hexo deploy/ hexo d #因为之前已经安装了插件并且在博客配置文件中也配置好了，所以这个命令会在博客根目录下生成一个.deploy_git的文件夹，并 把本地生成的静态文件部署到LiLei.github.io这个仓库中的master分支上； 如果是第一次部署，会提示输入github 账号和密码 成功！！ 远端访问：PPsteven.github.io Hexo CheetSheet 初始化目录：hexo init [folder] 新建文章：hexo new/n [layout] &lt;title&gt; 或 新建草稿：hexo new draft &lt;title&gt; 新建页面：hexo new page tags 将草稿发布为正式文章：hexo publish &lt;title&gt; 生成静态文件：hexo generate/g 监听文件变化：hexo g --watch 或 hexo g -w 部署：hexo deploy/d 先生成后部署：hexo d -g 等于 hexo g 加 hexo d 启动本地服务器（服务器会监听文件变化并自动更新） hexo server/s 启动调试：hexo s --debug 预览草稿：hexo s --draft 清除缓存：hexo clean 站点配置主题安装教程 安装教程： NexT主题官网 Butterfly主题 下载主题&amp;启动12345cd bloggit clone https://github.com/iissnan/hexo-theme-next themes/next# 编辑_config.ymltheme: next# theme: Butterfly NexT 主题配置设定主题/语言主题配置的文件在themes/NexT 文件夹下的_config.yml 中，我们按照官网教程，依次配置 12345#scheme: Muse#scheme: Mistscheme: Pisceslanguage: zh-Hans 添加标签/分类/关于页面hexo 新建命令 hexo n [layout] title 中 layout 有三个模板 post创建文章，生成在/source/_posts文件夹下，draft创建草稿，生成在/source/ _drafts 文件夹下，page创建页面，生成在/source/YourPageName文件夹下 ![image-20191027011714501](/Users/ppsteven/Library/Application Support/typora-user-images/image-20191027011714501.png) 新建页面 123hexo new page tagshexo new page categorieshexo new page about 修改菜单（编辑 themes/next/_config.yml） 123456789menu: home: / || home about: /about/ || user # 关于页面 tags: /tags/ || tags # 标签页面 categories: /categories/ || th # 分类页面 archives: /archives/ || archive # 归档页面 #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap commonweal: /404/ || heartbeat # 公益404 设置头像_config.yml 在blog 文件和 theme/next 文件夹下都有 blog 下的为站点配置文件，主题下的为主题配置文件 mkdir themes/next/source/uploads ，放置头像图片（jpg/gif 等） 修改配置文件 12# avatar: http://example.com/avatar.pngavatar: /uploads/avatar_1.jpg 设置作者昵称修改 站点配置文件 1author: Your name 设置阅读字数与时长需要安装插件，地址 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true 配置搜索服务Local Search添加百度/谷歌/本地 自定义站点内容搜索 1cnpm install hexo-generator-searchdb --save 编辑站点配置文件，新增如下代码 12345search: path: search.xml field: post format: html limit: 10000 编辑主题配置文件，启动本地搜索 123456789# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 3 设置摘要 12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: True length: 150 多端同步正常情况下，我们写的博客是备份在本地的，没有上传服务器，但是若是有多台电脑的话。如何保持同步是一个问题。最近用闲置的笔记本搞了一个manjaro 玩耍，需要进行多端同步。 创建分支在blog文件夹下，我们用hexo d 命令提交的仅仅是public 文件夹里面的内容，默认的是提交在 master 分支上。为了在同一个repo 下管理我们的博客，我们可以建立新的分支hexo github 上创建一个新的分支 hexo。进入仓库在，点击Branch，输入新的分支名回车建立 在本地仓库创建hexo 分支，添加remote 地址 123456$git checkout -b hexo # 代表创建并切换$git remote add origin git@github.com:PPsteven/hexo_source.git # 添加远端地址$git remote -v # 查看remote 地址origin git@github.com:PPsteven/PPsteven.github.io.git (fetch)origin git@github.com:PPsteven/PPsteven.github.io.git (push)# 表示添加成功 其实有一个取巧的方法，在GitHub上创建新的分支hexo 后，在blog 文件夹中直接将该仓库的hexo 分支克隆到本地。 1$git clone -b git@github.com:PPsteven/PPsteven.github.io.git 向本地分支添加文件 123$git add . # 本地文件添加至暂存区$git commit -m \"blog file backup\" # 暂存区文件提交至本地分支$git push origin hexo # 向远端hexo 分支提交文件 看到网上讨论，在提交文件的时候，themes 文件夹会出错。原因是themes 下文件夹的主题包含.git 文件，造成了冲突，删除即可。 同步分支进入新的电脑，同步到本地就可以编辑了 1$git pull origin hexo 参考教程： hexo教程:基本配置+更换主题+多终端工作+coding page部署分流(2) 如何使用 Hexo 和 GitHub Pages 搭建这个博客 学习了上面的教程后，基本的搭建和部署已经没有问题了。","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"}]},{"title":"Mac 入门基础环境搭建","slug":"Mac 入门配置","date":"2019-10-26T13:46:00.000Z","updated":"2020-02-15T17:21:39.268Z","comments":true,"path":"2019/10/26/Mac 入门配置/","link":"","permalink":"http://ppsteven.github.io/2019/10/26/Mac%20%E5%85%A5%E9%97%A8%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Homebrew常用命令 官网安装 Homebrew http://mxcl.github.com/homebrew/ 前言包管理软件 Win: 360软件管家 Debian/Ubuntu: apt包管理系统 Redhat/Fedora: yum包管理系统 Mac OS X: Macports,Fink,AppStore 以及 Homebrew 使用方法brew -v 查询Homebrew版本brew -h brew帮助brew update 更新Homebrewbrew install 安装任意软件brew uninstall 卸载任意软件brew search 查询任意包brew list 列出安装列表brew info 查看任意包内容信息brew upgrade 更新任意包brew cleanup 删除具体旧软件brew cleanup 删除所有旧软件brew outdated 已安装的包是否需要更新 item2+oh-my-zsh1sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" chsh -s /bin/zsh. # 命令航切换bash为zsh shelliterm的perference-&gt;profiles-&gt;commond 设置成/bin/zsh # iterm2 界面手动切换 更改shell 语言 cat /etc/shells # 查看所有 shell chsh -s /bin/zsh #切换为zsh 修改文件vi ~/.zshrcsource ~/.zshrc echo $SHELL # 查看当前shell Iterm2 使用技巧 参考 iTerm2常用的快捷键 设置全局打开快捷键 Perferemance -&gt; Keys -&gt;Hotkey -&gt; show/hide all windows with a system-wide hotkey command + shift + t # 设置快捷键 打开iterm2 1234567891011121314新建标签：command + t关闭标签：command + w切换全屏：command + enter查找：command + f垂直分屏：command + d垂直上下分屏：command + shift + d左右 tab 之间来回切换：⌘ + 1 / 2查看历史命令：command + ; （输入常用命令的前缀后使用该快捷键可以实现补全的功能）除当前行：ctrl + u / ctrl +c 上一条命令：ctrl + p搜索命令历史：ctrl + r清屏：clear重新打开：command + riTerm2 剪切板历史：command + shift + h zsh 插件配置目前已经有的自带插件在官网Github中可以看到，https://github.com/robbyrussell/oh-my-zsh/tree/master/plugins。凡是这里有的，都可以立刻生效。 参考页面 一些实用常用插件推荐 for zsh oh-my-zsh git 默认自带zsh-syntax-highlighting 语法高亮1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting 将zsh-syntax-highlighting 下载到zsh 的plugins 目录中 1plugins=(其他的插件 zsh-autosuggestions) zsh-autosuggestions 自动建议1git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions 1plugins=(其他的插件 zsh-autosuggestions) sublime 默认自带 命令 作用 st 打开sublime st + 文件夹 打开文件夹 st + 文件 打开文件 stt 打开当前文件夹 ，等价于 st . sst 管理员权限 相当于 sudo st z 默认自带12z -x 无效路径z 目录名称 autojump12345678910111213141516171819$ brew install autojump plugins=(其他的插件 autojump)# 如果是linux 系统可能比较麻烦一点，需要从github 上下源码安装（当然也可以保证是最新的）$ git clone git@github.com:wting/autojump.git autojump$ cd autojump$ ./install.py# 运行完毕后就会出现如下信息Please manually add the following line(s) to ~/.zshrc: [[ -s /home/ppsteven/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; source /home/ppsteven/.autojump/etc/profile.d/autojump.sh autoload -U compinit &amp;&amp; compinit -uPlease restart terminal(s) before running autojump.# 按照操作在 .zshrc 中添加，我是乖乖添加了，其实我们可以直接在plugins 中添加的plugins=(其他的插件 autojump) 附录.zshrc配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123# If you come from bash you might have to change your $PATH.# export PATH=$HOME/bin:/usr/local/bin:$PATH# Path to your oh-my-zsh installation.export ZSH=\"/Users/ppsteven/.oh-my-zsh\"# Set name of the theme to load --- if set to \"random\", it will# load a random theme each time oh-my-zsh is loaded, in which case,# to know which specific one was loaded, run: echo $RANDOM_THEME# See https://github.com/robbyrussell/oh-my-zsh/wiki/Themes# ZSH_THEME=\"agnoster\"ZSH_THEME=\"ys\"# Set list of themes to pick from when loading at random# Setting this variable when ZSH_THEME=random will cause zsh to load# a theme from this variable instead of looking in ~/.oh-my-zsh/themes/# If set to an empty array, this variable will have no effect.# ZSH_THEME_RANDOM_CANDIDATES=( \"robbyrussell\" \"agnoster\" )# Uncomment the following line to use case-sensitive completion.# CASE_SENSITIVE=\"true\"# Uncomment the following line to use hyphen-insensitive completion.# Case-sensitive completion must be off. _ and - will be interchangeable.# HYPHEN_INSENSITIVE=\"true\"# Uncomment the following line to disable bi-weekly auto-update checks.# DISABLE_AUTO_UPDATE=\"true\"# Uncomment the following line to automatically update without prompting.# DISABLE_UPDATE_PROMPT=\"true\"# Uncomment the following line to change how often to auto-update (in days).# export UPDATE_ZSH_DAYS=13# Uncomment the following line if pasting URLs and other text is messed up.# DISABLE_MAGIC_FUNCTIONS=true# Uncomment the following line to disable colors in ls.# DISABLE_LS_COLORS=\"true\"# Uncomment the following line to disable auto-setting terminal title.# DISABLE_AUTO_TITLE=\"true\"# Uncomment the following line to enable command auto-correction.# ENABLE_CORRECTION=\"true\"# Uncomment the following line to display red dots whilst waiting for completion.# COMPLETION_WAITING_DOTS=\"true\"# Uncomment the following line if you want to disable marking untracked files# under VCS as dirty. This makes repository status check for large repositories# much, much faster.# DISABLE_UNTRACKED_FILES_DIRTY=\"true\"# Uncomment the following line if you want to change the command execution time# stamp shown in the history command output.# You can set one of the optional three formats:# \"mm/dd/yyyy\"|\"dd.mm.yyyy\"|\"yyyy-mm-dd\"# or set a custom format using the strftime function format specifications,# see 'man strftime' for details.# HIST_STAMPS=\"mm/dd/yyyy\"# Would you like to use another custom folder than $ZSH/custom?# ZSH_CUSTOM=/path/to/new-custom-folder# Which plugins would you like to load?# Standard plugins can be found in ~/.oh-my-zsh/plugins/*# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/# Example format: plugins=(rails git textmate ruby lighthouse)# Add wisely, as too many plugins slow down shell startup.plugins=( git# zsh-syntax-highlighting zsh-autosuggestions sublime autojump )source $ZSH/oh-my-zsh.sh# User configuration# export MANPATH=\"/usr/local/man:$MANPATH\"# You may need to manually set your language environment# export LANG=en_US.UTF-8# Preferred editor for local and remote sessions# if [[ -n $SSH_CONNECTION ]]; then# export EDITOR='vim'# else# export EDITOR='mvim'# fi# added by Anaconda3 2019.07 installer# &gt;&gt;&gt; conda init &gt;&gt;&gt;# !! Contents within this block are managed by 'conda init' !!__conda_setup=\"$(CONDA_REPORT_ERRORS=false '/Users/ppsteven/anaconda3/bin/conda' shell.bash hook 2&gt; /dev/null)\"if [ $? -eq 0 ]; then \\eval \"$__conda_setup\"else if [ -f \"/Users/ppsteven/anaconda3/etc/profile.d/conda.sh\" ]; then . \"/Users/ppsteven/anaconda3/etc/profile.d/conda.sh\" CONDA_CHANGEPS1=false conda activate base else \\export PATH=\"/Users/ppsteven/anaconda3/bin:$PATH\" fifiunset __conda_setup# &lt;&lt;&lt; conda init &lt;&lt;&lt;# Compilation flags# export ARCHFLAGS=\"-arch x86_64\"# Set personal aliases, overriding those provided by oh-my-zsh libs,# plugins, and themes. Aliases can be placed here, though oh-my-zsh# users are encouraged to define aliases within the ZSH_CUSTOM folder.# For a full list of active aliases, run `alias`.## Example aliasesalias zshconfig=\"vim ~/.zshrc\"# alias ohmyzsh=\"mate ~/.oh-my-zsh\" 解压软件解压软件 unrarbrew install unrar 使用方法 unrar x test.rar # 解压到当前目录 解压软件 7zbrew search 7z # p7zip brew install p7zip 使用方法 7z e filename.7z 图床软件PicGo安装教程 https://github.com/Molunerfinn/PicGo 看完上面的配置才发现也是找工作的学生，真是厉害 Github 图床配置 12345PPsteven/picturesmasterToken:XXXXXimg/https://cdn.jsdelivr.net/gh/PPsteven/pictures 设置 ssh 远程连接超时为了解决 ssh 连接一段时间后会断开，我们需要在 服务端 和 客户端 做出以下操作 12/etc/ssh/sshd_config # 服务端配置/etc/ssh/ssh_config # 客户端配置 服务器端1234vim /etc/ssh/sshd_config# 修改为ClientAliveInterval 30 # 客户端每隔多少秒向服务发送一个心跳数据ClientAliveCountMax 86400 # 客户端多少秒没有相应，服务器自动断掉连接 最后重启 sshd 服务 (centos7+) 1sudo systemctl restart sshd 客户端12ServerAliveInterval 60 # 每分钟发送一次, 然后客户端响应, 从而保持长连接;ServerAliveCountMax 3 # 表示服务器发出请求后客户端没有响应的次数达到3次, 就自动断开 Charles破解教程 参考教程：Charles mac 破解教程 123# 工具栏中的 help --&gt; registerRegistered Name: https://zhile.ioLicense Key: 48891cf209c6d32bf4 Charles设置指南：Charles使用指南","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"}]}]}