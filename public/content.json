{"meta":{"title":"软微9133","subtitle":null,"description":"只争朝夕，不负韶华","author":"PPsteven","url":"http://ppsteven.github.io","root":"/"},"pages":[{"title":"","date":"2020-02-14T17:42:37.825Z","updated":"2019-12-22T15:16:34.050Z","comments":true,"path":"404/index.html","permalink":"http://ppsteven.github.io/404/index.html","excerpt":"","text":""},{"title":"关于","date":"2019-10-26T17:38:15.000Z","updated":"2020-02-15T17:06:40.671Z","comments":true,"path":"about/index.html","permalink":"http://ppsteven.github.io/about/index.html","excerpt":"","text":"自我介绍研二,对计算机和金融感兴趣。目前在一家互联网公司做后台开发实习，PHP开发。擅长爬虫，爬过的网站有：美团，点评，协程，马蜂窝等。"},{"title":"categories","date":"2019-10-26T17:38:06.000Z","updated":"2020-02-15T16:29:40.108Z","comments":false,"path":"categories/index.html","permalink":"http://ppsteven.github.io/categories/index.html","excerpt":"","text":""},{"title":"归档","date":"2019-10-27T08:36:41.000Z","updated":"2019-12-22T15:16:34.054Z","comments":true,"path":"archives/index.html","permalink":"http://ppsteven.github.io/archives/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-11-04T14:03:28.000Z","updated":"2020-02-16T09:47:47.761Z","comments":false,"path":"link/index.html","permalink":"http://ppsteven.github.io/link/index.html","excerpt":"","text":"用户 网址 描述 jordenbruce https://jordenbruce.com/ 数仓大神 wangjs-jacky http://wangjs-jacky.github.io/ 风雪之隅 http://www.laruence.com/2015/05/28/3038.html 鸟哥,PHP7主要开发人 韩天峰 http://rango.swoole.com/ swoole创始人"},{"title":"tags","date":"2019-10-26T17:09:48.000Z","updated":"2020-02-15T16:29:21.685Z","comments":false,"path":"tags/index.html","permalink":"http://ppsteven.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker 实战:利用 docker 搭建服务","slug":"docker-some-service-build-instruction","date":"2020-06-18T11:15:21.000Z","updated":"2020-06-18T12:08:01.576Z","comments":false,"path":"2020/06/18/docker-some-service-build-instruction/","link":"","permalink":"http://ppsteven.github.io/2020/06/18/docker-some-service-build-instruction/","excerpt":"用 docker 安装需要用到的服务实在是太方便了，我们下面介绍一些好的轮子来用。 web-vscode: 搭建一个web版的vscode，不过实测下来不是特别好用。很多vscode上的插件用不了 redis web: web端的web管理工具，不过配置起来稍微有点麻烦。 lamp: php基础开发环境","text":"用 docker 安装需要用到的服务实在是太方便了，我们下面介绍一些好的轮子来用。 web-vscode: 搭建一个web版的vscode，不过实测下来不是特别好用。很多vscode上的插件用不了 redis web: web端的web管理工具，不过配置起来稍微有点麻烦。 lamp: php基础开发环境 web-vscode 安装 传送门: code-server 1234567891011121314151617181920212223242526#创建docker rm -f vscode docker run \\# 后台运行-d \\ # 总是运行--restart=always \\ # Alias--name web_vscode \\ # hostname-h vscode \\ # 一定要以root账号运行,不然会报 Permission denied-u root \\ # 所有端口映射，而不要是127.0.0.1-p 8086:8080 \\ -v \"$&#123;HOME&#125;/.local/share/code-server:/home/coder/.local/share/code-server\" \\ # 密码是通过环境变量加入的-e PASSWORD=mycode \\ # $PWD 是当前希望项目放置的位置-v \"$PWD:/home/coder/project\" \\# 镜像名，本地不存在的话，会从仓库拉取codercom/code-server:v2 #查看docker ps -ldocker logs web_vscode 运行成功后 12345info Server listening on http://0.0.0.0:8080info - Password is 558ba38067432e3beddf1228info - To use your own password, set the PASSWORD environment variableinfo - To disable use `--auth none`info - Not serving HTTPS 由于我们的 web-vscode 是运行在容器内的，所以很多环境我们需要自己配置，参考上述操作。 redis web 管理工具mac 上 redis 管理工具破解版不好找，但是在 github 上找到了一个开源的工具，非常方便。拿来用一下 传送门: phpRedisAdmin 1234docker pull erikdubbelboer/phpredisadmindocker run --rm -itd -e REDIS_1_HOST=redis -e REDIS_1_NAME=myredis -p 8015:80 --link redis-test:redis --name redisadmin erikdubbelboer/phpredisadmin# 需要注意的是 REDIS_1_HOST 填写的是自己 redis 服务器的地址# 这里我采用的是容器链接的方式 redis &amp; redis可视化工具1234567docker pull redisdocker run -p 127.0.0.1:6379:6379 -d --name redis redis --requirepass &quot;mypassword&quot;# 查看redis的ip地址 172.17.0.2docker inspect redis | grep -ai &apos;ipa&apos;docker run --rm -it -e REDIS_1_HOST=172.17.0.2 -e REDIS_1_NAME=redis -p 80:80 erikdubbelboer/phpredisadmin php LAMP 环境搭建利用 docker 搭建 LAMP 环境本身应该是比较省力气的方式，但是网上 CSDN 之类的教程很多都是复制黏贴，很多实现不了，优质教程很少。目前发现了国外的一个 linode 的 docke r镜像，有非常详细的教程，很好用。 linode 详细配置，请看 https://hub.docker.com/r/linode/lamp https://www.linode.com/docs/applications/containers/how-to-install-docker-and-deploy-a-lamp-stack/ docker 安装docker 环境搭建请看我的 Centos 环境配置（持续总结） 这一篇教程 拉取docker镜像1234567# docker search -s 10 lampFlag --stars has been deprecated, use --filter=stars=3 insteadNAME DESCRIPTION STARS OFFICIAL AUTOMATEDmattrayner/lamp A simple LAMP docker image running the prere… 211 [OK]linode/lamp LAMP on Ubuntu 14.04.1 LTS Container 178... linode 的镜像 star数还是比较高的# sudo docker pull linode/lamp 生成配置文件目录这一步很多教程里面都缺失的一部分，lamp 的很多文件需要映射到宿主机，方法后面的配置。 12345678910111213141516171819# 启动进入容器 $ docker run -itd --name lamp linode/lamp:latest /bin/bash# 将需要映射的文件拷贝出来，主要就是 apache2, mysql的配置文件 和 www文件夹.├── apache2.conf├── my.cnf└── www ├── example.com │ ├── backups │ ├── log │ └── public_html └── html └── index.html $ docker cp lamp:/var/www /Users/xxx/Documents/Dockerfile/lamp/www$ docker cp lamp:/etc/apache2/apache2.conf /Users/xxx/Documents/Dockerfile/lamp/apache2.conf$ docker cp lamp:/etc/mysql/my.cnf /Users/xxx/Documents/Dockerfile/lamp/my.cnf# 删除旧的容器$ docker container rm -f lamp 启动容器123456sudo docker run -p 8010:80 -p 3309:3306 \\ -v /Users/ppsteven/Documents/Dockerfile/lamp/www:/var/www \\ -v /Users/ppsteven/Documents/Dockerfile/lamp/apache2.conf:/etc/apache2/apache2.conf \\ -v /Users/ppsteven/Documents/Dockerfile/lamp/my.cnf:/etc/mysql/my.cnf \\ --name lamp \\ -itd linode/lamp:latest /bin/bash 启动 Apache 和 MySQL 服务容器内部的 Apache 和 MySQL 服务是默认不自动启动的（当 LAMP 重启的时候需要注意查看这两个服务是否也启动了） 12service apache2 startservice mysql start MySQL 初始化配置这一步是很多地方没有提的，linode 的 MySQL 是有默认密码，Admin2015。我们需要初始化对于 MySQL 数据库的配置。 参考：https://zhuanlan.zhihu.com/p/111605563 123456789101112131415161718# 如下命令即可mysql_secure_installation按下回城键你会看见结尾如下的对话。Enter current password for root (enter for none): #Set root password? # 是否设置root用户密码 yNew password: # 新密码Re-enter new password: Remove anonymous users? [Y/n] # 是否删除匿名用户，回车 yDisallow root login remotely? [Y/n] # 是否禁止root远程登录Remove test database and access to it? [Y/n] # 是否删除test数据库Reload privilege tables now? [Y/n] # 是否重新加载权限表 yAll done! If you’ve completed all of the above steps, your MariaDBinstallation should now be secure.Thanks for using MariaDB!# 测试登录mysql -uroot -p\"自己的数据库密码\" 测试是否成功游览器输入 http://localhost:8010/ ，看到如下信息，表示成功 123The Docker LAMP stack is working.The configuration information can be found here or hereThis index.html file is located in the &quot;/var/www/example.com/public_html&quot; directory. 排查问题方法docker 退出12# 千万不要用 exit，容器会跟着退出的CTRL + P + Q docker ip查看 进入容器查看，这种方法可能会失败，因为可能容器的系统中没有对应的命令工具 12docker exec -ti &lt;NAME OR ID&gt; /bin/bash# ifconfig/ip addr 最正统的写法(可以写在 shell 脚本里) 12# docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' 2e23d01384ac172.17.0.2 最简单查询的写法 12345$ docker inspect lamp | grep -ai 'ipa' \"SecondaryIPAddresses\": null, \"IPAddress\": \"172.17.0.2\", \"IPAMConfig\": null, \"IPAddress\": \"172.17.0.2\", docker 日志排查（tail -f /dev/null）利用 tail -f /dev/null 长命令阻塞，不让容器立马结束，这种用法非常好用 1docker exec -ti &lt;NAME OR ID&gt; tail -f /dev/null","categories":[{"name":"docker","slug":"docker","permalink":"http://ppsteven.github.io/categories/docker/"}],"tags":[{"name":"docker, mysql, redis, ELK","slug":"docker-mysql-redis-ELK","permalink":"http://ppsteven.github.io/tags/docker-mysql-redis-ELK/"}]},{"title":"python并发编程——多线程编程 threading 协程","slug":"python-threading-basic","date":"2020-06-06T16:33:20.000Z","updated":"2020-06-07T03:13:52.823Z","comments":false,"path":"2020/06/07/python-threading-basic/","link":"","permalink":"http://ppsteven.github.io/2020/06/07/python-threading-basic/","excerpt":"Python 并发编程可以分为三块：多进程编程，多线程编程，多协程编程。之前一篇文章已经讲解过了 多进程编程 multiprocessing 的用法，threading 的使用基本上和 multiprocessing 的差别不大，由于协程是共享同一个进程下的内存地址，所以无需使用 Manager/Array/Values 这种进程间通信的方法，更加简单。 本章主要介绍 多线程threading 的基本使用方法 GIL锁概念","text":"Python 并发编程可以分为三块：多进程编程，多线程编程，多协程编程。之前一篇文章已经讲解过了 多进程编程 multiprocessing 的用法，threading 的使用基本上和 multiprocessing 的差别不大，由于协程是共享同一个进程下的内存地址，所以无需使用 Manager/Array/Values 这种进程间通信的方法，更加简单。 本章主要介绍 多线程threading 的基本使用方法 GIL锁概念 threading 库使用基本使用方法和 multiprocessing 一样 1234567891011import threadingimport timedef worker(name): print(\"线程 %s 正在运行\" % name) time.sleep(1)if __name__ == \"__main__\": for i in range(5): t = threading.Thread(target=worker, args=(i,)) t.start() #启动线程，即让线程开始执行 构造方法1class threading.Thread(group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *, daemon=None)¶ group 兼容逻辑，始终设置为默认 None target 目标函数 args 传入tuple参数 kwargs 传入字典参数 name 线程名称，默认会自动起一个 Thread-N 的名字 daemon 守护线程 属性 &amp; 方法 ident 线程标识符get_ident() name &amp; get_name() &amp; setName() 获取/设置进程名 daemon &amp; isDaemon() &amp; setDaemon() 设置/判断 守护进程 is_alive() &amp; isAlive() 线程是否存活 join([timeout]) 线程阻塞 start() 和 run() 启动线程 如同进程一样，线程也有两种构造方法。 a. 通过 start() 启动线程，此方法每个线程对象只能调用一次。start()会调用run()方法。 ​ 标准的run() 方法会执行 target 函数，并使用 args, kwargs参数 12t = threading.Thread(target=worker, args=(i,))t.start() #启动线程，即让线程开始执行 b. 通过继承 threading.Thread 的子类重写 run 方法实现我们上面的功能 1234567891011121314151617import threadingimport timeclass MyThreading(threading.Thread): def __init__(self, *args, **kwargs): super(MyThreading, self).__init__() # 有两种方法调用父类，注意self的区别 # threading.Thread.__init__(self) self.args = args def run(self): print(\"线程 %s 正在运行\" % self.args) time.sleep(1)if __name__ == \"__main__\": for i in range(5): t = MyThreading(i) t.start() 或者，更加通用一点 12345678910111213141516class MyThreading(threading.Thread): def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None): threading.Thread.__init__(self, group=None, target=None, name=None, args=(), kwargs=None, daemon=None) self.args = args self.kwargs = kwargs self.func = target def run(self): self.func(*self.args)if __name__ == \"__main__\": for i in range(5): t = MyThreading(target=worker, args=(i,)) t.start() #启动线程，即让线程开始执行 threading 提供的方法 threading.active_count() 当前存活的线程数目 len(threading.enumerate()) 也可以计算出相同的结果 threading.current_thread() 当前正在执行的线程对象 threading.enumerate() 当前活着的线程列表 threading.main_thread() 主线程 1234&gt;&gt; threading.enumerate())[&lt;_MainThread(MainThread, started 4573310400)&gt;, &lt;MyThreading(Thread-1, started 123145406984192)&gt;, &lt;MyThreading(Thread-2, started 123145412239360)&gt;, &lt;MyThreading(Thread-3, started 123145417494528)&gt;, &lt;MyThreading(Thread-4, started 123145422749696)&gt;, &lt;MyThreading(Thread-5, started 123145428004864)&gt;]&gt;&gt; threading.main_thread()&lt;_MainThread(MainThread, started 4573310400)&gt; 可以看到我们有一个主线程和程序运行中自主创建的5个子线程 线程 threading 和 mutiprocessing 异同 没有线程池 线程间共享全局变量，没有多进程间复杂的沟通方式 共享全局变量依旧会存在冲突的问题，使用的方法为互斥锁 Lock, RLock, Condtion, Semaphore, Event. Barrier这一部分和 mutiprocessing一样 GIL 锁GIL的基本概念 In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.) GIL(Global Interpreter Lock)，中文译为全局解释器锁。 Python 虽然是近年来非常火的一个语言，但是它并不是一个新语言，1991年第一个Python编译器诞生。那时候的计算机大多是单核CPU，也就不存在并行计算的问题。随着CPU性能的提升，单核CPU逐渐被多核CPU替代。随着而来的问题是，如何保持数据间的一致性。解决的最简单的方法是加锁，只是Python的这把锁太大了点。 GIL本质上类似操作系统的 Mutex。GIL 的功能是：在 CPython 解释器中执行的每一个 Python 线程，都会先锁住自己，以阻止别的线程执行。 GIL的工作原理 可以看到 Thread 1 和 Thread 3 并不是一次性执行完的，而是线程会主动释放。这里的原因是CPython中存在一个叫做 间隔式检查（check_interval） 的机制。CPython 解释器会轮询线程，每隔一段时间，CPython 就会强制当前线程释放GIL锁。 这和CPU时间片的概念一样 在Python3 中，“时间片”大致为15毫秒。 解决方法使用 multiprocessing 替代 threading multiprocessing库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。 – 作者：rookieyu multiprocessing 的问题在于，其占用的资源是高于多线程的。而且由于进程间不能读取对方的地址空间，导致了多进程沟通是较为复杂的，这个额外的成本使得原本就非常复杂的多线程编程变得更加困难了点。 不过 threading 也并非是一无是处，虽然在CPU 利用率上表现的不尽人意，但是在高I/O操作的时候，多线程可以起到避免阻塞的作用。 计算密集型使用多进程，I/O密集型使用多线程或者多协程 改用其他编译器使用JPython 或者 IronPython 编译器，可以解决这类问题 参考资料 threading— 基于线程的并行 食之无味，弃之可惜—Python threading——线程对象 Python GIL全局解释器锁详解（深度剖析） rookieyu 简书– GIL","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/tags/python/"},{"name":"threading","slug":"threading","permalink":"http://ppsteven.github.io/tags/threading/"}]},{"title":"mac + VMware + Centos7 下的网络配置","slug":"vmware-centos-environment-network","date":"2020-05-18T17:11:18.000Z","updated":"2020-05-20T14:04:37.216Z","comments":false,"path":"2020/05/19/vmware-centos-environment-network/","link":"","permalink":"http://ppsteven.github.io/2020/05/19/vmware-centos-environment-network/","excerpt":"本文介绍，如何在 mac 系统下配置一个 无图形化的 centos 环境，难点在于网络配置 教程参考: 个人专属多节点Linux环境打造，Linux操作系统学习实验环境安装配置视频教程 用到的工具 centos 系统 阿里云站点: http://mirrors.aliyun.com/centos/7/isos/x86_64/ 各个版本的ISO镜像文件说明： CentOS-7-x86_64-DVD-1708.iso 标准安装版（推荐） CentOS-7-x86_64-Everything-1708.iso 完整版，集成所有软件（以用来补充系统的软件或者填充本地镜像） CentOS-7-x86_64-LiveGNOME-1708.iso GNOME桌面版 CentOS-7-x86_64-LiveKDE-1708.iso KDE桌面版 CentOS-7-x86_64-Minimal-1708.iso 精简版，自带的软件最少 CentOS-7-x86_64-NetInstall-1708.iso 网络安装版（从网络安装或者救援系统） 作者：Ada54链接：https://www.jianshu.com/p/a63f47e096e8 这里 CentOS-7-x86_64-DVD-1708.iso 是标准安装版，如果选择最小安装，和 CentOS-7-x86_64-Minimal-1708.iso (无界面版本)一样。 vmware 或者 virtualbox finalShell/terminal","text":"本文介绍，如何在 mac 系统下配置一个 无图形化的 centos 环境，难点在于网络配置 教程参考: 个人专属多节点Linux环境打造，Linux操作系统学习实验环境安装配置视频教程 用到的工具 centos 系统 阿里云站点: http://mirrors.aliyun.com/centos/7/isos/x86_64/ 各个版本的ISO镜像文件说明： CentOS-7-x86_64-DVD-1708.iso 标准安装版（推荐） CentOS-7-x86_64-Everything-1708.iso 完整版，集成所有软件（以用来补充系统的软件或者填充本地镜像） CentOS-7-x86_64-LiveGNOME-1708.iso GNOME桌面版 CentOS-7-x86_64-LiveKDE-1708.iso KDE桌面版 CentOS-7-x86_64-Minimal-1708.iso 精简版，自带的软件最少 CentOS-7-x86_64-NetInstall-1708.iso 网络安装版（从网络安装或者救援系统） 作者：Ada54链接：https://www.jianshu.com/p/a63f47e096e8 这里 CentOS-7-x86_64-DVD-1708.iso 是标准安装版，如果选择最小安装，和 CentOS-7-x86_64-Minimal-1708.iso (无界面版本)一样。 vmware 或者 virtualbox finalShell/terminal 安装完 Linux 后的网络是默认不通的，为了使网络连通 设置桥接模式在虚拟机挂机的情况下 虚拟机 -&gt; 网络适配器 -&gt; 桥接模式 -&gt; 勾选 Wi-Fi 模式 勾选完毕后，我们就可以看到 IP 和 子网 掩码， 这个 ip 和 子网掩码 同样也是 宿主机 的 ip 和 子网掩码 分配静态地址由于虚拟机默认的是走的 DHCP，我们需要主动请求去获取 ip 地址。我们在使用虚拟机的时候肯定是希望一个固定的 ip。 利用 dhclient 命令可以主动向 DHCP 服务器获取一个 ip 地址 12345678910111213141516[root@192 ~]# dhclient[root@192 ~]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:45:4d:90 brd ff:ff:ff:ff:ff:ff inet 192.168.1.8/24 brd 192.168.1.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 2409:8a1e:5e7a:f280:c9ed:976f:94f1:9901/64 scope global noprefixroute dynamic valid_lft 209430sec preferred_lft 123030sec inet6 fe80::9f8c:26f6:3c23:c4d3/64 scope link noprefixroute valid_lft forever preferred_lft forever 我们获得了一个 ip 地址 192.168.1.8 设置固定 ip注意事项 如果你上面的静态 ip 没有主动分配的话，直接在本小节中修改配置也是可以的。但是这样做的话，你需要设置一个比较大的 ip，如 192.168.0.20。这是因为在同一个局域网下，可能有别的设备（手机，平板）占用了某个 ip 地址，你需要去避开这一点。 需要切换成 root 账号去操作 配置文件修改12345678910111213141516171819202122# vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=EthernetPROXY_METHOD=none BROWSER_ONLY=no- BOOTPROTO=dhcp+ BOOTPROTO=static # 默认是 dhcpDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=5bf952f3-8b37-4ded-b5bc-79ce0676e69dDEVICE=ens33- ONBOOT=no # 默认是no+ ONBOOT=yes # 默认是no+ IPADDR=192.168.1.8 # 填写刚刚分配给我们的 ip地址+ NETMASK=255.255.255.0 # 填写刚刚查到的 子网掩码+ GATEWAY=192.168.1.1 # 子网掩码 + ip 可得+ DNS1=192.168.1.1 # 这里填写的 mac 上的 dns 服务器 mac-&gt;网络偏好设置-&gt;高级-&gt;DNS 可以查到 DNS服务器地址打开【系统偏好设置】-【网络】- 选中【Wi-Fi】项（如果您是WIFI上网请选择此项）- 点右侧【高级】选择【TCP/IP】选项卡，记录好【子网掩码】、【路由器】地址、DNS选项卡下的DNS服务器地址（如果DNS服务器地址没有配置，也可以给配置个8.8.8.8） 网络重启1systemctl restart network.service 查看是否连通123456789[root@192 ~]# ping www.baidu.comPING www.a.shifen.com (36.152.44.95) 56(84) bytes of data.64 bytes from 36.152.44.95 (36.152.44.95): icmp_seq=1 ttl=56 time=11.3 ms64 bytes from 36.152.44.95 (36.152.44.95): icmp_seq=2 ttl=56 time=11.2 ms64 bytes from 36.152.44.95 (36.152.44.95): icmp_seq=3 ttl=56 time=65.8 ms^C--- www.a.shifen.com ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2003msrtt min/avg/max/mdev = 11.281/29.502/65.882/25.724 ms 有界面版如果切换成无界面12$ systemctl set-default multi-user.target (关闭图形界面) # 执行以后,输入命令 reboot 重启机器就可以$ systemctl set-default graphical.target (开启图形界面) # 执行以后,输入命令 reboot 重启机器就可以 参考资料https://segmentfault.com/a/1190000015227575","categories":[{"name":"centos","slug":"centos","permalink":"http://ppsteven.github.io/categories/centos/"}],"tags":[{"name":"centos","slug":"centos","permalink":"http://ppsteven.github.io/tags/centos/"}]},{"title":"算法笔记:《剑指 Offer》","slug":"jz-offer-solution","date":"2020-05-14T12:13:20.000Z","updated":"2020-07-10T12:25:09.945Z","comments":false,"path":"2020/05/14/jz-offer-solution/","link":"","permalink":"http://ppsteven.github.io/2020/05/14/jz-offer-solution/","excerpt":"用言简意赅的方法记录 《剑指》，作为复习《剑指offer》的笔记","text":"用言简意赅的方法记录 《剑指》，作为复习《剑指offer》的笔记 面试题03. 数据中的重复数字Best Answer【利用下表法】 解题思路： 利用 nums 里的所有数字都在 0～n-1 的范围内 这一条件，表示 每个数字都只有一个坑位，一个坑位上不能有两个数字 时间复杂度 O(n) 空间复杂度O(1) 123456789class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: for i in range(len(nums)): while i != nums[i]: if nums[i] == nums[nums[i]]: return nums[i] # 原地交换 temp = nums[i] nums[i] = nums[nums[i]] nums[temp] = temp 交换数组的时候，需要注意利用 python 便捷的交换方式存在陷阱 12345678910# 正确方法一：temp = nums[i]nums[i] = nums[nums[i]]nums[temp] = temp# 正确方法二：nums[nums[i]] , nums[i] = nums[i] , nums[nums[i]]# 错误方式：nums[i], nums[nums[i]] = nums[nums[i]], nums[i] Other Answer【哈希表法】 解题思路：哈希表 时间复杂度 O(n) 空间复杂度O(n) Python的实现哈希表的方式是通过 字典 和 集合 的方式 1234567891011121314# 基于集合class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: s = set() for i in nums: if i in s: return i else: s.add(i)# 基于字典class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: s = dict() for i in nums: if i in s: return i else: s[i] = True 面试题04. 二维数组中的查找 同 搜索二维矩阵 II Best Answer【左下/右上元素移动法】 解题思路： 左下、右上角的特点是，排除式查找。 时间复杂度 O(行高+列宽) 空间复杂度：O(1) 12345678910class Solution: def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -&gt; bool: if not matrix: return False # 以右上角为例 i, j = 0, len(matrix[0]) - 1 while i &lt; len(matrix) and j &gt;= 0: if matrix[i][j] == target: return True elif matrix[i][j] &lt; target: i += 1 # 比目标值小，向下一行查找 else: j -= 1 # 比目标值大，向上一行查找 return False Other Answer 【双折半查找】 解题思路 折半法 参考：https://blog.nowcoder.net/n/d332492753844d18aa4edc484e3c1318 时间复杂度：O(logM + logN) 复杂度最坏情况为O(M * logN) 二维数组分为上下左右四个边界top，bottom，left，right： 根据上边界折半查找——确定 right 范围 根据下边界折半查找——确定 left 范围 根据左边界折半查找——确定 top 范围 根据右边界折半查找——确定 bottom 范围 最直接的方法，代码量大，考察基本功 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class Solution: # array 二维列表 def Find(self, target, array): # write code here left = 0 right = len(array[0]) - 1 top = 0 bottom = len(array) - 1 while (left &lt; right or top &lt; bottom): # 对上边界进行折半，可以缩小右边界 l = left r = right while (l &lt;= r): mid = (l+r) // 2 if array[top][mid] == target: return True elif array[top][mid] &gt; target: r = mid - 1 else: l = mid + 1 if (mid &lt; right): right = mid top += 1 # 对下边界进行折半，可以缩小左边界 l = left r = right while (l &lt;= r): mid = (l + r) // 2 if array[bottom][mid] == target: return True elif array[bottom][mid] &gt; target: r = mid - 1 else: l = mid + 1 if (mid &gt; left): left = mid bottom -= 1 # 对左边界进行折半，可以缩小下边界 t = top b = bottom while (t &lt;= b): mid = (t + b) // 2 if array[mid][left] == target: return True elif array[mid][left] &gt; target: b = mid - 1 else: t = mid + 1 if (t &lt; mid): t = mid left += 1 # 对右边界进行折半，可以缩小上边界 t = top b = bottom while (t &lt;= b): mid = (t + b) // 2 if array[mid][right] == target: return True elif array[mid][right] &gt; target: b = mid - 1 else: t = mid + 1 if (b &gt; mid): b = mid right -= 1 return Falseif __name__ == \"__main__\": ret = Solution().Find(7,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]) print(ret) 面试题05. 替换空格 解题思路： 字符串相关操作 面试题06. 从尾到头打印链表 递归法 递归是由计算机帮助实现 “栈” 结构 12345class Solution: stack = [] def reversePrint(self, head: ListNode) -&gt; List[int]: if not head: return [] return self.reversePrint(head.next) + [head.val] 数据结构——栈 12345678class Solution: # 返回从尾部到头部的列表值序列，例如[1,2,3] def printListFromTailToHead(self, listNode): stack = [] while listNode: stack.append(listNode.val) listNode = listNode.next return stack[::-1] 面试题07. 重建二叉树Best Answer 解题思路: 数据结构——二叉树 根据 pre 确定 根节点 根据 vin 确定左右子树的大小 递归编程 注意点 需要根据中序遍历结果，确定左子树长度 tin.index(value) 1234567891011121314151617181920212223242526272829303132class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None class Solution: # 返回构造的TreeNode根节点 def reConstructBinaryTree(self, pre, tin): # write code here if len(pre) == 0 : return None if len(pre) == 1 : return TreeNode(pre[0]) value = pre[0] root = TreeNode(value) # 截取左子树 preLeft = pre[1:tin.index(value) + 1] # 先序遍历，从第二个开始截图 左子树长度的 数组 tinLeft = tin[:tin.index(value)] # 中序遍历 # 截取右子树 preRight = pre[tin.index(value) + 1:] # 先序遍历， 左子树后的数组元素是 右子树 tinRight = tin[tin.index(value) + 1:] # 中序遍历 root.left = self.reConstructBinaryTree(preLeft, tinLeft) root.right = self.reConstructBinaryTree(preRight, tinRight) return root if __name__ == \"__main__\": sol = Solution().reConstructBinaryTree([1,2,4,5,3,6,7],[4,2,5,1,6,3,7]) print(sol) 面试题09. 用两个栈实现一个队列Best Answer 解题思路:栈是后进先出(LIFO)，队列是先进先出(FIFO)。可以使用2个栈来表示，一个表示入栈，还有一个表示出栈，出栈的顺序与入栈的顺序相反。 第一个栈弹出后压入第二个栈就可以了 python 栈 &amp; 队列 实现 123456789101112131415161718192021222324252627282930313233# python 栈实现stack = []stack.append(1) # 入栈stack.pop() # 出栈# python 队列实现from collections import deque queue = deque(['A', 'B', 'C']) queue.append('D') # 入队queue.popleft() # 出队# 自定义实现class Stack: # item = [] 这样的用法是错误的，因为此时有两个栈实例都会使用此变量 def __init__(self): self.item = [] def push(self, node): self.item.append(node) def pop(self): v = self.item.pop() return v @property def length(self): return len(self.item) def isEmpty(self): if self.length &gt; 0: return False else: return True 图解 参考：https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/solution/fu-zhu-zhan-python3-c-by-z1m/ 123456789101112131415class CQueue: def __init__(self): # s1 用于存储，相当于仓库; s2 用于输出 self.s1, self.s2 = [], [] def appendTail(self, value: int) -&gt; None: self.s1.append(value) def deleteHead(self) -&gt; int: if self.s2: return self.s2.pop() while self.s1: # 如果 s1 为空，尝试把 s2 数据换过来 self.s2.append(self.s1.pop()) if self.s2: return self.s2.pop() # 再次尝试取数据 else: return -1 面试10- I. 斐波那契数列【动态规划经典】面试10- II. 青蛙跳台阶问题【动态规划经典】Best Answer【动态规划】 解题思路：动态规划动态规划解析： 作者：jyd 时间复杂度：O(n) 空间复杂度O(n) 123456class Solution: def fib(self, n: int) -&gt; int: fibArr = [0, 1] for i in range(2, n + 1): fibArr.append(fibArr[i - 1] + fibArr[i - 2]) return fibArr[n] % 1000000007 Other Answer 【循环求余法】 解题速率：动态规划的改进 作者：jyd 时间复杂度：O(n) 空间复杂度O(1) 动态规划的空间复杂度 O(n) ，可以不存储中间结果。 123456class Solution: def fib(self, n: int) -&gt; int: a, b = 0, 1 for _ in range(n): a, b = b, a + b return a % 1000000007 Other Answer【分治法+记忆化搜索】 解题思路： 分治法 + 记忆化搜索 传统的分治法会产生大量重复计算，一定会超时。通过将结果固定下来可以加快运算速度 123456789class Solution: def fib(self, n: int) -&gt; int: def F(n): if n in memory: return memory[n] value = F(n-1) + F(n-2) memory[n] = value return memory[n] memory = &#123;0:0, 1:1&#125; return F(n) % 1000000007 面试题11. 旋转数组的最小数字【中高难】Best Answer【变形二分查找】 解题思路： 时间复杂度O(n) 空间复杂度 O(1) 变形的二分查找，但是有一些坑 a. 正确情况下的二分查找 b. 特殊情况 当出现重复数字情形的时候，直接缩小左边界（因为最小值总是在右侧出现） 情形4 可以适应非递增数列的最小值为队首元素的情形。最后的代码非常巧妙 12345678910111213141516class Solution: def minNumberInRotateArray(self, rotateArray): left = 0 right = len(rotateArray) - 1 while left &lt; right: # 不能是 &lt;= # 加入特殊情况，非递减数组的最小值就是队首 if rotateArray[left] &lt; rotateArray[right]: return rotateArray[left] mid = (left + right) // 2 if rotateArray[mid] &gt; rotateArray[left]: left = mid + 1 # 一般都是在右侧，所以放心加1 elif rotateArray[mid] &lt; rotateArray[right]: right = mid # 此时 mid 可能是最小值，不能排除 else: left += 1 # 巧妙避免了offer书上说的坑点（1 0 1 1 1） return rotateArray[left] 二分法解题需要考虑的情况 while left &lt;= right 是错误的 实例：[2,2,2,0,1] 错误输出 2 ，实际上是 0 right = mid 提现了最小值一般是在右侧 考虑到存在有序的情况，单独处理 Other Answer 【直接搜索】 时间复杂度： O(n) 空间复杂度: O(1) 123456789class Solution: def minNumberInRotateArray(self, rotateArray): if not rotateArray: return 0 for i in range(1, len(rotateArray)): if rotateArray[i-1] &gt; rotateArray[i]: return rotateArray[i] return rotateArray[0] 面试题12. 矩阵中的路径Best Answer 解题思路: DFS 深度搜索 12345678910111213141516171819202122class Solution: def exist(self, board: List[List[str]], word: str) -&gt; bool: def dfs(i, j, word): if not word: return True # 已经找到 if not (0 &lt;= i &lt;= len(board) - 1 and \\ 0 &lt;= j &lt;= len(board[0]) - 1 and \\ board[i][j] == word[0]): return False flag.append((i, j)) # 加入访问过的节点 for d in dirction: ni, nj = i + d[0], j + d[1] if (ni, nj) not in flag: # 判断有无走过 if dfs(ni, nj, word[1:]): return True flag.remove((i, j)) # 走完一定要回溯回状态 return False dirction = [(-1, 0), (1, 0), (0, -1), (0, 1)] flag = [] # 标记走过的格子 for i in range(len(board)): for j in range(len(board[0])): if dfs(i, j, word): return True return False 重点元素： 终止条件 if not word: return True 不能漏掉 访问过的节点矩阵：两种实现方法 邻接矩阵表示法、稀疏矩阵标识方式 flags = [[0]*ncol for _ in range(nrow)] ，通过设置 flags[j][i] = True flags = [(1, 2), (3,4)] 一定要注意结束后 回溯状态 Graceful Answer 【精妙写法】 参考自: Krahets-Leetcode 题解 1234567891011121314151617class Solution: def exist(self, board: List[List[str]], word: str) -&gt; bool: def dfs(i, j, k): if not 0 &lt;= i &lt; len(board) or \\ not 0 &lt;= j &lt; len(board[0]) or \\ board[i][j] != word[k]: return False # 判断都放在这里 if k == len(word) - 1: return True tmp, board[i][j] = board[i][j], '/' # 直接修改原矩阵 res = dfs(i + 1, j, k + 1) or dfs(i - 1, j, k + 1) or dfs(i, j + 1, k + 1) or dfs(i, j - 1, k + 1) board[i][j] = tmp return res for i in range(len(board)): for j in range(len(board[0])): if dfs(i, j, 0): return True return False 面试题13. 机器人的运动范围My Answer【DFS 深度搜索改进】 解题思路：DFS 深度搜索 + 剪枝 上一题同样是 DFS 算法，其中提到一定要注意 状态回溯 。本题则不同，因为是求的 最多访问到的格子， 最多访问的路径 。所以 辅助矩阵 visited 是记录访问到的格子，最后返回的结果也是 len(visited) 终止条件： 下标越界、题目条件限制、节点已访问 计算节点位数和的方法可以尝试 memory 记忆矩阵做缓存 剪枝体现在：根据题意，只需要访问 右、下 两个方向即可。 1234567891011121314151617181920class Solution: def movingCount(self, m: int, n: int, k: int) -&gt; int: def cal_digit(x): if not x in memory: ret = sum([int(_) for _ in str(x)]) memory[x] = ret return memory[x] def dfs(i, j): if i &gt;= m or j &gt;=n: return # 下表越界 if cal_digit(i) + cal_digit(j)&gt; k: return # 题目条件限制 if (i, j) in visited: return # 节点已访问过 visited.append((i, j)) dfs(i + 1, j) dfs(i, j + 1) visited = [] memory = &#123;&#125; dfs(0, 0) return len(visited) 计算位数的方式： 12345678910111213141516# 循环取余def cal_digit(x): if not x in memory: ret, y = 0, x while y: ret += y % 10 y = y // 10 memory[x] = ret return memory[x]# 字符串计算def cal_digit(x): if not x in memory: ret = sum([int(_) for _ in str(x)]) memory[x] = ret return memory[x] Best Answer【DFS 深度搜索】 解题思路：DFS 搜索 + 数位和计算方式改进 参考：Krahets-解题 Krahets’s Blog 这个大神些的东西，真的比原书的作者写的解法好，而且是python版 数位和增量公式： 1s_x + 1 if (x + 1) % 10 else s_x - 8 代码如下【很精妙的写法】： 12345678910class Solution: def movingCount(self, m: int, n: int, k: int) -&gt; int: def dfs(i, j, si, sj): if i &gt;= m or j &gt;= n or k &lt; si + sj or (i, j) in visited: return 0 visited.add((i,j)) return 1 + dfs(i + 1, j, si + 1 if (i + 1) % 10 else si - 8, sj) \\ + dfs(i, j + 1, si, sj + 1 if (j + 1) % 10 else sj - 8) visited = set() return dfs(0, 0, 0, 0) Best Answer 【BFS 广度搜索】解题思路：BFS 广度搜索 12345678910class Solution: def movingCount(self, m: int, n: int, k: int) -&gt; int: queue, visited, = [(0, 0, 0, 0)], set() while queue: i, j, si, sj = queue.pop(0) if i &gt;= m or j &gt;= n or k &lt; si + sj or (i, j) in visited: continue visited.add((i,j)) queue.append((i + 1, j, si + 1 if (i + 1) % 10 else si - 8, sj)) queue.append((i, j + 1, si, sj + 1 if (j + 1) % 10 else sj - 8)) return len(visited) 面试题14- I. 剪绳子【非常经典】 参考：腐烂的橘子🍊 Answer 01 【暴力法】 下面我们手算一下 $F(4)$ 的取值是从 $F(3)\\times1, 3 \\times 1;F(2)\\times 2, 2\\times 2;F(1)\\times3, 1\\times3$ 中挑选出最大的值。可以归纳出如下递归函数 $$F(n)=max(i\\times(n-i),i\\times F(n-i)),i=1,2,…,n-2$$ 暴力法存在大量计算一定会超时，所以一般暴力法都是搭配 记忆化矩阵 一起 食用 Answer 02 【记忆化搜索】【自顶向下】 解题思路：记忆化技术（自顶向下） 递归函数中存在大量重复的计算，记忆化技术，可以帮助缩小时间，通过计算机验证 时间复杂度 $O(n^2)$ 空间复杂度 $O(n)$ 1234567891011class Solution: def cuttingRope(self, n: int) -&gt; int: def f(n): if n in memory: return memory[n] res = -1 for i in range(1, n): res = max(res, f(i) * (n - i), i * (n - i)) memory[n] = res return memory[n] memory = &#123;1: 1&#125; # 可以将终止条件设置在 记忆化矩阵中 return f(n) Best Answer 【动态规划】【自底向上】 解题思路：动态规划（自底向上）(推荐方法) 时间复杂度 O(n) 空间复杂度 O(n) 动态规划的核心是，设定边界条件 和 状态转移方程 。 建议一维动态数组 dp : 边界条件：$dp[1] = dp[2] = 1$ ，表示长度为 2 的绳子最大乘积为 1； 状态转移方程： $dp[i] = max(dp[i], max((i-j)j, jdp[i-j]))$ 12345678910class Solution: def cuttingRope(self, n: int) -&gt; int: d = [ 0 for _ in range(n + 1)] d[1], d[2] = 0, 1 for i in range(3, n+1): res = -1 for j in range(1, i // 2 + 1): res = max(res, j * (i - j), j * d[i-j]) d[i] = res return d[n] Best Answer 【动态规划空间优化】【自底向上】 同 面试题10-I 斐波那契数列一样。同样可以针对空间复杂度优化 123456789101112# 作者：z1m# 链接：https://leetcode-cn.com/problems/jian-sheng-zi-lcof/solution/xiang-jie-bao-li-di-gui-ji-yi-hua-ji-zhu-dong-tai-/class Solution: def cuttingRope(self, n): dp = [0, 1, 1] for i in range(3, n + 1): dp[i % 3] = max(max(dp[(i - 1) % 3], i - 1), 2 * max(dp[(i - 2) % 3], i - 2), 3 * max(dp[(i - 3) % 3], i - 3)) return dp[n % 3] Best Answer 【数学推导】这一部分属于数据公式的证明，可以参考如下教程，比较清晰 面试题14- I. 剪绳子（数学推导 / 贪心思想，清晰图解） 面试题15-二进制中的1 解题思路：位操作 原码、反码、补码相关概念。 原码 取反 + 1 ==&gt; 补码 教程：原码, 反码, 补码 详解 相关位运算 123n &amp; 1 # n &amp; 1 验证最后一位是否是1n &gt;&gt; 1 # 等价于 n // 2 n &amp; (n - 1) # My Answer 【无符号位】【逐位判断】 时间复杂度 $O(log_2n)$ 空间复杂度 $O(1)$ 1234567class Solution: def hammingWeight(self, n: int) -&gt; int: res = 0 while n: res += n &amp; 1 n &gt;&gt;= 1 return res Graceful Answer【无符号】【技巧法】 解题思路：技巧： n &amp; (n - 1) $(n - 1)$ 二进制最右边的 1变成0，0变成1 $n\\times(n - 1)$ 二进制最右边的 1 变成 0，其余保持不变 。每一次 $n\\times(n - 1)$都会消去一个0，直到消完为止。 时间复杂度 $O(M),M 代表数字N中1的个数$ 空间复杂度: $O(1)$ 1234567class Solution: def hammingWeight(self, n: int) -&gt; int: res = 0 while n: res += 1 n &amp;= n - 1 return res 面试题16. 数值的整数次方Best Answer 【递归法】【快速幂】 解题思路：快速幂 二分推导： 当 n 为偶数： $x^n=x^{n/2}\\times x^{n/2}$ 当 n 为奇数： $x^n=x^{n/2}\\times x^{n/2}\\times x$ 时间复杂度为 $O(log_2n)$ 空间复杂度 $O(1)$ 123456789101112class Solution: def myPow(self, x: float, n: int) -&gt; float: \"\"\" 分治法: 递归版 \"\"\" if x == 0: raise Exception(\"0 is not invalid\") if n == 0: return 1 # 这个特别容易漏 if n == 1: return x postivate_n = abs(n) temp = self.myPow(x, postivate_n &gt;&gt; 1) res = temp * temp * (x if postivate_n &amp; 1 else 1) return res if n &gt; 0 else 1/res Graceful Answer 【数学递推法】【快速幂】 解题思路： 数据递推法 + 位运算 举例 $n = 9$ ，用二进制可表示为 $n = 9 = 1001_b$$$x^9 = 1\\times x^{2^0} \\times x^{2^3}$$这里，发现 $x^{2^0} = x$， 此时公式就变成$$x^9 = 1\\times y \\times y^3$$可以发现，只要对应二进制位为 0 的话，就不乘上去。 123456789class Solution: def myPow(self, x: float, n: int) -&gt; float: pos_n = abs(n) res = 1 while pos_n: res = res * (x if (pos_n &amp; 1) else 1) pos_n = pos_n &gt;&gt; 1 x = x * x return res if n &gt; 0 else 1/res 面试题17. 打印从1到最大的n位数Simple Answer【简单版本】 题解，本题对于 Python并不是一道简单的题目。难点是如何处理 大数情况 1list(range(1, 10**n)) Hard Answer 【大数版本】【全排列】 解题思路：全排列 参考：面试题17. 打印从 1 到最大的 n 位数（分治算法 / 全排列，清晰图解） 时间复杂度 $O(10^n)$ 空间复杂度 $O(1)$ 首先实现简单的实现 两个数字0~9 的全排列。可以通过 递归 去实现 1234567891011121314151617181920# 利用递归实现 全排列问题def printNumbers(self, n: int) -&gt; [int]: def dfs(x): if x == n: # 终止条件：已固定完所有位 res.append(''.join(num)) # 拼接 num 并添加至 res 尾部 return for i in range(10): # 遍历 0 - 9 num[x] = str(i) # 固定第 x 位为 i dfs(x + 1) # 开启固定第 x + 1 位 num = ['0'] * n # 起始数字定义为 n 个 0 组成的字符列表 res = [] # 数字字符串列表 dfs(0) # 开启全排列递归 return resif __name__ == \"__main__\": res = printNumbers(2) print(res)# output: # ['00', '01', '02', '03', '04', '05', ...., '97', '98', '99'] 接下来，需要对 全排列 做一下优化，去除多余的 0 和 从1开始输出 这样的改进，感觉就是修复逻辑漏洞一样，比较考察是否细心，这里就比较见仁见智了。这里我参考的是 Krahets 给的解法。 1234567891011121314151617181920212223class Solution: def printNumbers(self, n): def dfs(x): if x == n: # 这一步复杂筛选和生产数字序列 s = ''.join(self.num)[self.digit:] # '0001' =&gt; '1' if s == '0': return # 只处理 ’0000‘ 全零的这一情况 if self.digit + self.nine == n : self.digit -= 1 self.res.append(s) return for i in range(10): # 这一步复杂生产 '00', '01', '02' 这样的序列 if i == 9: self.nine += 1 self.num[x] = str(i) dfs(x + 1) self.num = ['0'] * n self.digit = n - 1 # 代表是从最后一位开始 self.nine = 0 # 记录是不是从 9 self.res = [] dfs(0) return self.resif __name__ == \"__main__\": res = Solution().printNumbers(2) print(res) 面试题18. 删除链表的节点My Answer【单指针】12345678910111213class Solution: def deleteNode(self, head: ListNode, val: int) -&gt; ListNode: \"\"\" 单指针法 \"\"\" # 删除头结点 if head.val == val: return head.next temp = head # 非头结点 while temp and temp.next: if temp.next.val == val and temp.next: temp.next = temp.next.next temp = temp.next return head My Answer【双指针】【较为清晰】1234567891011class Solution: def deleteNode(self, head: ListNode, val: int) -&gt; ListNode: \"\"\" 双指针法 \"\"\" if head.val == val: return head.next # 如果正好是头结点 pre, cur = head, head.next while cur: if cur.val == val: pre.next = cur.next return head else: pre, cur = pre.next, cur.next Other Answer 【递归】12345class Solution: def deleteNode(self, head: ListNode, val: int) -&gt; ListNode: if not head: return head head.next = self.deleteNode(head.next, val) return head.next if head.val == val else head 面试题19. 正则表达式匹配【困难】本题的 【Hard】模式，正是因为考虑的情形比较多，很容易一些小细节漏做。尽管整理的时候已经是二次刷题了，但是还是花了 1H 调试+重写才成功 My Answer 【递归法】 解题思路：递归法 考虑到的极端情况 ab &lt;–&gt; ab ab &lt;–&gt; .* ab* 的时候，b 零次的信息很容易漏掉 终止条件： if not p: return not a 判断相等逻辑： p[0] in {s[i], &#39;.&#39;} 1234567891011121314class Solution: def isMatch(self, s: str, p: str) -&gt; bool: if not p: return not s # ab &lt;--&gt; a* 带星号的一定要先处理，不然在 s='' p='*b'的时候会出错 if len(p) &gt; 1 and p[1] == '*': if self.isMatch(s, p[2:]): return True # 零次情况考虑到 i = 0 while i &lt; len(s) and p[0] in &#123;s[i], '.'&#125;: # aaab a*b if self.isMatch(s[i+1:], p[2:]): return True i += 1 if p and s and p[0] in &#123;s[0], '.'&#125;: # ab &lt;--&gt; ab return self.isMatch(s[1:], p[1:]) else: return False 于此，我们又发现可以改进的地方 12while i &lt; len(s) and p[0] in &#123;s[i], '.'&#125;: # aaab a*b if self.isMatch(s[i+1:], p[2:]): return True 可以列一张表，看到这里的 while 循环是不必要的，因为递归程序会帮我们一次次最终走到 * 三次 的情况，不需要我们自己显式的去写出，而且就算写出了，程序也走不到。 s p value 原始 aaab a*b True * 零次 aaab b False * 一次 aab b False–&gt; * 二次 * 二次 ab b False–&gt;* 三次 * 三次 b b True 改进的代码 1234567891011class Solution: def isMatch(self, s: str, p: str) -&gt; bool: if not p: return not s # ab &lt;--&gt; a* 带星号的一定要先处理，不然在 s='' p='*b'的时候会出错 if len(p) &gt; 1 and p[1] == '*': if self.isMatch(s, p[2:]): return True # 零次情况考虑到 if p and s and p[0] in &#123;s[0], '.'&#125; and self.isMatch(s[1:], p): return True if p and s and p[0] in &#123;s[0], '.'&#125;: # ab &lt;--&gt; ab return self.isMatch(s[1:], p[1:]) else: return False Graceful Answer【递归法】【大神代码】1234567891011121314# 作者：z1m# 链接：https://leetcode-cn.com/problems/zheng-ze-biao-da-shi-pi-pei-lcof/solution/hui-su-dong-tai-gui-hua-by-ml-zimingmeng/class Solution: def isMatch(self, s: str, p: str) -&gt; bool: if not p: return not s # 第一个字母是否匹配 first_match = bool(s and p[0] in &#123;s[0],'.'&#125;) # 如果 p 第二个字母是 * if len(p) &gt;= 2 and p[1] == \"*\": return self.isMatch(s, p[2:]) or \\ first_match and self.isMatch(s[1:], p) else: return first_match and self.isMatch(s[1:], p[1:]) Graceful Answer 【倒查递归】【大神代码】1234567891011121314151617181920def isMatch(self, s: str, p: str) -&gt; bool: \"\"\" 倒查递归，思路参考 https://leetcode-cn.com/problems/zheng-ze-biao-da-shi-pi-pei-lcof/solution/zhu-xing-xiang-xi-jiang-jie-you-qian-ru-shen-by-je/ 1. 正则串是 正常字符串匹配/. s[:n-2] p[:m-2] 2. 正则串带 * a. 先直接去除 c* s,p[:m-2] b. 如果匹配*前的字符串， s[:n-1] p 3、 正常字符串 不匹配 直接返回False \"\"\" if not p : return not s if s and p[-1] in &#123;s[-1], '.'&#125;: return self.isMatch(s[:-1], p[:-1]) if p[-1] == '*': return self.isMatch(s, p[:-2]) or \\ bool(s and p[-2] in &#123;s[-1], '.'&#125; and self.isMatch(s[:-1], p)) else: return False Graceful Answer 【动态规划】 123456789101112131415161718192021222324252627282930313233# 作者：z1m# 链接：https://leetcode-cn.com/problems/zheng-ze-biao-da-shi-pi-pei-lcof/solution/hui-su-dong-tai-gui-hua-by-ml-zimingmeng/class Solution: def isMatch(self, s: str, p: str) -&gt; bool: # 边界条件，考虑 s 或 p 分别为空的情况 if not p: return not s if not s and len(p) == 1: return False m, n = len(s) + 1, len(p) + 1 dp = [[False for _ in range(n)] for _ in range(m)] # 初始状态 dp[0][0] = True dp[0][1] = False for c in range(2, n): j = c - 1 if p[j] == '*': dp[0][c] = dp[0][c - 2] for r in range(1,m): i = r - 1 for c in range(1, n): j = c - 1 if s[i] == p[j] or p[j] == '.': dp[r][c] = dp[r - 1][c - 1] elif p[j] == '*': # ‘*’前面的字符匹配s[i] 或者为'.' if p[j - 1] == s[i] or p[j - 1] == '.': dp[r][c] = dp[r - 1][c] or dp[r][c - 2] else: # ‘*’匹配了0次前面的字符 dp[r][c] = dp[r][c - 2] else: dp[r][c] = False return dp[m - 1][n - 1] 面试题21. 调整数组顺序使奇数位于偶数前面Best Answer【快排思路】【首尾双指针】 解题思路： 快排思想 主要变动的是在判断的依据上 时间复杂度 $O(n)$ 空间复杂度 $O(1)$ 12345678910111213141516class Solution: def exchange(self, nums: List[int]) -&gt; List[int]: if not nums: return [] left = 0 right = len(nums) - 1 temp = nums[left] while left &lt; right: while left &lt; right and nums[right] % 2 == 0: right -= 1 nums[left] = nums[right] while left &lt; right and nums[left] % 2 == 1: left += 1 nums[right] = nums[left] nums[right] = temp return nums 更加简单一点的写法 1234567891011# 作者：jyd# 链接：https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/solution/mian-shi-ti-21-diao-zheng-shu-zu-shun-xu-shi-qi-4/class Solution: def exchange(self, nums: List[int]) -&gt; List[int]: i, j = 0, len(nums) - 1 while i &lt; j: while i &lt; j and nums[i] &amp; 1 == 1: i += 1 while i &lt; j and nums[j] &amp; 1 == 0: j -= 1 nums[i], nums[j] = nums[j], nums[i] return nums Best Answer 【首端快慢指针】12345678910class Solution: def exchange(self, nums: List[int]) -&gt; List[int]: # 首端快慢指针 i, j, size = -1, -1, len(nums) while i &lt; size - 1: i += 1 if nums[i] &amp; 1 == 1: # 找到奇数 j += 1 nums[i], nums[j] = nums[j], nums[i] return nums Simple Answer 【辅助数组】 时间复杂度 $O(n)$ 空间复杂度 $O(n)$ 1234567class Solution: def exchange(self, nums: List[int]) -&gt; List[int]: num1, num2 = [], [] for n in nums: if n &amp; 1: num1.append(n) else: num2.append(n) return num1 + num2 面试题22. 链表中倒数第k个节点Simple Answer【辅助数组】 时间复杂度 $O(n)$ 空间复杂度 $O(n)$ 1234567class Solution: def getKthFromEnd(self, head: ListNode, k: int) -&gt; ListNode: arr = [] while head: arr.append(head) head = head.next return arr[-1*k] Best Answer 【双指针】 解题思路： 双指 ，两步走 12345678910class Solution: def getKthFromEnd(self, head: ListNode, k: int) -&gt; ListNode: h1, h2 = head, head for _ in range(k): # h1 先走 k 步 h1 = h1.next while h1: # h1 走完 h1 = h1.next h2 = h2.next # 此时 h2 走了 n-k 步，即倒数第k个节点 return h2 面试题24. 反转链表My Answer 1 【双指针头尾交换】 图参考：【反转链表】：双指针，递归，妖魔化的双指针 12345678910def reverseList(self, head: ListNode) -&gt; ListNode: \"\"\" 双指针\"\"\" pre, cur = None, head while cur: cur_next_bak = cur.next # 因为cur.next 马上要指向前节点，这里做个备份 cur.next = pre pre = cur cur = cur_next_bak return pre My Answer 2【递归】【理解有点难度】 动图来自：动画演示+多种解法 面试题24. 反转链表 12345678910class Solution: def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head cur = self.reverseList(head.next) head.next.next = head head.next = None return cur My Answer 3【辅助空间】12345678910class Solution: def reverseList(self, head: ListNode) -&gt; ListNode: ret = None while head: node = ListNode(head.val) node.next = ret ret = node head = head.next return ret 面试题25. 合并两个排序的链表【经典】Best Answer 引入一个头节点 12345678910111213141516class Solution: def mergeTwoLists(self, l1: ListNode, l2: ListNode) -&gt; ListNode: sortedList = ListNode(None) # 伪节点 head = sortedList while l1 and l2: if l2.val &gt; l1.val: node = ListNode(l1.val) sortedList.next = node l1 = l1.next else: node = ListNode(l2.val) sortedList.next = node l2 = l2.next sortedList = sortedList.next sortedList.next = l1 if l1 else l2 # 剪枝 return head.next 面试题26. 树的子结构Best Answer 【递归】 解题技巧 在 return 中，加入bool(A and B) 来代替 if not A and not B: return False ，显得更加简洁 12345678class Solution: def isSubStructure(self, A: TreeNode, B: TreeNode) -&gt; bool: def recur(A, B): if not B: return True if not A and A.val != B.val: return False # 头结点匹配成功 return recur(A.left, B.left) and recur(A.right, B.right) return bool(A and B) and # 空树不是任意一个树的子节点\\ (recur(A, B) or recur(A.left, B) or recur(A.right, B)) 面试题27. 二叉树的镜像Best Answer【递归】1234567class Solution: def mirrorTree(self, root: TreeNode) -&gt; TreeNode: if not root: return True root.left, root.right = root.right, root.left self.mirrorTree(root.left) self.mirrorTree(root.right) return root 面试题28. 对称的二叉树Best Answer 【递归】1234567891011class Solution: def isSymmetric(self, root: TreeNode) -&gt; bool: def compareTree(treeA, treeB): if not treeA and not treeB: return True if not treeA or not treeB: return False if treeA.val != treeB.val: return False return compareTree(treeA.left, treeB.right) and \\ compareTree(treeA.right, treeB.left) if not root: return True return compareTree(root.left, root.right) 面试题29. 顺时针打印矩阵My Answer 【寻找规律】 解题思路： 可以通过观察，发现每次 横向移动的时候，移动的长度会减一。纵向移动同样如此。 如一个 $3 \\times 3$ 的矩阵，规律为：向右移动3次，向下移动2次，向左移动2次，向上移动1次，向右移动1次。 我们给横向移动设置初始值值 3，纵向移动 2。每次移动完了就减一。 这里需要考虑终止条件的位置：一定是在移动之前检查本方向是否已终止 1234567891011121314151617181920212223242526class Solution: def spiralOrder(self, matrix: List[List[int]]) -&gt; List[int]: if not matrix: return [] xlen, ylen = len(matrix[0]), len(matrix) - 1 x, y = -1, 0 direction = [(1, 0), (0, 1), (-1, 0), (0, -1)] # 右下左上 dflag = 0 ret = [] while True: if not xlen: break # 在横向移动之前，检查能否移动，不能的话一定是代表结束 for _ in range(xlen): # 横向打印 x = x + direction[dflag][0] y = y + direction[dflag][1] ret.append(matrix[y][x]) xlen -= 1 dflag = (dflag + 1) % 4 if not ylen: break # 在纵向向移动之前，检查能否移动，不能的话一定是代表结束 for _ in range(ylen): # 横向打印 x = x + direction[dflag][0] y = y + direction[dflag][1] ret.append(matrix[y][x]) ylen -= 1 dflag = (dflag + 1) % 4 return ret 面试题30. 包含min函数的栈【思路经典】Best Answer 解题思路：辅助栈 123456789101112131415161718class MinStack: def __init__(self): self.A, self.B = [], [] def push(self, x: int) -&gt; None: self.A.append(x) if not self.B or self.B[-1] &gt;= x: self.B.append(x) def pop(self) -&gt; None: if self.A.pop() == self.B[-1]: self.B.pop() def top(self) -&gt; int: return self.A[-1] def min(self) -&gt; int: return self.B[-1] 面试题31. 栈的压入、弹出序列Best Answer 【模拟法】 解题思路：由于题目中假定了两个队列长度相等，栈内元素不同。这一假设大大简化了问题的复杂程度 12345678910class Solution: def validateStackSequences(self, pushed: List[int], popped: List[int]) -&gt; bool: tempList = [] for each in pushed: tempList.append(each) while tempList and tempList[-1] == popped[0]: tempList.pop() popped = popped[1:] return True if not popped else False 面试题32 - I. 从上到下打印二叉树Best Answer【经典算法】【二叉树的层次遍历】12345678910111213141516171819202122232425262728class Solution: def levelOrder(self, root: TreeNode) -&gt; List[int]: if not root : return [] res = [] queue = [root] while queue: node, queue = queue[0], queue[1:] res.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) return res # 利用 collection.deque 实现队列class Solution: def levelOrder(self, root: TreeNode) -&gt; List[int]: if not root : return [] res, queue = [], collections.deque() queue.append(root) while queue: node = queue.popleft() res.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) return res 面试题32 - II. 从上到下打印二叉树 IIBest Answer 【层次遍历升级】 解题思路： 核心解决的就是层与层的区分 通过标记层号解决 通过queue的长度来区分层 【标记层号】 123456789101112class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] res, queue = [], collections.deque() queue.append((root, 0)) while queue: node, level = queue.popleft() if level &gt; len(res) - 1: res.append([]) res[level].append(node.val) if node.left: queue.append((node.left, level + 1)) if node.right: queue.append((node.right, level + 1)) return res 【根据queue长度】 1234567891011121314class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] res, queue = [], collections.deque() queue.append(root) while queue: _res = [] for _ in range(len(queue)): node = queue.popleft() _res.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) res.append(_res) return res 面试题32 - III. 从上到下打印二叉树 III 参考：面试题32 - III. 从上到下打印二叉树 III（层序遍历 BFS / 双端队列，清晰图解） Best Answer 解题思路： 层次遍历 + 双端队列 在奇偶层节点加入上，奇数层从左端加入，偶数层在右端加入 12temp.appendleft()temp.append() 12345678910111213141516class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] queue = collections.deque() queue.append(root) res = [] while queue: temp = collections.deque() for _ in range(len(queue)): node = queue.popleft() if len(res) &amp; 1 == 0: temp.append(node.val) else: temp.appendleft(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) res.append(list(temp)) return res 层次遍历 + 奇偶逻辑分开 （略） 在出队的时候，奇数层从左端出队，偶数层从右端出队 12queue.popleft()queue.pop() 仅对 面试题32-II 的顺序进行调整 （略） 面试题33. 二叉搜索树的后序遍历序列 面试题33. 二叉搜索树的后序遍历序列（递归分治 / 单调栈，清晰图解） Best Answer 解题思路：递归分治 判断当前根是否存在错误 ，即 是否符合 左 &lt; 根 &lt; 右 self.verifyPostorder(postorder[: m]) 判断左子树是否正确 self.verifyPostorder(postorder[m : -1]) 判断右子树是否正确 12345678910111213class Solution: def verifyPostorder(self, postorder: List[int]) -&gt; bool: if not postorder: return True # 判断是否符合 左&lt;根&lt;右 root = postorder[-1] for i in range(len(postorder)): if postorder[i] &gt; root: break m = i # m 为右子树的第一个元素 for i in range(m, len(postorder) - 1): if postorder[i] &lt; root: return False # 右子树出现了比根节点小的节点。 return self.verifyPostorder(postorder[: m]) and \\ self.verifyPostorder(postorder[m : -1]) 剑指 Offer 34. 二叉树中和为某一值的路径待整理 剑指 Offer 35. 复杂链表的复制待整理 面试题36. 二叉搜索树与双向链表【困难】My Answer 【中序遍历】【辅助队列】 解题思路：中序遍历 + 辅助队列 12345678910111213141516171819class Solution: def treeToDoublyList(self, root: 'Node') -&gt; 'Node': def dfs(cur): # 中序遍历 if not cur: return [] dfs(cur.left) # 左 res.append(cur) # 中 dfs(cur.right) # 右 if not root: return None res = [] dfs(root) # 根据 队列，前后链接链表 for i in range(0, len(res) - 1): res[i].right = res[i + 1] res[i+1].left = res[i] # 头尾特殊处理 res[0].left = res[-1] res[-1].right = res[0] return res[0] Best Answer 【中序遍历】【双指针改进】 解题思路 上述方法虽然简单，但是借助了 辅助队列 ，可以利用双指针改进 1234567891011121314151617class Solution: def treeToDoublyList(self, root: 'Node') -&gt; 'Node': def dfs(cur): if not cur: return None dfs(cur.left) if self.pre: self.pre.right, cur.left = cur, self.pre else: self.head = cur # 此时记录的是头结点 self.pre = cur # 最后遍历的是尾结点 dfs(cur.right) if not root: return None self.pre = None dfs(root) self.head.left, self.pre.right = self.pre, self.head return self.head 面试题37. 序列化二叉树【困难】Best Answer 解题思路：层次遍历 我们可以根据 level 层级，限制最后生成 队列 的长度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import collectionsclass TreeNode(object): def __init__(self, x): self.val = x self.left = None self.right = Noneclass Codec: def serialize(self, root): \"\"\"Encodes a tree to a single string. :type root: TreeNode :rtype: str \"\"\" if not root: return \"[]\" res, queue = [], collections.deque() queue.append(root) level = 0 while queue: for _ in range(len(queue)): node = queue.popleft() if node: res.append(node.val) queue.append(node.left) queue.append(node.right) else: res.append(\"null\") level += 1 level -= 1 # 减一后的level是真实的 层数 res = res[:2**level - 1] return \"[\" + \",\".join([str(_) for _ in res]) + \"]\" def deserialize(self, data): \"\"\"Decodes your encoded data to tree. :type data: str :rtype: TreeNode \"\"\" if data == \"[]\": return None vals, i = data[1:-1].split(','), 1 root = TreeNode(int(vals[0])) queue = collections.deque() queue.append(root) while queue and i &lt; len(vals): node = queue.popleft() if vals[i] != \"null\": node.left = TreeNode(int(vals[i])) queue.append(node.left) i += 1 if vals[i] != \"null\": node.right = TreeNode(int(vals[i])) queue.append(node.right) i += 1 return root 面试题38. 字符串的排列【全排列】Best Answer 解题思路：回溯 + 交换 12345678910111213141516171819# 作者：jyd# 链接：https://leetcode-cn.com/problems/zi-fu-chuan-de-pai-lie-lcof/solution/mian-shi-ti-38-zi-fu-chuan-de-pai-lie-hui-su-fa-by/class Solution: def permutation(self, s: str) -&gt; List[str]: c, res = list(s), [] def dfs(x): if x == len(c) - 1: res.append(''.join(c)) # 添加排列方案 return dic = set() for i in range(x, len(c)): if c[i] in dic: continue # 重复，因此剪枝 dic.add(c[i]) c[i], c[x] = c[x], c[i] # 交换，将 c[i] 固定在第 x 位 dfs(x + 1) # 开启固定第 x + 1 位字符 c[i], c[x] = c[x], c[i] # 恢复交换 dfs(0) return res My Answer 解题思路： 回溯 + 辅助站 每一位上只能使用一次，故用 visited 矩阵 记录的位置 123456789101112131415class Solution: def permutation(self, s: str): def recur(st): if len(st) == len(s): res.append(st) return for i in range(len(s)): if i not in visited: visited.append(i) recur(st + s[i]) visited.remove(i) visited, res = [], [] recur(\"\") return list(set(res)) 面试题39. 数组中出现次数超过一半的数字 参考：https://leetcode-cn.com/problems/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi-lcof/solution/mian-shi-ti-39-shu-zu-zhong-chu-xian-ci-shu-chao-3/ 解题思路： 哈希表统计法： 遍历数组 nums ，用 HashMap 统计各数字的数量，最终超过数组长度一半的数字则为众数。此方法时间和空间复杂度均为 $O(N)$ 。 数组排序法： 将数组 nums 排序，由于众数的数量超过数组长度一半，因此 数组中点的元素 一定为众数。此方法时间复杂度 $O(N log_2 N)$ 摩尔投票法： 核心理念为 “正负抵消” ；时间和空间复杂度分别为 $O(N)$ 和 $O(1)$；是本题的最佳解法。 Best Answer 【摩尔投票法】12345678910class Solution: def majorityElement(self, nums: List[int]) -&gt; int: votes, count = 0, 0 for num in nums: if votes == 0: x = num votes += 1 if num == x else -1 # 验证 x 是否为众数 for num in nums: if num == x: count += 1 return x if count &gt; len(nums) // 2 else 0 # 当无众数时返回 0 面试题40. 最小的k个数 解题思路： 快排 + 筛选 时间复杂度: $O(N log_2 N)$， 空间复杂度 $O(1)$ 堆排 时间复制度：$O(Nlog_2k)$ ，空间复杂度 $O(N)$ My Answer1【快排】 快排 + 筛选 123456789101112131415161718# 快排 + 筛选class Solution: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: def quicksort(nums, start, end): if start &gt;= end: return pivot = nums[start] low, high = start, end while low &lt; high: while low &lt; high and nums[high] &gt;= pivot: high -= 1 nums[low] = nums[high] while low &lt; high and nums[low] &lt; pivot: low += 1 nums[high] = nums[low] nums[low] = pivot quicksort(nums, start, low - 1) quicksort(nums, low + 1, end) quicksort(arr, 0, len(arr) - 1) return arr[:k] # 筛选 上面的方法没有利用到 快排 的性质，由于每次排完之后，存在 左 &lt; 中 &lt; 右 中 == k - 1 我们已经获得了前K个元素，但是也没有排序 中 &gt; k - 1 只需要在左边找 中 &lt; k - 1 只需要在右边找 利用快排 性质 123456789101112131415161718class Solution: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: def quicksort(nums, start, end): if start &gt;= end: return pivot = nums[start] low, high = start, end while low &lt; high: while low &lt; high and nums[high] &gt;= pivot: high -= 1 nums[low] = nums[high] while low &lt; high and nums[low] &lt; pivot: low += 1 nums[high] = nums[low] nums[low] = pivot if low == k - 1: return arr[:k] elif low &lt; k - 1: quicksort(nums, low + 1, end) else: quicksort(nums, start, low - 1) My Answer2 【堆排】1234567891011121314151617181920212223242526272829class Solution: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: def adjust_heap(nums, i, size): lchild = 2 * i + 1 rchild = 2 * i + 2 max = i if i &lt; size / 2: if lchild &lt; size and nums[lchild] &gt; nums[max]: max = lchild if rchild &lt; size and nums[rchild] &gt; nums[max]: max = rchild if max != i: nums[max], nums[i] = nums[i], nums[max] adjust_heap(nums, max, size) def build_heap(nums): size = len(nums) for i in range(0, size &gt;&gt; 1)[::-1]: adjust_heap(nums, i, size) if not arr: return [] arr = [-1 * _ for _ in arr] build_heap(arr) size = len(arr) for i in range(len(arr) - 1, len(arr) - 1 - k, -1): # print(arr) arr[0], arr[i] = arr[i], arr[0] adjust_heap(arr, 0, i) arr = [-1 * _ for _ in arr][::-1] return arr[:k] 堆排可以直接使用 python 自带的 堆结构 1234567import heapqfrom random import shuffleclass Solution: def getLeastNumbers(self, arr, k: int) : shuffle(arr) # 随机排序 heapq.heapify(arr) # 建立堆结构 return heapq.nsmallest(k, arr) heapq 模块的使用 12345678910111213141516heapq.heappush(heap, item) # 添加元素heapq.heappop(heap) # 弹出元素heapq.heappushpop(heap, item) #添加元素后，再弹出一个元素，比 heappush + heappop 更高效heapq.heapreplace(heap, item) #添加元素后，返回的是原数组中最小的元素heapq.heapify(x) # 堆的初始化heapq.nlargest(n, heap) # 最大n个元素heapq.nsmallest(n, heap) # 最小n个元素# heapreplace vs heappushpop &gt;&gt;&gt; a = [2,7,4,0,8,12,14,13,10,3,4]&gt;&gt;&gt; heapify(a)&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; heappushpop(a, -1)-1&gt;&gt;&gt; heapreplace(b, -1)0 面试题41. 数据流中的中位数【困难】Best Answer【优先队列】 解题思路： 维持两个根堆，一个是大顶堆A，一个是小顶堆B。其中A的最大元素 小于 B的最小元素。 寻找中位数的思路：令m为A的长度，n为B的长度，N为总长度​ 当 m = n 时，证明N为偶数，中位数为 (A的堆顶 + B的堆顶)/2 当 m != n 时，证明N为奇数，中位数为A的堆顶(也可以取B的堆顶，类推) Tips: 为了保存中位数一直在A的堆顶，要保证A的长度始终要大于等于B。而且所有元素一定要在A，B中都调整过。 当 m = n 时，应该向A推元素，故应先推B，再推A，此时 A 有 m + 1 个，B有 n 个 当 m != n 时，应该向B推元素，因为我们始终保持的是A的数量大于B。即 m &gt;= n。故应先推A再推B，此时 A 有 m，B 有 n + 1 个 我们可以看出，先推的那个总是长度不变的，可以直接使用 heapq.hashpushpop() 方法 A 是大堆顶，故 push&amp;pop 的时候应该注意使用负数。heapq 实现了小顶堆，需要借助 负号 实现大根堆 时间复杂度：$O(logn)$。堆插入和删除需要$O(logn)$，查找中位数需要$O(1)$。空间复杂度：$O(n)$ 123456789101112131415161718192021# 作者：jyd# 链接：https://leetcode-cn.com/problems/shu-ju-liu-zhong-de-zhong-wei-shu-lcof/solution/mian-shi-ti-41-shu-ju-liu-zhong-de-zhong-wei-shu-y/class MedianFinder: def __init__(self): self.max_heap, self.min_heap = [], [] def addNum(self, num: int) -&gt; None: if len(self.max_heap) == len(self.min_heap): heapq.heappush(self.max_heap, -heapq.heappushpop(self.min_heap, num)) else: heapq.heappush(self.min_heap, -heapq.heappushpop(self.max_heap, -num)) def findMedian(self) -&gt; float: if len(self.max_heap) == len(self.min_heap): return (- self.max_heap[0] + self.min_heap[0])/2 else: return - self.max_heap[0] Best Answer【折半直接插入】 参考：腐烂的橘子🍊 图解 排序+二分查找+优先队列 解题思路： 排序法是针对无序数组，本题中最适合的排序方法是 直接插入排序，Python 自带的 bisect 已经为我们提前实现了 二分插入 Tips: 当 数组长度为奇数时，直接返回中位数：nums[len(nums)&gt;&gt;1] 当 数组长度为偶数时，直接返回平均数： (nums[len(nums)//2] + nums[len(nums)//2 +1])/2 12345678# a 查找数组；x为插入的元素；lo,hi 约定为数组的范围bisect.insort(a, x, lo=0, hi=len(a)) # 折半插入，若存在x则插入x的右侧bisect.insort_right # 同 bisect.insortbisect.insort_left # 折半插入，若存在x则插入x的左侧# 有以下三种方法，对应上面的插入方法。不同的是，它们只返回应插入的位置bisect.bisectbisect.bisect_leftbisect.bisect_right 1234567891011121314class MedianFinder: def __init__(self): self.A = [] def addNum(self, num: int) -&gt; None: bisect.insort(self.A, num) def findMedian(self) -&gt; float: size = len(self.A) if size &amp; 1 == 0: # even return (self.A[size &gt;&gt; 1] + self.A[(size &gt;&gt; 1) - 1]) / 2 else: return self.A[size &gt;&gt; 1] 面试题42. 连续子数组的最大和 参考Krahets 的 方法总结 常见解法 时间复杂度 空间复杂度 暴力搜索 $O(N^2)$ $O(1)$ 分治思想 $O(NlogN)$ $O(logN)$ 动态规划 $O(N)$ $O(1)$ 剪枝法 $O(N)$ $O(1)$ Best Answer 【暴力+剪枝】 解题思路： 只需要 保证求出的 sum 始终大于 0 即可，若是小于0，完全可以直接丢弃。 本质算是暴力法的剪枝，这种剪枝巧妙的利用了规律 123456789# 64msclass Solution: def maxSubArray(self, nums: List[int]) -&gt; int: s, ret = 0, -101 for i in nums: if s &lt; 0: s = 0 s += i ret = max(ret, s) return ret Best Answer 【动态规划】 12345678class Solution: def maxSubArray(self, nums: List[int]) -&gt; int: for i in range(1, len(nums)): nums[i] += max(nums[i - 1], 0) return max(nums)# 作者：jyd# 链接：https://leetcode-cn.com/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/solution/mian-shi-ti-42-lian-xu-zi-shu-zu-de-zui-da-he-do-2/ 上面 jyd 在处理的时候，直接在 nums 基础上进行了运算，可以说节约了 $O(N)$ 的空间使用，非常精妙 Other Answer 【分治法】 参考资料： 最大子序和（暴力法 + 分治法 + DP）- Python3 【超全·4种解法】动态规划及优化、贪心法、分治法（JavaScript实现） 解题思路： 将数组分为 2 部分。例如 [1, 2, 3, 4] 被分为 [1, 2] 和 [3, 4] 通过递归计算，得到左右两部分的最大子序列和是 lsum，rsum 从数组中间开始向两边计算最大子序列和 cross 返回 max(lsum, cross, rsum) Tips: 由于 len(nums)==1 保证了 mid=len(nums)//2 - 1 和 mid - 1 是存在的 中间值计算一定是从 mid 开始的连续值 1234567891011121314151617181920212223# 544 msclass Solution: def maxSubArray(self, nums: List[int]) -&gt; int: def crossSum(nums): mid = len(nums) // 2 - 1 left_max_sum, left_sum = nums[mid], 0 for i in nums[mid: : -1]: left_sum += i left_max_sum = max(left_max_sum, left_sum) right_max_sum, right_sum = nums[mid + 1], 0 for i in nums[mid + 1: : 1]: right_sum += i right_max_sum = max(right_max_sum, right_sum) return left_max_sum + right_max_sum if len(nums) == 1: return nums[0] mid = len(nums) &gt;&gt; 1 left_max = self.maxSubArray(nums[:mid]) right_max = self.maxSubArray(nums[mid:]) mid_max = crossSum(nums) return max(left_max, right_max, mid_max) 剑指 Offer 43. 1～n整数中1出现的次数待整理 剑指 Offer 44. 数字序列中某一位的数字待整理","categories":[{"name":"刷题","slug":"刷题","permalink":"http://ppsteven.github.io/categories/%E5%88%B7%E9%A2%98/"}],"tags":[{"name":"剑指Offer，刷题","slug":"剑指Offer，刷题","permalink":"http://ppsteven.github.io/tags/%E5%89%91%E6%8C%87Offer%EF%BC%8C%E5%88%B7%E9%A2%98/"}]},{"title":"提升 git 速度的几个加速方法","slug":"several-tips-git-speed-up","date":"2020-05-03T12:07:16.000Z","updated":"2020-06-16T08:47:15.795Z","comments":false,"path":"2020/05/03/several-tips-git-speed-up/","link":"","permalink":"http://ppsteven.github.io/2020/05/03/several-tips-git-speed-up/","excerpt":"最近经常需要从github上拉代码下来，速度实在是太慢了。所以写这篇文件，来好好总结一下提速的方法。 总的来说，方法有 替换 镜像源/修改hosts/使用国内托管平台/使用代理 经过实验下来，使用代理的效果最好","text":"最近经常需要从github上拉代码下来，速度实在是太慢了。所以写这篇文件，来好好总结一下提速的方法。 总的来说，方法有 替换 镜像源/修改hosts/使用国内托管平台/使用代理 经过实验下来，使用代理的效果最好 使用镜像源(推荐) 参考 知乎Don.hub 替换 github 镜像网站，把 github.com 替换成 github.com.cnpmjs.org 12https://github.com/graykode/nlp-tutorialhttps://github.com.cnpmjs.org/graykode/nlp-tutorial 这个方法最简单，提速效果还是很明显的。当然缺点也是很明显的，就是如果是一些不知名的项目，就没有对应的镜像源可以用了。 修改hosts（不推荐）DNS污染是GFW的一个重要手段，通过修改 hosts 文件来直接绕过DNS解析是一个不错的方法。这是一个主流的解决方法，但是实测下来效果并不显著。 第一步: 找到以下两个域名对应最快的 ip 地址 查 ip 地址： https://www.ipaddress.com 12github.global.ssl.fastly.net github.com 第二步: 将找到的对应的 ip 添加至 hosts ( 地址: /etc/hosts) 123# 举个例子213.54.23.32 github.global.ssl.fastly.net 212.44.53.42 github.com 使用国内托管平台通过国内托管平台，如码云 gitee/阿里云/oschaina 等作为中转，将代码 fork 到自己的仓库下。然后去 clone 对应仓库的repo，基本可以到达满速。 搬运教程：https://zhuanlan.zhihu.com/p/111697412 这也是一个不错的方法，就是稍微有点烦。而且对于小白来说，还容易碰到一个问题是，在使用 SSH 方式拉代码的话，需要碰到多个秘钥管理的麻烦事情。 代理服务器（选择方案）最后我采用的是这个方案，参考 这篇教程。如果你手里有一台海外的VPS，就非常简单。 本地代理加速第一步: 查看你的连接工具的监听端口 连接 VPS 的工具各不相同，这里以最常使用的 shadowssocks 为例，选择 偏好设置-&gt;高级 就可以查看 socks5 监听的端口。 第二步：设置代理转发的端口 设置全局代理 全局代理设置后，所有 git 的 http/https 都会走我们的代理端口 1234567# SOCKS5 协议，1080 端口修改成自己的本地 SOCKS5 代理端口git config --global http.proxy socks5://127.0.0.1:1080git config --global https.proxy socks5://127.0.0.1:1080# HTTP 协议，1081 端口修改成自己的本地 HTTP 代理端口git config --global http.proxy http://127.0.0.1:1081git config --global https.proxy https://127.0.0.1:1081 设置局部代理 1234567# SOCKS5 协议，1080 端口修改成自己的本地 SOCKS5 代理端口git config --global http.https://github.com.proxy socks5://127.0.0.1:1080git config --global https.https://github.com.proxy socks5://127.0.0.1:1080# HTTP 协议，1081 端口修改成自己的本地 HTTP 代理端口git config --global http.https://github.com.proxy https://127.0.0.1:1081git config --global https.https://github.com.proxy https://127.0.0.1:1081 设置后，我们可以打开 ~/.gitconfig 1234[http &quot;https://github.com&quot;] proxy = socks5://127.0.0.1:1080[https &quot;https://github.com&quot;] proxy = socks5://127.0.0.1:1080 或者 git config --global -l 查看配置是否生效 12http.https://github.com.proxy=socks5://127.0.0.1:1080https.https://github.com.proxy=socks5://127.0.0.1:1080 取消代理 123456# 取消局部代理git config --global --unset http.https://github.com.proxygit config --global --unset https.https://github.com.proxy# 取消全局代理git config --global --unset http.proxygit config --global --unset https.proxy 远程代理加速本地代理的话，对于在个人电脑上开发是很有帮助的。但是如果服务器也要 git加速 的话就比较麻烦了，还要在服务器上配置一遍本地代理。与其这样做，不如直接在服务器端开一个代理来的方便。 服务器端的基本配置1234567891011121314# 安装 shadowsockssudo pip install shadowsocks# 创建配置文件&#123; \"server\":\"*.*.*.*\", \"server_port\":***,+ \"local_server\":\"0.0.0.0\", # 默认127.0.0.1 \"local_port\":1081, \"password\":\"*****\", \"timeout\":600, \"method\":\"aes-256-cfb\"&#125;# 后台运行nohup /root/miniconda2/envs/base/bin/sslocal -c ss.json &gt;&gt; ss.log 1&gt;2&amp; 注意: 这里需要添加一行配置，0.0.0.0 表示监听所有端口，原先默认 127.0.0.1 只监听本地端口 P.S. 查看服务器绑定端口的命令: netstat -tunlp 有了远端代理，所有东西突然就方便了很多。所有的配置都只要走 x.x.x.x:1081 转发一下就可以了。因为我们本地的代理并不是会一直开着的，而远端的代理是一直存在的。 Baacloud 加速由于我是用的我弟弟的 Baacloud，这种FQ工具提供的不是一台机器，而是多台机器的地址。由于有很多人用，所以每个节点拥挤程度不同。我自己编了一个小脚本，获取每个节点的 PING 值，选择延时最低的节点连接。 具体的文章后续更新 Baacloud 优化方法 缺点经过测试下来，我的 github 拉代码的速度从 4kb 一下子提到了 100+ kb/s。有人觉得这个速度也并不快，但是实际上已经达到了速度的上线了。 我远端服务器使用的是国内腾讯云的服务器 (学生优惠时候办的)，但是只有 1M 的小水管 (带宽的上限制也就是125kb/s) ，所以 git 也到达满速了。 经过这个事情，我比较了一下国内外VPS的价格，发现除了考虑 硬盘/内存 以外，国内外的VPS带宽的差距是真的打。国内的带宽普遍是1/2M的小水管，国外的都能到达 1G。 后续我可能考虑找一个稳定的海外VPS重新搞一下。 Socks5/http/https代理的区别 作者：黎明链接：https://www.zhihu.com/question/65960461/answer/505625432来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 知乎上看到一个回答 HTTP 代理是基于 HTTP 协议的，属于应用层协议，一般只会代理转发 HTTP 请求，也可以通过CONNECT 方法来实现一般 TCP 的代理转发。 而 Socks5 代理则相对底层一些，属于 会话层协议 ，它直接通过协议握手来进行连接，并直接修改报头来实现转发，所以速度非常快，并且支持对 FTP 甚至是 UDP 进行代理转发，功能比 HTTP 代理要强大很多。 两个代理在 OSI 模型中的位置： 物理层 &lt; 数据链路层 &lt; 网络层 &lt; 传输层 &lt; 会话层[socks5] &lt; 表示层 &lt; 应用层[http] 实际使用时，一般建议是在支持的时候使用 Socks5，不支持 Socks5 的话就用 HTTP。 腾讯云被封博客写好没一天，我的这个远程代理就被腾讯云检测到了。不知道是哪个”用户”举报的我。为了解决这个方法，我感觉最好的还是买一个国外的VPS。 方案流程图为了不让腾讯云发现的话，可以选择使用 frp 代理，在腾讯云上做一个端口转发，发到我家里闲置的电脑上，然后在本地搭代理。这样饶了一圈，会特别烦，但是应该可以躲避腾讯云的监控（虽然我不知道怎么被发现的）。 此外，socks5 代理开启的时候，最好要加上演验证策略。 参考资料Git 命令行加速 Socks5/http/https代理的区别 知乎上还有一位大佬深入整理了一套代理的技术文章 由浅入深写代理(3) -socks5 代理","categories":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"},{"name":"代理","slug":"代理","permalink":"http://ppsteven.github.io/tags/%E4%BB%A3%E7%90%86/"}]},{"title":"Python并发编程——多进程编程 multiprocessing 模块","slug":"python-multiprocessing-basic","date":"2020-04-05T04:27:57.000Z","updated":"2020-06-06T19:12:51.853Z","comments":false,"path":"2020/04/05/python-multiprocessing-basic/","link":"","permalink":"http://ppsteven.github.io/2020/04/05/python-multiprocessing-basic/","excerpt":"Python 并发编程可以分为三块：多进程编程，多线程编程，多协程编程。前两者是由于操作系统控制的，协程是由用户控制。所以在多进程的编程上，不同操作系统的效果不一样。如果是为了学习多进程编辑，建议在Mac Os 或者 Linux 上。 本篇介绍基于进程的并行操作，主要用到的模块是 multiprocessing","text":"Python 并发编程可以分为三块：多进程编程，多线程编程，多协程编程。前两者是由于操作系统控制的，协程是由用户控制。所以在多进程的编程上，不同操作系统的效果不一样。如果是为了学习多进程编辑，建议在Mac Os 或者 Linux 上。 本篇介绍基于进程的并行操作，主要用到的模块是 multiprocessing 简单多进程编程简单多进程用 Process 和 Pool 两个基础类就可以实现 Process123456789from multiprocessing import Processdef f(name): print('hello', name)if __name__ == '__main__': p = Process(target=f, args=('bob',)) p.start() # 启动进程 p.join() # 阻塞进程，只有当本次进程完成后才运行下一进程。进程同步逻辑。 下面我们可以详细看看 Process 类的属性，构造方法和方法 构造方法1class multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *, daemon=None) group 兼容逻辑，始终设置为None target 目标函数 args, kwargs 传入目标函数的参数，列表参数和字典参数 name 进程名称 daemon 后台运行，守护进程。若 daemon =True，该进程会一直存在于主进程中，伴随着父进程终止而终止。 Tips： 守护进程 主进程结束后，子进程不一定会运行结束。如果我们需要让父进程终止的时候，可以设置子进程为守护进程。注意的是，守护进程不能够再创造子进程了。 12multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *, daemon=True) # 创建Process类时设置p.daemon = True # 主动设置deemon 属性 属性 pid 进程ID name 进程名 deamon 设置后台守护进程 exitcode 子进程退出代码。如果进程尚未终止，这将是 None 。负值 -N 表示孩子被信号 N 终止。 我们可以轻松的通过访问任一 Process 类的变量获取基本信息 12multiprocessing.current_process().pidmultiprocessing.current_process().name 方法 run() 进程活动的方法 通过重载 run 方法实现进程 12345678910111213141516import multiprocessingclass MyProcess(multiprocessing.Process): def __init__(self): super().__init__() def run(self): name = multiprocessing.current_process().name pid = multiprocessing.current_process().pid print(f'name:&#123;name&#125;, pid:&#123;pid&#125;')if __name__ == '__main__': p = MyProcess() p.start() p.join() 需要注意的是，尽管我们修改的是 run 方法。我们启动进程的方法还是 p.start start() 启动进程 join([timeout]) 进程阻塞，直到进程终止。 timeout 是阻塞的时间，默认None，一直阻塞直到进程终止。 is_alive() 进程存在返回 True， 否则 False terminate()/kill() 在Unix上，这是使用 SIGTERM 信号完成的 close() 关闭 Process对象，释放与之关联的所有资源 Pool如果需要运行多个子进程，采用进程池 Pool 的方式可以节省程序开销。进程的创建和销毁都是需要操作系统资源的。 进程池Pool vs Process12345678910111213141516171819202122232425262728293031import multiprocessingimport osdef worker(msg): print(\"%s is now running, process id: %s\" % (msg, os.getpid()))if __name__ == \"__main__\": po = multiprocessing.Pool(4) for i in range(10): po.apply_async(worker, args=(i,)) print(\"main process starting....\") po.close() po.join() print(\"main process stoping....\")''' 输出main process starting....0 is now running, process id: 34361 is now running, process id: 34372 is now running, process id: 34384 is now running, process id: 34363 is now running, process id: 34395 is now running, process id: 34376 is now running, process id: 34387 is now running, process id: 34368 is now running, process id: 34379 is now running, process id: 3439main process stoping....''' 使用进程池的优点提现在 限制同一时间进程并行的数目多进程可以提高程序运行的效率，但是过多的进程切换反而会降低效率。原因是a.进程会占用计算机资源，资源决定了进程不能开启过多。b.进程的切换开销比较大，占用过多CPU资源。 进程池减少不必要的创建，销毁过程。 程序中，Pool(4) 的进程号只有 3436，3437，3438，3439 这四个进程号。证明进程池省去了创建和销毁的过程。 当进程数和计算机的内核数一致的时候，效率最高。我们可以先看看自己计算机的内核个数，使用 os.cpu_count() 或者 multiprocess.cpu_count() 来查看内核个数。如果不填写内核参数，Pool 默认采取机器的内核个数。 1234567from multiprocessing import Poolp = Pool(4)for i in range(5): p.apply_async(f, args=(i,)) # 异步调用 p.apply(f, args=(i,)) # 同步调用p.close()p.join() 构造方法12class multiprocessing.pool.Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])# 一个进程池对象，它控制可以提交作业的工作进程池。它支持带有超时和回调的异步结果，以及一个并行的 map 实现。 processes 进程数，默认采用 os.cpu_count() initializer(*initargs) 进程池调用前的初始化方法 方法 apply(func[, args[, kwds]]) 返回结果前阻塞。这种情况下，apply_async() 更适合并行化工作。另外 func 只会在一个进程池中的一个工作进程中执行。 apply_async(func[, args[, kwds[, callback[, error_callback]]]]) 非阻塞操作 callback 是一个只接受一个参数的可调用对象。成功则执行callback，失败执行 error_callback map(func, iterable[, chunksize]) 内置函数 map 的并行版本，map会 保持阻塞 直到获得结果。 iterable 可以切分成多块运行，chunksize 指定块的大小。 当 iterable 太大的时候，为了节省内存，可以使用 imap 和 imap_unordered map_async(func, iterable[, chunksize[, callback[, error_callback]]]) map 的对应的异步回调方法 imap(func, iterable[, chunksize] 需要显式的设置 chunksize，可以极大的加快 map 的速度。原先map中的默认值为1。 imap_unordered imap 的无序版本 apply_async 和 map_async 除了是异步执行的以外，它们还会放回一个 AsyncResult 对象，它有如下方法 get([timeout]) 获取执行的结果 wait([timeout]) 阻塞，直到返回结果 ready 是否已完成结果 successful 是否已完成且没有发生异常 进程间通信——数据传递multiprocessing 支持两种通信方式：Queue(队列) , Pipe(管道) 基础用法12345678910q = Queue(maxsize=4)q.put(obj, block=True, timeout=None) # 存入队列中q.get(obj, block=False) # 读取队列# block: 是否主动阻塞，阻塞的时间为timeout。timeout=None 代表一直阻塞。block为 False 的时候，会主动抛出 queue.Full 和 queue.Empty 的错误。# Pipe 建立的是一个双全工的连接parent_conn, child_conn = Pipe()parent_conn.send([42, None, 'hello']) # 发送parent_conn.close() # 关闭 一端的连接，关闭后不可以再次进行 send 和 recv 操作child_conn.recv() # 接收 可以看出，Pipe 是只能在两个进程进行通信，而 Queue 可以支持多个队列。Pipe 解决了进程之间的通信问题，Queue 还加上了一个缓冲区的作用。 那么multiprocessing.Queue 和 标准库中的 queue 的区别是什么？ 需要注意的是这里是多进程编程，进程是资源分配的最小单位。不同的进程是无法获取对方堆栈的。Queue 可以解决这一个数据共享的问题。如果我们现在采用的是多线程编程，那么就可以直接采用标准库的queue 来替代。 multiprocessing 中的 Queue 实现了标准库中的 queue 中的所有方法，除了task_done 和 join 方法 Pipe 的使用1234conn1, conn2 = multiprocessing.Pipe([duplex])# 返回 Connection 对象 conn1,conn2 分别代表管道的两端。Connection 类型while conn1.poll(): conn1.recv() duplex: True 代表双全工，即管道的两端是可以双向的通信的。False 代表单向， conn1 只能用于接收消息，而 conn2 仅能用于发送消息。 Connect 对象的方法有 send/recv 发送的对象必须是可序列化的 send_bytes(buffer[, offset[, size]]) / recv_bytes([maxlength]) / recv_bytes_into(buffer[, offset]) 发送 和 接受 bytes-like object 字节类对象 poll([timeout]) 返回连接对象中是否有可以读取的数据 close() 关闭 注意的一点是，Connect 的仅仅支持少量数据的发送，对于多大的对象（32M+），可能会引发异常 Queue 的使用1class multiprocessing.Queue([maxsize]) 主要实现了如下属性&amp;方法，基本和 queue 一样 qsize 队列大小，由于是多进程的上下文，这个数字不是很可靠，而且在Mac OS X 上可能存在异常。 empty 是否为空 full 是否为满 put(obj[, block[, timeout]]) 当没有可用缓冲槽的时，抛出 queue.Empty 异常 put_nowait(obj) 等价于 put(obj, False) get([block[, timeout]]) 当没有可取用对象时，抛出 queue.Empty 异常 get_nowait() 等价于 get(False) close() 指示当前进程将不会再往队列中放入对象 Queue的几种变形 multiprocessing.SimpleQueue() 简化的队列，其只具有empty、get、put3个方法。 这个队列实际上是用 Pipe 实现的 multiprocessing.JoinableQueue(maxsize=0) 建立可阻塞的队列实例，采用一般队列的方式访问。加上了 join 和 task_done 两个方法。 进程间通信——数据共享进程间的通信 Pipe 和 Queue 能解决小批量数据的传输，如 Pipe.send() 方法发送的数据一般不超过 32M。对于大量的数据，可以借助 共享内存 和 Manager 类实现。Manager实现了两个重要的类型 list 和 dict。 Manager 类（共享进程）123456789101112131415161718192021222324252627282930import multiprocessingimport timedef f(list, x): print(list, x) list.append(x)if __name__ == '__main__': manager = multiprocessing.Manager() mag_list = manager.list([]) with multiprocessing.Pool(4) as p: for item in [1, 2, 3]: p.apply(f, args=(mag_list, item)) p.close() print(mag_list)# output: # [] 1# [1] 2# [1, 2] 3# [1, 2, 3]# 可以尝试 mag_list=[] ,最后的结果是不会发生任何变化# [] 1# [] 2# [] 3# [] Value, Array（共享内存）12multiprocessing.Value(typecode_or_type, *args, lock=True)multiprocessing.Array(typecode_or_type, size_or_initializer, *, lock=True) typecode_or_type 类型码 size_or_initializer 大小，或者初始化操作 12multiprocessing.Array('i', 3) # 结果 [0,0,0]multiprocessing.Array('i', range(3)) # 结果 [0,1,2] Lock 锁操作，在修改访问数据的时候，通过设置为 True 能锁定资源，阻塞其他进程的访问。 例子123v = multiprocessing.Value('d', 10, lock=True)with v.get_lock(): # 修改值前，加锁 v.value += 1 # 属性 value 取值 数据进程锁上一部分解决了进程间共享数据的操作。但是不同进程若是需要对于共享数据进行修改，可能会发生冲突。解决这一类问题的方式就是在 重要数据修改的时候加上锁，修改完毕再释放。 multiprocessing 的 互斥&amp;同步操作有： Lock, Semaphore , Event 和 Barrier Lock 原始锁原始锁（非递归锁）对象，一旦一个进程或者线程拿到了锁，后续的任何其他进程或线程的其他请求都会被阻塞直到锁被释放。任何进程或线程都可以释放锁。 Lock 一般只针对一个资源同步访问 RLock 递归锁递归锁必须由持有线程、进程亲自释放。递归锁和原始锁的区别是，一个进程可以多次加锁，每次加锁，锁加一。每次释放，锁减一。所以当获得锁和释放锁的数量相等的时候，才能释放锁住的资源。使用方法和Lock 一样。 Semaphore 信号量Semaphore 一般是针对多个(有限)资源的访问的，它的操作和Lock一样。只是初始化的时候，需要给出型号量的初始值。可以认为Semaphore(1) 和 RLock是相同的。 上面三个锁的使用方法都可以使用 acquire/release 操作 Barrier 屏障当若干个进程没有到达屏障点的时候，会自动阻塞，一旦到达屏障点，将会自动解除阻塞并启动运行 1class threading.Barrier(parties, action=None, timeout=None) parties 栅栏的个数 action 当突破栅栏后，会在被释放的其中一个进程中运行 属性 n_waiting 当前时刻正在栅栏中阻塞的线程数量。 broken 值为 True 表明栅栏为破损态。 方法 wait(timeout=None) 阻塞操作，函数会返回一个范围在 0~parties-1 内的整数。当为0 的时候，代表栅栏破裂 reset() 重置为初始状态 abort() 与reset() 相反，设置为破损状态 Event 事件锁这是线程之间通信的最简单机制之一：一个线程发出事件信号，而其他线程等待该信号。 方法 is_set() 判断内部标识位是否为True set() 设置内部标识位为True clear() 设置内部标识位为False wait() 阻塞线程直到内部变量为true。如果调用时内部标志为true，将立即返回。否则将阻塞线程， 例子由于之前没有接触过Event，这里自己练手写了一个Event 的小例子。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import multiprocessingimport timedef car(e, car_id): print(f'car &#123;car_id&#125; is coming ') if not e.is_set(): print(f'car &#123;car_id&#125; is waiting') e.wait() if e.is_set(): print(f'car &#123;car_id&#125; pass the cross road')def traffic_light(e): \"\"\" 红绿灯切换的时候，e.clear 和 e.set 是成队出现的。 因为红绿本省就是相互同步的一个操作 \"\"\" while True: # 每5秒切换一次红绿灯 if e.is_set(): time.sleep(2) print('&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; green to red &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;') e.clear() if not e.is_set(): time.sleep(2) print('&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; red to green &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;') e.set()if __name__ == '__main__': event = multiprocessing.Event() event.clear() # 默认设置红灯 cars = [multiprocessing.Process(target=car, args=(event,car_id)) for car_id in range(10)] lights = multiprocessing.Process(target=traffic_light, args=(event,)) lights.daemon = True # 设置完这一步，可以在小汽车都开走后，结束整个程序。 lights.start() for each in cars: each.start() time.sleep(1) # 间隔一秒钟发车 for each in cars: each.join() # 当 each.join 执行完毕，此时 traffic_light 还在后台运行 # 但是由于没有添加 traffic_light.join() 所以此时 mian 结束，带着守护进程 traffic_light一起结束# 输出结果如下car 0 is coming car 0 is waitingcar 1 is coming car 1 is waiting&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; red to green &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;....&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; green to red &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;car 8 is coming car 8 is waitingcar 9 is coming car 9 is waiting&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; red to green &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;car 8 pass the cross roadcar 9 pass the cross road 如果我们不启动守护进程，而是一直让程序在后台运行。这样我们可以感受到 守护进程 的作用 12345678910111213141516171819 cars = [multiprocessing.Process(target=car, args=(event,car_id)) for car_id in range(10)] lights = multiprocessing.Process(target=traffic_light, args=(event,))- lights.daemon = True # 设置完这一步，可以在小汽车都开走后，结束整个程序。 lights.start() for each in cars: each.start() time.sleep(1) # 间隔一秒钟发车 for each in cars: each.join()+ lights.join() # # 输出结果如下&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; red to green &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;car 9 pass the cross roadcar 8 pass the cross road&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; green to red &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; red to green &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; green to red &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; red to green &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Condition 条件锁几种方法的比较 方法 名称 作用 Lock 原始锁 当多个进程需要访问共享资源的时候，、 RLock 递归锁 Lock 的升级 Semaphore 信号量（计数器锁） Semaphore用来控制对共享资源的访问数量，例如池的最大连接数。 Barrier 时间锁 进程间同步通信 Barrier 障碍锁 等待足够资源启动 参考资料python官方文档 B站【李兴华编程训练营】Python并发编程 知乎python并行计算（上）：multiprocessing、multiprocess模块","categories":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/tags/python/"},{"name":"multiprocessing","slug":"multiprocessing","permalink":"http://ppsteven.github.io/tags/multiprocessing/"}]},{"title":"mysql 常用命令","slug":"mysql-freq-command","date":"2020-03-01T14:38:46.000Z","updated":"2020-06-13T13:17:22.370Z","comments":false,"path":"2020/03/01/mysql-freq-command/","link":"","permalink":"http://ppsteven.github.io/2020/03/01/mysql-freq-command/","excerpt":"慢慢总结常用的的mysql 命令，看做是平时工作的“缓存”","text":"慢慢总结常用的的mysql 命令，看做是平时工作的“缓存” 修改密码强度修改密码强度一般是mysql5.7 升级到 mysql8.0，或者是刚刚安装mysql8.0时候很容易碰到的问题。 12345678# 查看密码需要满足的条件SHOW VARIABLES LIKE &apos;validate_password%&apos;; # validate_password_policy代表密码策略，默认是1：符合长度，且必须含有数字，小写或大写字母，特殊字符。设置为0判断密码的标准就基于密码的长度了。一定要先修改两个参数再修改密码set global validate_password.policy=0;# validate_password_length代表密码长度，最小值为4set global validate_password.length=4; yum安装mysql 下载速度慢12345678910# 备份系统自带yum源配置文件mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 下载ailiyun的yum源配置文件(阿里云速度比较快)wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 生成缓存yum makecache# yum 升级yum -y update# 安装yumyum install -y mysql-server 创建新的用户123456789101112# 创建新用户 reader01， 赋予密码&apos;onlyread@123&apos;CREATE USER `reader01`@`%` IDENTIFIED by &apos;onlyread@123&apos;;# 赋予 select 权限， 赋予nongwei_syn所有数据表的访问权限GRANT SELECT ON `nongwei_syn`.* TO `reader01`@`%` ;# 降低 mysql 加密规则ALTER USER `reader01`@`%` IDENTIFIED WITH mysql_native_password BY &apos;onlyread@123&apos;;# 刷新一下权限flush privileges;# 查看用户的权限show grants for reader01;GRANT USAGE ON *.* TO `reader01`@`%`GRANT SELECT ON `nongwei_syn`.* TO `reader01`@`%` 数据字典显示显示字段的详细信息（包含COMMENT） 1show full columns from d_dbname.t_table_name 建议每次建表的时候，都带上COMMENT 如果你一开始并没有这样做的话，需要借助 alter 来添加 COMMENT 1alter table `d_dbname`.`t_table_name` modify column foodtype varchar(20) COMMENT &apos;品种&apos;; 显示建表的SQL 1234567891011121314151617show create table `d_dbname`.`t_table_name`# output:CREATE TABLE `t_vegnet_price_202003` ( `id` int NOT NULL AUTO_INCREMENT COMMENT &apos;序号&apos;, `foodtype` varchar(20) DEFAULT NULL COMMENT &apos;品种&apos;, `market` varchar(30) DEFAULT NULL COMMENT &apos;批发市场&apos;, `lprice` float(10,2) DEFAULT NULL COMMENT &apos;最低价&apos;, `hprice` float(10,2) DEFAULT NULL COMMENT &apos;最高价&apos;, `avgprice` float(10,2) DEFAULT NULL COMMENT &apos;平均价&apos;, `unit` varchar(20) DEFAULT NULL COMMENT &apos;计量单位&apos;, `date` varchar(10) DEFAULT NULL COMMENT &apos;日期&apos;, `pagenum` int DEFAULT NULL COMMENT &apos;页码&apos;, `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, PRIMARY KEY (`id`), UNIQUE KEY `date` (`date`,`foodtype`,`market`)) ENGINE=InnoDB AUTO_INCREMENT=42501 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci","categories":[{"name":"mysql","slug":"mysql","permalink":"http://ppsteven.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://ppsteven.github.io/tags/mysql/"}]},{"title":"【转载】 mysql触发器trigger 实例详解","slug":"转载/mysql触发器trigger 实例详解","date":"2020-02-29T17:35:50.000Z","updated":"2020-02-29T18:47:35.334Z","comments":false,"path":"2020/03/01/转载/mysql触发器trigger 实例详解/","link":"","permalink":"http://ppsteven.github.io/2020/03/01/%E8%BD%AC%E8%BD%BD/mysql%E8%A7%A6%E5%8F%91%E5%99%A8trigger%20%E5%AE%9E%E4%BE%8B%E8%AF%A6%E8%A7%A3/","excerpt":"mysql触发器trigger 实例详解MySQL好像从5.0.2版本就开始支持触发器的功能了，本次博客就来介绍一下触发器，首先还是谈下概念性的东西吧： 什么是触发器触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性。 举个例子，比如你现在有两个表【用户表】和【日志表】，当一个用户被创建的时候，就需要在日志表中插入创建的log日志，如果在不使用触发器的情况下，你需要编写程序语言逻辑才能实现，但是如果你定义了一个触发器，触发器的作用就是当你在用户表中插入一条数据的之后帮你在日志表中插入一条日志信息。当然触发器并不是只能进行插入操作，还能执行修改，删除。","text":"mysql触发器trigger 实例详解MySQL好像从5.0.2版本就开始支持触发器的功能了，本次博客就来介绍一下触发器，首先还是谈下概念性的东西吧： 什么是触发器触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性。 举个例子，比如你现在有两个表【用户表】和【日志表】，当一个用户被创建的时候，就需要在日志表中插入创建的log日志，如果在不使用触发器的情况下，你需要编写程序语言逻辑才能实现，但是如果你定义了一个触发器，触发器的作用就是当你在用户表中插入一条数据的之后帮你在日志表中插入一条日志信息。当然触发器并不是只能进行插入操作，还能执行修改，删除。 创建触发器创建触发器的语法如下： 123456789CREATE TRIGGER trigger_name trigger_time trigger_event ON tb_name FOR EACH ROW trigger_stmttrigger_name：触发器的名称tirgger_time：触发时机，为BEFORE或者AFTERtrigger_event：触发事件，为INSERT、DELETE或者UPDATEtb_name：表示建立触发器的表明，就是在哪张表上建立触发器trigger_stmt：触发器的程序体，可以是一条SQL语句或者是用BEGIN和END包含的多条语句所以可以说MySQL创建以下六种触发器：BEFORE INSERT,BEFORE DELETE,BEFORE UPDATEAFTER INSERT,AFTER DELETE,AFTER UPDATE 其中，触发器名参数指要创建的触发器的名字 BEFORE和AFTER参数指定了触发执行的时间，在事件之前或是之后 FOR EACH ROW表示任何一条记录上的操作满足触发事件都会触发该触发器 创建有多个执行语句的触发器12345CREATE TRIGGER 触发器名 BEFORE|AFTER 触发事件ON 表名 FOR EACH ROWBEGIN 执行语句列表END 其中，BEGIN与END之间的执行语句列表参数表示需要执行的多个语句，不同语句用分号隔开 tips：一般情况下，mysql默认是以 ; 作为结束执行语句，与触发器中需要的分行起冲突 为解决此问题可用DELIMITER，如：DELIMITER ||，可以将结束符号变成|| 当触发器创建完成后，可以用DELIMITER ;来将结束符号变成; 1234567891011mysql&gt; DELIMITER ||mysql&gt; CREATE TRIGGER demo BEFORE DELETE -&gt; ON users FOR EACH ROW -&gt; BEGIN -&gt; INSERT INTO logs VALUES(NOW()); -&gt; INSERT INTO logs VALUES(NOW()); -&gt; END -&gt; ||Query OK, 0 rows affected (0.06 sec)mysql&gt; DELIMITER ; 上面的语句中，开头将结束符号定义为||，中间定义一个触发器，一旦有满足条件的删除操作 就会执行BEGIN和END中的语句，接着使用||结束 最后使用DELIMITER ; 将结束符号还原 tigger_event： load data语句是将文件的内容插入到表中，相当于是insert语句，而replace语句在一般的情况下和insert差不多，但是如果表中存在primary 或者unique索引的时候，如果插入的数据和原来的primary key或者unique相同的时候，会删除原来的数据，然后增加一条新的数据，所以有的时候执行一条replace语句相当于执行了一条delete和insert语句。 触发器可以是一条SQL语句，也可以是多条SQL代码块，那如何创建呢？ 12345678DELIMITER $ #将语句的分隔符改为$BEGINsql1;sql2;...sqlnEND $DELIMITER ; #将语句的分隔符改回原来的分号&quot;;&quot; 在BEGIN…END语句中也可以定义变量，但是只能在BEGIN…END内部使用： 12DECLARE var_name var_type [DEFAULT value] #定义变量，可指定默认值SET var_name = value #给变量赋值 NEW和OLD的使用: 根据以上的表格，可以使用一下格式来使用相应的数据： 12NEW.columnname：新增行的某列数据OLD.columnname：删除行的某列数据 说了这么多现在我们来创建一个触发器吧！ 现在有表如下：用户users表 1234567CREATE TABLE `users` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(255) CHARACTER SET utf8mb4 DEFAULT NULL, `add_time` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `name` (`name`(250)) USING BTREE) ENGINE=MyISAM AUTO_INCREMENT=1000001 DEFAULT CHARSET=latin1; 日志logs表： 12345CREATE TABLE `logs` ( `Id` int(11) NOT NULL AUTO_INCREMENT, `log` varchar(255) DEFAULT NULL COMMENT &apos;日志说明&apos;, PRIMARY KEY (`Id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&apos;日志表&apos;; 需求是：当在users中插入一条数据，就会在logs中生成一条日志信息。 创建触发器： 12345678910DELIMITER $CREATE TRIGGER user_log AFTER INSERT ON users FOR EACH ROWBEGINDECLARE s1 VARCHAR(40)character set utf8;DECLARE s2 VARCHAR(20) character set utf8;#后面发现中文字符编码出现乱码，这里设置字符集SET s2 = &quot; is created&quot;;SET s1 = CONCAT(NEW.name,s2); #函数CONCAT可以将字符串连接INSERT INTO logs(log) values(s1);END $DELIMITER ; 这里我用的navicat: 查看触发器SHOW TRIGGERS语句查看触发器信息 Tip: 12上面我用的navicat直接创建，如果大家用的mysql front，name这里会有个区别，我们删除刚才的触发器，在Mysql front中测试drop trigger user_log;#删除触发器 打开Mysql Front： mysql front在编译sql时，不用定义结尾分隔符，修改后的sql直接这样既可： 12345678910#DELIMITER $CREATE TRIGGER user_log AFTER INSERT ON users FOR EACH ROWBEGINDECLARE s1 VARCHAR(40)character set utf8;DECLARE s2 VARCHAR(20) character set utf8;SET s2 = &quot; is created&quot;;SET s1 = CONCAT(NEW.name,s2); #函数CONCAT可以将字符串连接INSERT INTO logs(log) values(s1);END #$#DELIMITER ; 这里再啰嗦几句： tips：SHOW TRIGGERS语句无法查询指定的触发器 在triggers表中查看触发器信息1SELECT * FROM information_schema.triggers; 结果显示了所有触发器的详细信息，同时，该方法可以查询制定触发器的详细信息 1SELECT * FROM information_schema.triggers WHERE TRIGGER_NAME=&apos;user_log&apos;; tips：所有触发器信息都存储在information_schema数据库下的triggers表中 可以使用SELECT语句查询，如果触发器信息过多，最好通过TRIGGER_NAME字段指定查询 回到上面,我们创建好了触发器,继续在users中插入数据并查看数据： 1insert into users(name,add_time) values(&apos;周伯通&apos;,now()); 好吧，我们再来查看一下logs表吧！ 通过上面的例子，可以看到只需要在users中插入用户的信息，日志会自动记录到logs表中，这也许就是触发器给我带来的便捷吧！ 限制和注意事项触发器会有以下两种限制： 1.触发程序不能调用将数据返回客户端的存储程序，也不能使用采用CALL语句的动态SQL语句，但是允许存储程序通过参数将数据返回触发程序，也就是存储过程或者函数通过OUT或者INOUT类型的参数将数据返回触发器是可以的，但是不能调用直接返回数据的过程。 2.不能再触发器中使用以显示或隐式方式开始或结束事务的语句，如START TRANS-ACTION,COMMIT或ROLLBACK。 注意事项：MySQL的触发器是按照BEFORE触发器、行操作、AFTER触发器的顺序执行的，其中任何一步发生错误都不会继续执行剩下的操作，如果对事务表进行的操作，如果出现错误，那么将会被回滚，如果是对非事务表进行操作，那么就无法回滚了，数据可能会出错。 总结触发器是基于行触发的，所以删除、新增或者修改操作可能都会激活触发器，所以不要编写过于复杂的触发器，也不要增加过得的触发器，这样会对数据的插入、修改或者删除带来比较严重的影响，同时也会带来可移植性差的后果，所以在设计触发器的时候一定要有所考虑。 触发器是一种特殊的存储过程，它在插入，删除或修改特定表中的数据时触发执行，它比数据库本身标准的功能有更精细和更复杂的数据控制能力。 数据库触发器有以下的作用： 1.安全性。可以基于数据库的值使用户具有操作数据库的某种权利。 # 可以基于时间限制用户的操作，例如不允许下班后和节假日修改数据库数据。 # 可以基于数据库中的数据限制用户的操作，例如不允许股票的价格的升幅一次超过10%。 2.审计。可以跟踪用户对数据库的操作。 # 审计用户操作数据库的语句。 # 把用户对数据库的更新写入审计表。 3.实现复杂的数据完整性规则 # 实现非标准的数据完整性检查和约束。触发器可产生比规则更为复杂的限制。与规则不同，触发器可以引用列或数据库对象。例如，触发器可回退任何企图吃进超过自己保证金的期货。 # 提供可变的缺省值。 4.实现复杂的非标准的数据库相关完整性规则。触发器可以对数据库中相关的表进行连环更新。例如，在auths表author_code列上的删除触发器可导致相应删除在其它表中的与之匹配的行。 # 在修改或删除时级联修改或删除其它表中的与之匹配的行。 # 在修改或删除时把其它表中的与之匹配的行设成NULL值。 # 在修改或删除时把其它表中的与之匹配的行级联设成缺省值。 # 触发器能够拒绝或回退那些破坏相关完整性的变化，取消试图进行数据更新的事务。当插入一个与其主健不匹配的外部键时，这种触发器会起作用。例如，可以在books.author_code 列上生成一个插入触发器，如果新值与auths.author_code列中的某值不匹配时，插入被回退。 5.同步实时地复制表中的数据。 6.自动计算数据值，如果数据的值达到了一定的要求，则进行特定的处理。例如，如果公司的帐号上的资金低于5万元则立即给财务人员发送警告数据。 无论从事什么行业，只要做好两件事就够了，一个是你的专业、一个是你的人品，专业决定了你的存在，人品决定了你的人脉，剩下的就是坚持，用善良專業和真诚赢取更多的信任。 分类: mysql笔记 标签: mysql","categories":[{"name":"mysql","slug":"mysql","permalink":"http://ppsteven.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://ppsteven.github.io/tags/mysql/"},{"name":"转载","slug":"转载","permalink":"http://ppsteven.github.io/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"数据库同步","slug":"数据库同步","permalink":"http://ppsteven.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8C%E6%AD%A5/"}]},{"title":"docker搭建elasticsearch+kibana","slug":"docker-elasticsearch-Kibana-installation","date":"2020-02-25T01:10:44.000Z","updated":"2020-02-25T03:24:08.469Z","comments":false,"path":"2020/02/25/docker-elasticsearch-Kibana-installation/","link":"","permalink":"http://ppsteven.github.io/2020/02/25/docker-elasticsearch-Kibana-installation/","excerpt":"工作中需要对公司的es服务器进行配置，小白不敢直接在公司的开发机上直接修改。故需要在测试机上临时搭建一个es+kibana环境。 为了避开基础的环境问题和快速搭建，docker是我们非常好的伙伴","text":"工作中需要对公司的es服务器进行配置，小白不敢直接在公司的开发机上直接修改。故需要在测试机上临时搭建一个es+kibana环境。 为了避开基础的环境问题和快速搭建，docker是我们非常好的伙伴 elasticsearch安装1docker pull elasticsearch:6.6.1 创建配置文件 12345# vim /etc/elasticsearch.ymlcluster.name: \"docker-cluster\"network.host: 0.0.0.0# 允许任何端口访问transport.host: 0.0.0.0 启动容器 1docker run -di --name=es -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /etc/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml elasticsearch:6.6.1 开放了9300端口 挂载配置文件：/usr/share/elasticsearch/config/elasticsearch.yml 查看容器是否启动，以及端口是否正常开放 123$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESacc39c54a0d8 elasticsearch:6.6.1 \"/usr/local/bin/dock…\" 18 hours ago Up 18 hours 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp es 更加直观的判断是否启动成功的提示是，直接访问 9200 端口号。成功的话，会返回如下信息。 12345678910111213141516# 这里假设一个公网的ip http://111.111.111.111:9200/&#123; &quot;name&quot; : &quot;cWz9ZWm&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;5v3SilrTQyCjjQO-a5heBA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.2.4&quot;, &quot;build_hash&quot; : &quot;ccec39f&quot;, &quot;build_date&quot; : &quot;2018-04-12T20:37:28.497551Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.2.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; kibana安装1docker pull kibana:6.6.1 接下来，如果我们手里没有kibana配置文件的信息的话，需要先从容器中copy一份过来。 1234567891011# 启动容器 tempdocker run -di -p 5601:5601 --name temp kibana:6.6.1# 创建文件夹存放配置文件mkdir -p /etc/kibana# 从容器中复制过来，注意配置文件地址是 /usr/share/kibana/configdocker cp temp:/usr/share/kibana/config /etc/kibana/config# 删除临时的temp文件，强制删除docker container rm -f temp 注意挂载的配置文件地址为： /usr/share/kibana/config 修改本地配置文件 123456789# vim /etc/kibana/config/kibana.ymlserver.name: kibana# 允许所有地址访问server.host: \"0.0.0.0\"# elasticsearch的地址，注意这里我直接填写的公网ip。# 有的教程里面填写elasticsearch，127.0.0.1，localhost 等# docker容器的网络问题是我的弱项，采用上述方案，需要在docker容器互联，网络方面有一定的知识，不然会出问题。elasticsearch.url: http://111.111.111.111:9200xpack.monitoring.ui.container.elasticsearch.enabled: true 启动容器 1docker run -di --name=kibana -p 5601:5601 -v /etc/kibana/config:/usr/share/kibana/config kibana:6.6.1 这里开放了新的端口 5601 验证是否成功，直接访问 http://111.111.111.111:5601 就可以看到如下界面 注意点 elasticsearch 和 kibana 的版本最好保持一致，这里我都使用了 6.6.1 elasticsearch 和 kibana 都是比较吃内存的家伙，所以如果你的服务器的内存少于4G，可能就会出很多问题。 kibana 端口可能会被封掉。注意你的服务器有没有打开 5601 端口，若是没有的话，换一个端口映射即可。-p 7899:5601 配置修改后可能会需要重启服务/容器 12345# 重启/查看 服务状态service kibana restart/statussystemctl restart/status kibana# 容器重启docker restart kibana TODO如果是搭建ELK，我们可能还需要 Filebeat 和 Logstash 的配和，这些还要后续的进行搭建。ELK 是好东西，只是太吃内存了。如果不是公司基本的项目，只是做的玩票性质的小服务，估计买服务器的开销就不小，所以我暂时不太会用 ELK 搭建日志系统。 参考资料Docker安装ELK","categories":[{"name":"docker","slug":"docker","permalink":"http://ppsteven.github.io/categories/docker/"}],"tags":[{"name":"es","slug":"es","permalink":"http://ppsteven.github.io/tags/es/"},{"name":"kibana","slug":"kibana","permalink":"http://ppsteven.github.io/tags/kibana/"},{"name":"docker","slug":"docker","permalink":"http://ppsteven.github.io/tags/docker/"}]},{"title":"linux 环境变量读取顺序","slug":"linux-environment-variable-config-file-order","date":"2020-02-22T13:02:00.000Z","updated":"2020-02-22T13:21:29.402Z","comments":false,"path":"2020/02/22/linux-environment-variable-config-file-order/","link":"","permalink":"http://ppsteven.github.io/2020/02/22/linux-environment-variable-config-file-order/","excerpt":"","text":"linux 环境变量读取顺序参考了许多优秀的教程，总结了 linux 读取配置文件的顺序 文件 系统/用户 描述 /etc/environment 系统 系统环境变量 /etc/profile 系统 此文件为系统的每个用户设置环境信息当用户第一次登录时,该文件被执行并从/etc/profile.d目录的配置文件中搜集shell的设置. /etc/profile.d/test.sh 系统 新建文件，没有文件夹可略过 /etc/bashrc/etc/bash.bashrc 系统 为每一个运行 bash shell的用户执行此文件当 bash shell被打开时,该文件被读取. ~/.bash_profile~/.bash_login 用户 每个用户输入专用于自己使用的shell信息当用户登录时,该文件仅仅执行一次!默认情况下,设置一些环境变量,执行用户的.bashrc文件 ~/.profile 用户 只在用户登录的时候读取一次 ~/.bashrc 用户 每次打开新 bash shell 或 登录时生效 ~/.bash_logout 用户 每次退出 bash shell 或 系统时生效 参考资料Linux环境变量配置全攻略 /etc/profile和~/.bash_profile等文件的区别和联系","categories":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/tags/linux/"},{"name":"环境变量","slug":"环境变量","permalink":"http://ppsteven.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"}]},{"title":"【转载】Linux环境变量配置全攻略","slug":"转载/Linux环境变量配置全攻略","date":"2020-02-22T07:02:00.000Z","updated":"2020-02-22T13:21:13.450Z","comments":false,"path":"2020/02/22/转载/Linux环境变量配置全攻略/","link":"","permalink":"http://ppsteven.github.io/2020/02/22/%E8%BD%AC%E8%BD%BD/Linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E5%85%A8%E6%94%BB%E7%95%A5/","excerpt":"Linux环境变量配置全攻略 注：本文是转载文章 原文链接：Linux环境变量配置全攻略 Linux环境变量配置在自定义安装软件的时候，经常需要配置环境变量，下面列举出各种对环境变量的配置方法。 下面所有例子的环境说明如下： 系统：Ubuntu 14.0 用户名：uusama 需要配置MySQL环境变量路径：/home/uusama/mysql/bin Linux读取环境变量读取环境变量的方法： export命令显示当前系统定义的所有环境变量 echo $PATH命令输出当前的PATH环境变量的值","text":"Linux环境变量配置全攻略 注：本文是转载文章 原文链接：Linux环境变量配置全攻略 Linux环境变量配置在自定义安装软件的时候，经常需要配置环境变量，下面列举出各种对环境变量的配置方法。 下面所有例子的环境说明如下： 系统：Ubuntu 14.0 用户名：uusama 需要配置MySQL环境变量路径：/home/uusama/mysql/bin Linux读取环境变量读取环境变量的方法： export命令显示当前系统定义的所有环境变量 echo $PATH命令输出当前的PATH环境变量的值 这两个命令执行的效果如下 123456789101112131415uusama@ubuntu:~$ exportdeclare -x HOME=&quot;/home/uusama&quot;declare -x LANG=&quot;en_US.UTF-8&quot;declare -x LANGUAGE=&quot;en_US:&quot;declare -x LESSCLOSE=&quot;/usr/bin/lesspipe %s %s&quot;declare -x LESSOPEN=&quot;| /usr/bin/lesspipe %s&quot;declare -x LOGNAME=&quot;uusama&quot;declare -x MAIL=&quot;/var/mail/uusama&quot;declare -x PATH=&quot;/home/uusama/bin:/home/uusama/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;declare -x SSH_TTY=&quot;/dev/pts/0&quot;declare -x TERM=&quot;xterm&quot;declare -x USER=&quot;uusama&quot;uusama@ubuntu:~$ echo $PATH/home/uusama/bin:/home/uusama/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin 其中PATH变量定义了运行命令的查找路径，以冒号:分割不同的路径，使用export定义的时候可加双引号也可不加。 Linux环境变量配置方法一：export PATH使用export命令直接修改PATH的值，配置MySQL进入环境变量的方法: 1234export PATH=/home/uusama/mysql/bin:$PATH# 或者把PATH放在前面export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：立即生效 生效期限：当前终端有效，窗口关闭后无效 生效范围：仅对当前用户有效 配置的环境变量中不要忘了加上原来的配置，即$PATH部分，避免覆盖原来配置 Linux环境变量配置方法二：vim ~/.bashrc通过修改用户目录下的~/.bashrc文件进行配置： 1234vim ~/.bashrc# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：使用相同的用户打开新的终端时生效，或者手动source ~/.bashrc生效 生效期限：永久有效 生效范围：仅对当前用户有效 如果有后续的环境变量加载文件覆盖了PATH定义，则可能不生效 Linux环境变量配置方法三：vim ~/.bash_profile和修改~/.bashrc文件类似，也是要在文件最后加上新的路径即可： 1234vim ~/.bash_profile# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：使用相同的用户打开新的终端时生效，或者手动source ~/.bash_profile生效 生效期限：永久有效 生效范围：仅对当前用户有效 如果没有~/.bash_profile文件，则可以编辑~/.profile文件或者新建一个 Linux环境变量配置方法四：vim /etc/bashrc该方法是修改系统配置，需要管理员权限（如root）或者对该文件的写入权限： 1234567# 如果/etc/bashrc文件不可编辑，需要修改为可编辑chmod -v u+w /etc/bashrcvim /etc/bashrc# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source /etc/bashrc生效 生效期限：永久有效 生效范围：对所有用户有效 Linux环境变量配置方法五：vim /etc/profile该方法修改系统配置，需要管理员权限或者对该文件的写入权限，和vim /etc/bashrc类似： 1234567# 如果/etc/profile文件不可编辑，需要修改为可编辑chmod -v u+w /etc/profilevim /etc/profile# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source /etc/profile生效 生效期限：永久有效 生效范围：对所有用户有效 Linux环境变量配置方法六：vim /etc/environment该方法是修改系统环境配置文件，需要管理员权限或者对该文件的写入权限： 1234567# 如果/etc/bashrc文件不可编辑，需要修改为可编辑chmod -v u+w /etc/environmentvim /etc/profile# 在最后一行加上export PATH=$PATH:/home/uusama/mysql/bin 注意事项： 生效时间：新开终端生效，或者手动source /etc/environment生效 生效期限：永久有效 生效范围：对所有用户有效 Linux环境变量加载原理解析上面列出了环境变量的各种配置方法，那么Linux是如何加载这些配置的呢？是以什么样的顺序加载的呢？ 特定的加载顺序会导致相同名称的环境变量定义被覆盖或者不生效。 环境变量的分类环境变量可以简单的分成用户自定义的环境变量以及系统级别的环境变量。 用户级别环境变量定义文件：~/.bashrc、~/.profile（部分系统为：~/.bash_profile） 系统级别环境变量定义文件：/etc/bashrc、/etc/profile(部分系统为：/etc/bash_profile）、/etc/environment 另外在用户环境变量中，系统会首先读取~/.bash_profile文件，如果没有该文件则读取~/.bash_login，如果也没有该文件，则读取~/.profile，根据这些文件中内容再去读取~/.bashrc。 测试Linux环境变量加载顺序的方法为了测试各个不同文件的环境变量加载顺序，我们在每个环境变量定义文件中的第一行都定义相同的环境变量UU_ORDER，该变量的值为本身的值连接上当前文件名称。 需要修改的文件如下： /etc/environment /etc/profile /etc/profile.d/test.sh，新建文件，没有文件夹可略过 /etc/bashrc，或者/etc/bash.bashrc /.bash_profile，或者/.profile ~/.bashrc 在每个文件中的第一行都加上下面这句代码，并相应的把冒号后的内容修改为当前文件的绝对文件名。 1export UU_ORDER=&quot;$UU_ORDER:~/.bash_profile&quot; 修改完之后保存，新开一个窗口，然后echo $UU_ORDER观察变量的值： 12uusama@ubuntu:~$ echo $UU_ORDER$UU_ORDER:/etc/environment:/etc/profile:/etc/bash.bashrc:/etc/profile.d/test.sh:~/.profile:~/.bashrc 可以推测出Linux加载环境变量的顺序如下： /etc/environment /etc/profile /etc/bash.bashrc /etc/profile.d/test.sh ~/.profile ~/.bashrc Linux环境变量文件加载详解由上面的测试可容易得出Linux加载环境变量的顺序如下，： 系统环境变量 -&gt; 用户自定义环境变量/etc/environment -&gt; /etc/profile -&gt; ~/.profile 打开/etc/profile文件你会发现，该文件的代码中会加载/etc/bash.bashrc文件，然后检查/etc/profile.d/目录下的.sh文件并加载。 123456789101112131415161718192021222324252627# /etc/profile: system-wide .profile file for the Bourne shell (sh(1))# and Bourne compatible shells (bash(1), ksh(1), ash(1), ...).if [ &quot;$PS1&quot; ]; then if [ &quot;$BASH&quot; ] &amp;&amp; [ &quot;$BASH&quot; != &quot;/bin/sh&quot; ]; then # The file bash.bashrc already sets the default PS1. # PS1=&apos;\\h:\\w\\$ &apos; if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ &quot;`id -u`&quot; -eq 0 ]; then PS1=&apos;# &apos; else PS1=&apos;$ &apos; fi fifiif [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset ifi 其次再打开~/.profile文件，会发现该文件中加载了~/.bashrc文件。 12345678910# if running bashif [ -n &quot;$BASH_VERSION&quot; ]; then # include .bashrc if it exists if [ -f &quot;$HOME/.bashrc&quot; ]; then . &quot;$HOME/.bashrc&quot; fifi# set PATH so it includes user&apos;s private bin directoriesPATH=&quot;$HOME/bin:$HOME/.local/bin:$PATH&quot; 从~/.profile文件中代码不难发现，/.profile文件只在用户登录的时候读取一次，而/.bashrc会在每次运行Shell脚本的时候读取一次。 一些小技巧可以自定义一个环境变量文件，比如在某个项目下定义uusama.profile，在这个文件中使用export定义一系列变量，然后在~/.profile文件后面加上：sourc uusama.profile，这样你每次登陆都可以在Shell脚本中使用自己定义的一系列变量。 也可以使用alias命令定义一些命令的别名，比如alias rm=&quot;rm -i&quot;（双引号必须），并把这个代码加入到~/.profile中，这样你每次使用rm命令的时候，都相当于使用rm -i命令，非常方便。","categories":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/tags/linux/"},{"name":"环境变量","slug":"环境变量","permalink":"http://ppsteven.github.io/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"name":"转载","slug":"转载","permalink":"http://ppsteven.github.io/tags/%E8%BD%AC%E8%BD%BD/"}]},{"title":"linux crontab 入门","slug":"linux-crontab-basic","date":"2020-02-18T16:18:48.000Z","updated":"2020-02-22T13:56:47.084Z","comments":true,"path":"2020/02/19/linux-crontab-basic/","link":"","permalink":"http://ppsteven.github.io/2020/02/19/linux-crontab-basic/","excerpt":"crontab 的作用是，执行 linux 上的定时任务。当我们需要运行一些诸如 日志采集 、心跳检查 这种任务的时候，需要用到。 最近在做 linux 脚本检查 python 爬虫脚本 是否健康运行，故采用这个方法。 只要是常驻的程序，对于程序的要求比较高，必须有很好的稳健性，可以面对各种情况。 一个程序很难考虑到各种极端情况(死机，内存爆，网络问题等)，这时候我们必须要实时监控这些进程的方法。 这里我准备采用的方法一：日记采集+监控， 方法二：定期检查并唤起。日志采集的东西准备放在下一篇讲。 当安装完成操作系统之后，默认便会启动此任务调度命令。crond 命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作","text":"crontab 的作用是，执行 linux 上的定时任务。当我们需要运行一些诸如 日志采集 、心跳检查 这种任务的时候，需要用到。 最近在做 linux 脚本检查 python 爬虫脚本 是否健康运行，故采用这个方法。 只要是常驻的程序，对于程序的要求比较高，必须有很好的稳健性，可以面对各种情况。 一个程序很难考虑到各种极端情况(死机，内存爆，网络问题等)，这时候我们必须要实时监控这些进程的方法。 这里我准备采用的方法一：日记采集+监控， 方法二：定期检查并唤起。日志采集的东西准备放在下一篇讲。 当安装完成操作系统之后，默认便会启动此任务调度命令。crond 命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作 而 linux 任务调度的工作主要分为以下两类： 1、系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 2、个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 安装1yum install crontabs 对于 crontabs 服务的操作 123456systemctl status crond // systemctl 和 service 也是一样service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看服务是否启动 基础语法12345crontab [ -u user ] filecrontab [ -u user ] &#123; -l | -r | -e &#125; -l 列出目前用户的时程表-r 删除目前用户的时程表-e 编辑目前用户的时程表(默认采用VI) 等价于运行 vi /var/spool/cron/root [注:假如你是root用户(文件名与用户名一样)] 使用方法1f1 f2 f3 f4 f5 program 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,… 时表示第 a, b, c,… 分钟要执行，f2 为 a, b, c,… 时表示第 a, b, c…个小时要执行，其馀类推 12345678* * * * *- - - - -| | | | || | | | +----- 星期中星期几 (0 - 7) (星期天 为0)| | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31)| +-------------------- 小时 (0 - 23)+------------------------- 分钟 (0 - 59) 实例12345670 */2 * * * /sbin/service httpd restart 意思是每两个小时重启一次apache 50 7 * * * /sbin/service sshd start 意思是每天7：50开启ssh服务 50 22 * * * /sbin/service sshd stop 意思是每天22：50关闭ssh服务 0 0 1,15 * * fsck /home 每月1号和15号检查/home 磁盘 1 * * * * /home/bruce/backup 每小时的第一分执行 /home/bruce/backup这个文件 00 03 * * 1-5 find /home &quot;*.xxx&quot; -mtime +4 -exec rm &#123;&#125; \\; 每周一至周五3点钟，在目录/home中，查找文件名为*.xxx的文件，并删除4天前的文件。30 6 */10 * * ls 意思是每月的1、11、21、31日是的6：30执行一次ls命令 配置文件crontab 是系统任务调度的配置文件 1234# /etc/crontabSHELL=/bin/bash # 记录使用的 shell PATH=/sbin:/bin:/usr/sbin:/usr/bin # 记录 crontab 的环境变量MAILTO=root # 发送邮件的用户 常见问题如何查看日志执行日志 存储地址 /var/log/cron* 执行日志按天排列：cron 、cron-20171119 … 1tail -f /var/log/cron 运行日志 存储地址 /var/spool/mail/root mail/root 中的root 是文件名，与用户保持一致 发邮件的功能，我没有尝试成功 // TODO 如何查看/备份任务12345678# 编辑任务crontab -e # 实际上所有的配置都存放在 /var/spool/cron/*下，文件名与用户名一致/var/spool/conf/root :root 用户任务/var/spool/conf/mysql :mysql 用户任务# 备份任务crontab -l &gt; $HOME/mycrontabcp /var/spool/conf/root $HOME/YOURPLACE/root 注意事项crontab 有很多的注意实现，新手很容易翻车 建议不输出日志原因是任务运行太频繁，日志会累积的非常大，不留意会撑爆你的硬盘 1&gt; /dev/null 2&gt;&amp;1 环境变量问题crontab 的环境变量是一个大问题，crontab运行的时候不是以交互式的方式运行我们的程序，这样的话，我们常规的用来配置 linux 环境变量 的方法。如 .bashrc ，.bash_profile 等都不会起作用。 官方给的建议是，不要假定 cron 知道所需要的特殊环境，所以要保证 shell 脚本中提供所有必要的路径和环境变量。 脚本中涉及文件路径时写全局路径； 脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如: 123456cat start_cbp.sh#!/bin/sh# shell 脚本中写入所需引入的环境变量source /etc/profileexport RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf/usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 当手动执行脚本OK，但是crontab死活不执行时,很可能是环境变量惹的祸，可尝试在crontab中直接引入环境变量解决问题。如: 10 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 参考资料菜鸟教程：Linux crontab 命令 小a玖拾柒：Linux crontab命令详解","categories":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ppsteven.github.io/tags/linux/"},{"name":"crontab","slug":"crontab","permalink":"http://ppsteven.github.io/tags/crontab/"},{"name":"运维","slug":"运维","permalink":"http://ppsteven.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"mysql error:Waiting for table metadata lock","slug":"mysql-bug-solution","date":"2020-02-11T15:57:07.000Z","updated":"2020-02-15T17:00:07.283Z","comments":true,"path":"2020/02/11/mysql-bug-solution/","link":"","permalink":"http://ppsteven.github.io/2020/02/11/mysql-bug-solution/","excerpt":"背景是，Navicat 在针对一张表格做删除操作的时候，会一直等待，无法进行任何操作。 经过 show PROCESSLIST 发现是 Waiting for table metadata lock 错误。","text":"背景是，Navicat 在针对一张表格做删除操作的时候，会一直等待，无法进行任何操作。 经过 show PROCESSLIST 发现是 Waiting for table metadata lock 错误。 删除 mysql 中表格遇到锁出现了Waiting for table metadata lock 的原因是，程序中对于数据库的一次操作并没有成功关闭，导致数据库上锁后，没有解锁。按照如下操作即可解决问题。 12345show PROCESSLIST; # 显示所有的操作select * from information_schema.innodb_trx # 查看未提交事务kill sid # 删除锁住的操作set session lock_wait_timeout = 1800; set global lock_wait_timeout = 1800;# 调整锁超时阈值 lock_wait_timeout 表示获取metadata lock的超时（单位为秒），允许的值范围为1到31536000（1年）。 默认值为31536000。 参考资料：MySQL出现Waiting for table metadata lock的原因以及解决方法 参考资料","categories":[{"name":"mysql","slug":"mysql","permalink":"http://ppsteven.github.io/categories/mysql/"}],"tags":[{"name":"mysql error","slug":"mysql-error","permalink":"http://ppsteven.github.io/tags/mysql-error/"}]},{"title":"Python装饰器：将装饰器定义为类","slug":"define-decorators-as-class","date":"2020-02-08T16:18:59.000Z","updated":"2020-02-15T17:53:24.593Z","comments":false,"path":"2020/02/09/define-decorators-as-class/","link":"","permalink":"http://ppsteven.github.io/2020/02/09/define-decorators-as-class/","excerpt":"最近在强化补齐 Python 的基础知识，向高阶玩家进发。主攻《Python CookBook 3rd》，上面的知识点比较多，我挑重点看这几个方面。 yield + 协程 装饰器 多线程 面向对象 本篇博客讨论的主题是 装饰器 ，装饰器其实也不是什么新鲜的用法，就是传入的参数是 函数 ，这一点上，它更像是一个语法糖。装饰器的作用是可以给我们原本编写好的函数再一次的加上额外的功能（比如统计时间，打日志）。 装饰器可以给我们的函数加上武器，使它们更加强大。如果是利用 Python 进行 Web 开发的小伙伴对装饰器并不陌生，在 Flask 和 Django 中 @ 符号应该不少见了","text":"最近在强化补齐 Python 的基础知识，向高阶玩家进发。主攻《Python CookBook 3rd》，上面的知识点比较多，我挑重点看这几个方面。 yield + 协程 装饰器 多线程 面向对象 本篇博客讨论的主题是 装饰器 ，装饰器其实也不是什么新鲜的用法，就是传入的参数是 函数 ，这一点上，它更像是一个语法糖。装饰器的作用是可以给我们原本编写好的函数再一次的加上额外的功能（比如统计时间，打日志）。 装饰器可以给我们的函数加上武器，使它们更加强大。如果是利用 Python 进行 Web 开发的小伙伴对装饰器并不陌生，在 Flask 和 Django 中 @ 符号应该不少见了 用类来实现装饰器Python 对某个对象是否能通过装饰器（@decorator）形式使用只有一个要求：decorator 必须是一个“可被调用（callable）的对象。类也可以通过实现 __call__ 方法，变得和函数一样可调用 123456789class Foo: def __call__(self): print('__call__ has been called')foo = Foo()# OUTPUT: __call__ has been calledfoo()# OUTPUT: Trueprint(callable(foo)) 这样的话，我们就可以直接开始用类来实现装饰器了 123456789101112131415161718class Profiled: def __init__(self, func): self.func = func self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1 return self.func(*args, **kwargs)@Profileddef add(x, y): return x + y# 3 add(1,2)# 7add(3,4)# OUTPUT:2 总共调用了2次装饰器print(add.ncalls) 问题一：装饰器无法装饰类内的方法这时候出现了第一个问题，当装饰器尝试装饰类内的方法的时候，我们常常会出现 参数输入不正确的提示 12345678class Spam: @Profiled def bar(self, x): print(self, x)s = Spam()# TypeError: bar() missing 1 required positional argument: 'x's.bar(1) 这个问题会让很多人感到困惑，明明我已经输入了参数x，赋值为1，但是却提示没有收到函数。我当时困惑了很久。终于发现了一个我们不容易注意到的细节：函数和方法的功能相似，当时实现方式不同。 我的理解是：与实例绑定的函数，叫做过程。不与实例绑定的叫做函数。这里的实例，在代码里面就是 self类内的方法，需要多传一个 self ，它本质上可以看做是一个指向实例的指针。 123456# 我们在 __call__ 里面多加一行，看看输出会是什么def __call__(self, *args, **kwargs): self.ncalls += 1+ print(self, *args, **kwargs) return self.func(*args, **kwargs)# &lt;__main__.Profiled object at 0x10faf1128&gt; 1 self 就是 &lt;__main__.Profiled object at 0x10faf1128&gt; ，而输入的参数是 1 。 Self 到低是一个什么玩意？ 为了探寻 self 的本质，我又多做了一个实验。发现 self ，Spam.bar ，s.bar 都是一个东西，相互替换的话，也是OK的，它就是类的一个实例。需要注意的是@Profiled 等价于 bar = Profiled(bar) ，所以这个实例也就是 Spam.bar 。 123456self&lt;__main__.Profiled object at 0x10aaf5470&gt;Spam.bar&lt;__main__.Profiled object at 0x10aaf5470&gt;s.bar&lt;__main__.Profiled object at 0x10aaf5470&gt; 下面的例子，可以帮助我们更好的理解 对象的方法 和 类的方法 1234567891011121314# 带 self 的意思是对象的方法，所以我们必须传入一个对象class Spam: def bar(self, x): print(self, x)# 正常用法，实例化对象，然后调用对象的方法# OUTPUT: &lt;__main__.Spam object at 0x10b3470b8&gt; 111s = Spam()s.bar(111)# 直接使用 Spam.bar 方法Spam.bar(123) # 错误用法，因为这里当做类的方法去使用了# OUTPUT: &lt;__main__.Spam object at 0x10b3470b8&gt; 123Spam.bar(Spam(),123) # 正确用法 更进一步，我们发现，定义类的方法的时候，类并不关心你传入的实例到底是什么，可以是 self ，也可以是任何类型的实例。 12345678# &lt;__main__.Spam object at 0x107bcc128&gt; 123Spam.bar(Spam(),123)# &lt;__main__.Spam object at 0x107bc2e80&gt; 123Spam.bar(s,123)# &lt;function Spam.bar at 0x107badea0&gt; 123Spam.bar(Spam.bar,123)# 任何类型的对象都可以 123Spam.bar(\"任何类型的对象都可以\",123) 解决方案回到正题，我们终于找到了原先错误的原因，就是漏掉了 self 。 1234567891011121314151617181920212223class Profiled: def __init__(self, func): self.func = func self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1- return self.func(*args, **kwargs)+ return self.func(self, *args, **kwargs)class Spam: @Profiled def bar(self, x): print(self, x)s = Spam()s.bar(1)s.bar(2)print(Spam.bar.ncalls)# OUTPUT&lt;__main__.Profiled object at 0x104168eb8&gt; 1&lt;__main__.Profiled object at 0x104168eb8&gt; 22 解决完这个问题，附带的我们对 self 的理解就加深了一层。 类方法 和 实例方法1234567891011121314class Spam: \"\"\"实例方法\"\"\" def bar(self, x): print(self, x)class Swam: \"\"\"类方法\"\"\" @classmethod def bar(cls, x): print(cls, x)# OUTPUT: &lt;__main__.Spam object at 0x1102080f0&gt; 1Spam().bar(1)# OUTPUT: &lt;class '__main__.Swam'&gt; 1Swam.bar(1) 问题二：如何兼顾类内类外的函数刚刚的问题一解决后，我们发现，对原来类外的函数又失效了，原因是它并没有 self 这个参数。为了解决这个问题，我们需要花一番功夫，其实简单来说，有实例的情况下，我们需要填充实例到 self 参数的位置。 这里我们借助 types.MethodTpye 和 __get__ 解决方法（完美版）12345678910111213141516171819202122232425262728293031323334import typesfrom functools import wrapsclass Profiled: def __init__(self, func): self.func = func self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1 return self.func(*args, **kwargs) def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance)@Profileddef add(x, y): return x + yclass Spam: @Profiled def bar(self, x): print(self, x)add(1,2)add(3,4)print(add.ncalls)s = Spam()s.bar(1)s.bar(2)print(Spam.bar.ncalls) __get__ 是怎么使用当一个类中实现了任意的 __get__()、__set__() 和__delete__() 三个特殊的方法后， 这个类就是一个描述器类。当这个描述器在另一个类中被调用的时候，就会调用以上的三个方法。 123456789101112131415161718# 定义一个描述器类class Integer: def __init__(self, name): self.name = name def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] def __set__(self, instance, value): if not isinstance(value, int): raise TypeError('Expected an int') instance.__dict__[self.name] = value def __delete__(self, instance): del instance.__dict__[self.name] 为了使用一个描述器，这个类必须作为另外一个类的属性 1234567891011121314151617# x, y 都是 Point 的描述器属性# 需要注意的是: x, y 是类的属性，需要在方法前定义class Point: x = Integer('x') y = Integer('y') def __init__(self, x, y): self.x = x self.y = y# 下面的定义是错误的class Point: def __init__(self, x, y): self.x = Integer('x') # No! Must be a class variable self.y = Integer('y') self.x = x self.y = y 使用方法如下 1234&gt;&gt;&gt; p = Point(2, 3)&gt;&gt;&gt; p.x # Calls Point.x.__get__(p,Point)2&gt;&gt;&gt; p.y = 5 # Calls Point.y.__set__(p, 5) 我们会发现 __get__ 方法实现起来比较复杂 12345def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] self, instance, cls 分别代表什么意思？self 是 Integer 类的实例，这里 x、y 都可以看做是self。instance 是 Point 类的实例，也就是 p。cls（也可以写成 owner）是类本身，这里就是 Point 类。 如果一个描述器被当做一个类变量来访问，那么 instance 参数被设置成 None 。 这种情况下，标准做法就是简单的返回这个描述器本身即可(尽管你还可以添加其他的自定义操作)。 1234&gt;&gt;&gt; p.x # Calls Point.x.__get__(p, Point)2&gt;&gt;&gt; Point.x # Calls Point.x.__get__(None, Point)&lt;__main__.Integer object at 0x100671890&gt; types.MethodType 详解Python 是动态的编程语言，可以在执行的过程中，给类动态的添加方法。 下面举一个经典用法 123456789import types def fn_get_name(self): return self.nameclass Person(object): def __init__(self, name, score): self.name = name self.score = score 添加函数到 Person 类的方法上。 12345678&gt;&gt;&gt; p1 = Person('Bob', 90) &gt;&gt;&gt; p1.get_name = types.MethodType(fn_get_name, p1) &gt;&gt;&gt; print p1.get_name() Bob&gt;&gt;&gt; p2 = Person('Alice', 65) &gt;&gt;&gt; print p2.get_name() # ERROR: AttributeError: 'Person' object has no attribute 'get_name' # 因p2实例没有绑定get_name方法，所以出现错误。 下面我们深入理解一下 p1.get_name = types.MethodType(fn_get_name, p1)types.MethodType 接受两个参数（好像Python2 是3 个参数？） 第一个参数：绑定的函数 第二个参数：需要绑定的实例 孤立的看两个参数和实现的结果并不能很好的理解其中的原理，实际上，所谓的绑定的实质上是：第二个实例是作为参数，传入到绑定函数(现在是类的过程)的 self 中去。 如果理解了这一句话，那么应该不难理解下面的程序。明明是 p1 调用自己的方法，最后输出的是 p2 的结果 12345p1 = Person('Bob', 90) p2 = Person('Tom', 0)p1.get_name = types.MethodType(fn_get_name, p2) print (p1.get_name())# OUTPUT: Tom 原因是我们的类最终是变成了下面的样子 12345678910111213141516import types def fn_get_name(self): return self.nameclass Person(object): def __init__(self, name, score): self.name = name self.score = score def get_name(self): self = p2 return self.namep1 = Person('Bob', 90) p2 = Person('Tom', 0)print (p1.get_name())# OUTPUT: TOM 回顾有了上面的各种铺垫后，我们再一次的回顾 __get__, __call__ 两个方法，就瞬间了然。 1234567891011def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance) # 该实例会作为参数传入 self 中def __call__(self, *args, **kwargs): # 当实例发生调用的时候，__call__(self, self, 1) # args = (self, 1) self.ncalls += 1 return self.func(*args, **kwargs) # self.func(self, 1) 利用 wrapper 再次包装一下wrapper 的作用非常简单，就是让复制被包装函数的元信息。下面的代码就是 Python Cookbook 给出的答案。 12345678910111213141516171819import typesfrom functools import wrapsclass Profiled: def __init__(self, func):- self.func = func+ wraps(func)(self) self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1- return self.func(*args, **kwargs)+ return self.__wrapped__(*args, **kwargs) def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance) 小结花了相当长的一个篇幅去讨论 Python Cookbook 的一个章节，虽然有点小题大做。不过也是把很多不懂的地方理清楚了。特别是对于 函数和方法 的认识更深一步了。 后续会利用装饰器去做一个应用，计划是做一个 requests 包的一个封装，使得 request 请求的时候自动加上代理，把它封装成一个 Util 工具。 参考资料Python 工匠：使用装饰器的技巧 python中函数和方法区别，以及如何给python类动态绑定方法和属性（涉及types.MethodType()和slots） Python Cookbook 8.9 创建新的类或实例属性 Python Cookbook 9.9 将装饰器定义为类","categories":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/categories/python/"}],"tags":[{"name":"python高级","slug":"python高级","permalink":"http://ppsteven.github.io/tags/python%E9%AB%98%E7%BA%A7/"}]},{"title":"如何在python项目中使用import导入自编模块","slug":"how-to-import-module-in-python-project","date":"2020-01-26T09:06:02.000Z","updated":"2020-02-15T17:54:37.443Z","comments":false,"path":"2020/01/26/how-to-import-module-in-python-project/","link":"","permalink":"http://ppsteven.github.io/2020/01/26/how-to-import-module-in-python-project/","excerpt":"背景是在python项目中导入模块时碰到的问题，当需要导入的模块是位于项目的不同层级的时候，导入文件就变成了一个非常麻烦的事情。 下面举一个例子 123456789. # 当前工作目录├── DB │ ├── MySQLClient.py│ └── RedisClient.py└── Util│ └── LogHandler.py├── Email│ └── SendEmail.py # 本文件│ └── Email_setting.py # 待导入文件 DB 和 Util 是我们经常使用到的模块，若是我们的工作目录位于项目文件的第一层的话，当我们导入 Email_setting.py 的时候，我们应该是 1234from DB.MySQLClient import MySQLClassfrom Util.LogHandler import LogHandlerfrom Email_setting import * # 这是错误的例子from Email.Email_setting import * 下面我们讨论一下如何在python中导入模块 参考自: Python 101: All about imports","text":"背景是在python项目中导入模块时碰到的问题，当需要导入的模块是位于项目的不同层级的时候，导入文件就变成了一个非常麻烦的事情。 下面举一个例子 123456789. # 当前工作目录├── DB │ ├── MySQLClient.py│ └── RedisClient.py└── Util│ └── LogHandler.py├── Email│ └── SendEmail.py # 本文件│ └── Email_setting.py # 待导入文件 DB 和 Util 是我们经常使用到的模块，若是我们的工作目录位于项目文件的第一层的话，当我们导入 Email_setting.py 的时候，我们应该是 1234from DB.MySQLClient import MySQLClassfrom Util.LogHandler import LogHandlerfrom Email_setting import * # 这是错误的例子from Email.Email_setting import * 下面我们讨论一下如何在python中导入模块 参考自: Python 101: All about imports 导入 Python 模块的各种姿势 Regular imports Using from Relative imports Optional imports Local imports import Pitfalls 常规导入我们最常见的导入方式是 import module ，我们一般用来导入 官方库 和 第三方库 。 123import math # 官方库from bs4 import Beautfiul # 第三方库import pandas as pd 以上两个来源的库用起来比较省心，因为它们的目录已经加入了环境变量中了 1234# 查看环境变量的方式&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path['', '/Users/ppsteven/anaconda3/lib/python37.zip', '/Users/ppsteven/anaconda3/lib/python3.7', '/Users/ppsteven/anaconda3/lib/python3.7/lib-dynload', '/Users/ppsteven/anaconda3/lib/python3.7/site-packages', '/Users/ppsteven/anaconda3/lib/python3.7/site-packages/aeosa', '/Users/ppsteven/anaconda3/lib/python3.7/site-packages/xgboost-1.0.0_SNAPSHOT-py3.7.egg'] 从模块导入12from functools import lru_cachelru_cache(*args) 同样，你也可以导入该模块中的所有函数和变量，只是这种导入方式是不被推荐的 1from os import * 官方建议我们，需要对 import 的函数，要显式的写出，但是当函数过多的时候，我们可能写成多行的形式 12from os import path, walk, unlinkfrom os import uname, remove 为了能用一个 import 实现，我们可以利用 括号 帮助，或者 \\ 1234from os import (path, walk, unlink, uname, remove, rename)from os import path, walk, unlink, uname, \\ remove, rename 相对导入当使用的是绝对路径时，容易出现的问题是，在大型的项目中，当你改变包结构的时候，你需要对你的代码进行大幅度的修改。 另外，如果没有相对路径，那么包内的模块无法轻松导入自身。 一些例子12from .foo import barfrom ...foo import bar 这两种形式有两种不同的建议语义。一种语义是使每个点代表一个级别。但是数需要多少个点也是一件麻烦事。 另一种选择是只允许一个相对导入级别，这样的话又会制约模块的功能。 最后的选择是定义一种算法，用于查找相关的模块和软件包。 这里的反对意见是“明确胜于隐含”。 （建议的算法是“从当前程序包目录中搜索，直到最终的父程序包被命中为止。”） 只导入兄弟模块一种建议是，只导入 兄弟 模块。换言之，对于更高层级的模块，使用绝对路径 12from .spam import eggsimport .spam.eggs 使用索引父节点12from -2.spam import eggs # 高层级from .spam import eggs # 本地 把代码组织成很多分层模块的包使用一个 leading dot 作为相对路径，两个或以上代表父目录。 这里我们把整个项目作为一个包来看待，需要对每一层写一个 __init__.py 文件这里，我们整个项目可以看成 package 包，和 subpackage1 和 subpackage2 两个子包。 实现的方法很简单，就是确保在每一层目录上添加一个 __init__.py 文件 下面是我们的目录结构 12345678910package/ __init__.py subpackage1/ __init__.py moduleX.py # 当前文件 moduleY.py subpackage2/ __init__.py # 当前文件 moduleZ.py moduleA.py 假设 moduleX.py 和 __init__.py 是我们的当前文件，那么正确的导入的做法是 12345678from .moduleY import spamfrom .moduleY import spam as hamfrom . import moduleYfrom ..subpackage1 import moduleYfrom ..subpackage2.moduleZ import eggsfrom ..moduleA import foofrom ...package import barfrom ...sys import path 相对路径必须使用 from &lt;&gt; import 绝对路径使用 import &lt;&gt; 12345678910111213141516# my_package/__init__.pyfrom . import subpackage1from . import subpackage2# my_package/subpackage1/__init__.pyfrom . import module_xfrom . import module_y# my_package/subpackage1/module_x.pyfrom .module_y import spam as ham def main(): ham()# my_package/subpackage1/module_y.pydef spam(): print('spam ' * 3) 我们切换到 my_package 上一层的目录，运行下面代码是正常的。 1234567In [1]: import my_package In [2]: my_package.subpackage1.module_xOut[2]: &lt;module 'my_package.subpackage1.module_x' from 'my_package/subpackage1/module_x.py'&gt; In [3]: my_package.subpackage1.module_x.main()spam spam spam 可选导入可选导入用的情况比较少，一般是用在需要导入一个模块，但是这个模块并不一定存在的情况。比如我们使用的python 版本不一致的时候，需要导入的模块也会有所不同，这样的写法能加强模块的健壮性= github2下面是一段来自 github2 的例子 123456789try: # For Python 3 from http.client import responsesexcept ImportError: # For Python 2.5-2.7 try: from httplib import responses # NOQA except ImportError: # For Python 2.4 from BaseHTTPServer import BaseHTTPRequestHandler as _BHRH responses = dict([(k, v[0]) for k, v in _BHRH.responses.items()]) lxml下面是一段来自 lxml package 的例子 1234567try: from urlparse import urljoin from urllib2 import urlopenexcept ImportError: # Python 3 from urllib.parse import urljoin from urllib.request import urlopen 本地导入导入的模块分为 local scope 和 global scope 空间。当你在 python script 的头部导入的时候，作用在全局域。当在函数中导入的时候是本地域。 1234567891011121314import sys # global scope def square_root(a): # This import is into the square_root functions local scope import math return math.sqrt(a) def my_pow(base_num, power): # 这里直接使用 math 会报错的 return math.pow(base_num, power) if __name__ == '__main__': print(square_root(49)) print(my_pow(2, 3)) 导入的注意事项容易犯错误的主要有两点 循环导入 Shadowed imports 循环导入简言之，就是模块相互导入 12345678# a.pyimport b def a_test(): print(\"in a_test\") b.b_test() a_test() 我们在相同的文件夹下，创建一个文件 b.py 1234567import a def b_test(): print('In test_b\"') a.a_test() b_test() 如果是你运行这些模块的话，你将会获得 AttributeError 报错。虽然有一些旁门左道的变通方法可以解决，但是还是建议重构代码。 覆盖导入(Shadowed imports)覆盖导入是指导入一个和官方库起名一样的模块，会报错。 主要的原因是，python 会首先搜索本地文件夹下的模块，其次是搜索其他路径。 123456import math def square_root(number): return math.sqrt(number) square_root(72) 参考资料Python 101: All about imports","categories":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/tags/python/"},{"name":"import","slug":"import","permalink":"http://ppsteven.github.io/tags/import/"}]},{"title":"Python编码规范","slug":"python编码规范","date":"2020-01-12T09:37:56.000Z","updated":"2020-06-07T03:34:26.557Z","comments":false,"path":"2020/01/12/python编码规范/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/python%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/","excerpt":"Python编码规范 Python 编码规范(Google Python Style Guide 目前写了: 函数、模块、变量等命名 函数注释 字符串编码规范 TODO 模块的导入规范，项目的结构","text":"Python编码规范 Python 编码规范(Google Python Style Guide 目前写了: 函数、模块、变量等命名 函数注释 字符串编码规范 TODO 模块的导入规范，项目的结构 命名应该避免的名称 单字符名称, 除了计数器和迭代器. 包/模块名中的连字符(-) 双下划线开头并结尾的名称(Python保留, 例如init) 命名约定 所谓”内部(Internal)”表示仅模块内可用, 或者, 在类内是保护或私有的. 用单下划线(_)开头表示模块变量或函数是protected的(使用import * from时不会包含). 用双下划线(__)开头的实例变量或方法表示类内私有. 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块. 对类名使用大写字母开头的单词(如CapWords, 即Pascal风格), 但是模块名应该用小写加下划线的方式(如lower_with_under.py). 尽管已经有很多现存的模块使用类似于CapWords.py这样的命名, 但现在已经不鼓励这样做, 因为如果模块名碰巧和类名一致, 这会让人困扰. Python之父Guido推荐的规范 Type Public Internal Modules lower_with_under _lower_with_under Packages lower_with_under Classes CapWords _CapWords Exceptions CapWords Functions lower_with_under() _lower_with_under() Global/Class Constants CAPS_WITH_UNDER _CAPS_WITH_UNDER Global/Class Variables lower_with_under _lower_with_under Instance Variables lower_with_under _lower_with_under (protected) or __lower_with_under (private) Method Names lower_with_under() _lower_with_under() (protected) or __lower_with_under() (private) Function/Method Parameters lower_with_under Local Variables lower_with_under 注意 模块尽量使用小写命名，首字母保持小写，尽量不要用下划线 类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头 函数名一律小写，如有多个单词，用下划线隔开 私有函数可用一个下划线开头 变量名尽量小写, 如有多个单词，用下划线隔开 常量采用全大写，如有多个单词，使用下划线隔开 函数注释reST 参考：python代码规范以及函数注释规范 12345678\"\"\"This is a reST style. :param param1: this is a first param:param param2: this is a second param:returns: this is a description of what is returned:raises keyError: raises an exception\"\"\" 下面的一个例子，来自：这里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546def pinyin(hans, style=Style.TONE, heteronym=False, errors='default', strict=True): \"\"\"将汉字转换为拼音. :param hans: 汉字字符串( ``'你好吗'`` )或列表( ``['你好', '吗']`` ). 可以使用自己喜爱的分词模块对字符串进行分词处理, 只需将经过分词处理的字符串列表传进来就可以了。 :type hans: unicode 字符串或字符串列表 :param style: 指定拼音风格，默认是 :py:attr:`~pypinyin.Style.TONE` 风格。 更多拼音风格详见 :class:`~pypinyin.Style` :param errors: 指定如何处理没有拼音的字符 * ``'default'``: 保留原始字符 * ``'ignore'``: 忽略该字符 * ``'replace'``: 替换为去掉 ``\\\\u`` 的 unicode 编码字符串 (``'\\\\u90aa'`` =&gt; ``'90aa'``) * callable 对象: 回调函数之类的可调用对象。如果 ``errors`` 参数 的值是个可调用对象，那么程序会回调这个函数: ``func(char)``:: def foobar(char): return 'a' pinyin('あ', errors=foobar) :param heteronym: 是否启用多音字 :param strict: 是否严格遵照《汉语拼音方案》来处理声母和韵母，详见 :ref:`strict` :return: 拼音列表 :rtype: list Usage:: &gt;&gt;&gt; from pypinyin import pinyin, Style &gt;&gt;&gt; import pypinyin &gt;&gt;&gt; pinyin('中心') [['zhōng'], ['xīn']] &gt;&gt;&gt; pinyin('中心', heteronym=True) # 启用多音字模式 [['zhōng', 'zhòng'], ['xīn']] &gt;&gt;&gt; pinyin('中心', style=Style.FIRST_LETTER) # 设置拼音风格 [['z'], ['x']] &gt;&gt;&gt; pinyin('中心', style=Style.TONE2) [['zho1ng'], ['xi1n']] &gt;&gt;&gt; pinyin('中心', style=Style.CYRILLIC) [['чжун1'], ['синь1']] \"\"\" # 对字符串进行分词处理 if isinstance(hans, text_type): .py文件头文件12345678910111213# -*- encoding:utf-8 -*-\"\"\"------------------------------------------------- File Name： $&#123;NAME&#125; Description : Author : $&#123;USER&#125; date： $&#123;DATE&#125; $&#123;HOUR&#125;:$&#123;MINUTE&#125;------------------------------------------------- Change Activity: $&#123;DATE&#125;: -------------------------------------------------\"\"\"# 上面的代码加入 PyCharm 中 样例代码这里我们参考 崔庆才 书中 Scrapy 微博爬虫 的编码风格 项目结构123456789101112Weibo├── README.md├── scrapy.cfg└── weibo ├── __init__.py ├── items.py ├── middlewares.py ├── pipelines.py ├── settings.py └── spiders ├── __init__.py └── weibocn.py weibocn.py 文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import json+ from scrapy import Request, Spider # 可以看到导入的模块名也是 双驼峰 from weibo.items import *+ class WeiboSpider(Spider): # 类名双驼峰 WebioSpider name = 'weibocn' + allowed_domains = ['m.weibo.cn'] # 变量全部小写，用下划线_ 连接 ... + start_users = ['3217179555', '1742566624', '2282991915', '1288739185', '3952070245', '5878659096'] + def start_requests(self): # 函数名全部小写，用下划线_ 连接 for uid in self.start_users: yield Request(self.user_url.format(uid=uid), callback=self.parse_user) def parse_user(self, response): + \"\"\"+ 解析用户信息 代码注释风格+ :param response: Response对象+ \"\"\" self.logger.debug(response) result = json.loads(response.text) if result.get('data').get('userInfo'): user_info = result.get('data').get('userInfo') user_item = UserItem() field_map = &#123; 'id': 'id', 'name': 'screen_name', 'avatar': 'profile_image_url', 'cover': 'cover_image_phone', 'gender': 'gender', 'description': 'description', 'fans_count': 'followers_count', 'follows_count': 'follow_count', 'weibos_count': 'statuses_count', 'verified': 'verified', 'verified_reason': 'verified_reason', 'verified_type': 'verified_type' &#125; for field, attr in field_map.items(): user_item[field] = user_info.get(attr) yield user_item+ # 关注 uid = user_info.get('id') yield Request(self.follow_url.format(uid=uid, page=1), callback=self.parse_follows, meta=&#123;'page': 1, 'uid': uid&#125;)+ # 粉丝 yield Request(self.fan_url.format(uid=uid, page=1), callback=self.parse_fans, meta=&#123;'page': 1, 'uid': uid&#125;)+ # 微博 yield Request(self.weibo_url.format(uid=uid, page=1), callback=self.parse_weibos, meta=&#123;'page': 1, 'uid': uid&#125;)....","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"python","slug":"python","permalink":"http://ppsteven.github.io/tags/python/"}]},{"title":"Centos 环境配置（持续总结）","slug":"centos-install-introduction","date":"2020-01-12T08:35:50.000Z","updated":"2020-06-18T11:16:53.311Z","comments":false,"path":"2020/01/12/centos-install-introduction/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/centos-install-introduction/","excerpt":"本章节收集一下配置一个centos 环境所需要的操作 git wget MiniConda(python) mysql … web-vscode phpredisAdmin(redis web 管理工具)","text":"本章节收集一下配置一个centos 环境所需要的操作 git wget MiniConda(python) mysql … web-vscode phpredisAdmin(redis web 管理工具) 基础配置显示完整文件路径123456命令行提示符完全显示完整的工作目录名称:（推荐用法）export PS1='[\\u@\\h $PWD]$ '命令行提示符只列出最后一个目录：export PS1='[\\u@\\h \\W]$'命令行提示符显示完整工作目录，当前用户目录会以 ~代替：export PS1='[\\u@\\h \\w]$' 命令释义 123456\\u 显示当前用户账号\\h 显示当前主机名\\W 只显示当前路径最后一个目录\\w 显示当前绝对路径（当前用户目录会以 ~代替）$PWD 显示当前全路径\\$ 显示命令行’$&apos;或者’#&apos;符号 参考资料：linux下显示完整路径，linux下显示绝对路径 必要软件安装ifconfig1234$ yum search ifconfig============================== 匹配：ifconfig ============================================net-tools.x86_64 : Basic networking tools$ yum install net-tools.x86_64 git1$ yum install -y git wget1$ yum install -y wget 7z压缩1$ yum install p7zip 使用方法 12345678910117za test -t7z -r test.7z test#a 代表添加文件／文件夹到压缩包-t 是指定压缩类型，这里定为7z，可不指定，因为7za默认压缩类型就是7z。-r 表示递归所有的子文件夹7za x test.7z -r -o./# x 代表解压缩文件，并且是按原始目录树解压（还有个参数 e 也是解压缩文件，但其会将所有文件都解压到根下，而不是自己原有的文件夹下）# -r 表示递归解压缩所有的子文件夹# -o 是指定解压到的目录，-o后是没有空格的，直接接目录。这一点需要注意。# FRE COMMAND7za test test.7z7za x test.7z sz, rz服务器上传，下载文件，除了使用FTP软件外，lrzsz是一个unix通信套件提供的X，Y，和ZModem文件传输协议,是一个非常强大的文件传输工具，安装方便，使用简单。 rzsz 官网入口：http://freecode.com/projects/lrzsz/ 123$ yum -y install lrzszsz filename # 下载文件 filenamerz # 上传文件 进程树12yum -y install psmiscpstree MiniConda网址https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/ 下载最新的版本，一般来说是 Miniconda-latest-Linux 123456789$ wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda-latest-Linux-x86_64.sh$ yum -y install bzip2 # 下载解压软件$ bash Miniconda-latest-Linux-x86_64.sh# 添加环境变量$ echo \"export PATH=/root/miniconda2/bin:$PATH\" &gt;&gt; .bashrc$ source ~/.bashrc# 检查是否成功安装$ /root/miniconda2/bin/conda -Vconda 4.0.5 配置 Anaconda 仓库镜像源123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes 设置快捷命令12345alias conl=\"conda env list\"alias conc=\"conda create -n\"alias cona=\"source activate\"alias cond=\"source deactivate\"alias conr=\"conda remove --all -n\" 新建 python 环境123456789101112# 创建新环境 base 并安装python3.6$ conda create -n base python=3.6# 查看当前环境$ conl# conda environments:#base /root/miniconda2/envs/baseroot * /root/miniconda2# 切换为 base 环境$ cona base$ which python /root/miniconda2/envs/base/bin/python # 当前python的地址 安装必要的库 12$ pip install --upgrade pip$ pip install numpy pandas jsonpath pymysql requests datetime dateutil 参考来源：Centos7安装Miniconda及配置jupyter shadowsocksshadowsocks 需要利用 pip 安装 1$ sudo pip install shadowsocks 创建配置文件ss.json 12345678910# vim ss.json&#123; \"server\":\"*.*.*.*\", \"server_port\":***, \"local_server\":\"0.0.0.0\", # 默认127.0.0.1 \"local_port\":1081, \"password\":\"*****\", \"timeout\":600, \"method\":\"aes-256-cfb\"&#125; 启动ss隧道 1234# 前台方式运行/root/miniconda2/envs/base/bin/sslocal -c ss.json# 后台运行nohup /root/miniconda2/envs/base/bin/sslocal -c ss.json &gt;&gt; ss.log 1&gt;2&amp; mysqlMariaDB 是由 MySQL 开发的 MySQL的替代版本。如果我们直接在 Centos 上 yum install mysql 第零步：查看系统版本号12$ cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) 第一步：安装MySQL需要到如下网站上去定位需要安装的版本号 https://dev.mysql.com/downloads/repo/yum/ 注意：我们使用的CentOs Linux 7 选择下面的第二个 不用试图去点击右手边的 Download 按钮，因为这个会导向一个登陆界面。获取版本号后，直接用 wget 下载 12345678910$ wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm# 下载完了以后，还是可以检查一下是否正常下载$ md5sum mysql80-community-release-fc30-1.noarch.rpm$ rpm -ivh mysql80-community-release-fc30-1.noarch.rpm警告：mysql80-community-release-fc30-1.noarch.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:mysql80-community-release-fc30-1 ################################# [100%] 若是安装错误 repo 源了怎么办？我很不幸就干过 12345# 查看所有 mysql 源$ rpm -qa|grep mysql# 删掉安装错误的 mysql 源$ rpm -e mysql80-community-release-fc30-1.noarch --nodeps 安装 MySQL 1$ sudo yum install mysql-server 第二步：启动 mysql 服务1sudo systemctl start mysqld 该命令不会返回报错，为了进一步确认 mysql 服务确实启动 123456789101112$ sudo systemctl status mysqldLoaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2020-01-28 20:07:00 CST; 6s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 12281 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 12402 (mysqld) Status: \"Server is operational\" Tasks: 39 Memory: 616.5M CGroup: /system.slice/mysqld.service └─12402 /usr/sbin/mysqld 第三步：修改默认配置首先，我们需要修改 MySQL 给我们的默认密码，这个直接从日志中获取即可 12cat /var/log/mysqld.log | grep \"temporary password\"2020-01-28T12:06:55.699956Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 5H(?khVdysDW 初始密码只能用于登录，但是此时你不能进行任何操作，必须修改新的密码 在修改密码之前，你需要做的是修改密码的规格（默认的规格···太严格了） 12345# validate_password_policy代表密码策略，默认是1：符合长度，且必须含有数字，小写或大写字母，特殊字符。设置为0判断密码的标准就基于密码的长度了。一定要先修改两个参数再修改密码set global validate_password.policy=0;# validate_password_length代表密码长度，最小值为4set global validate_password.length=4; 最后，修改为合适的密码 1ALTER USER 'root'@'localhost' IDENTIFIED BY 'new password'; 如果我们安装的是 MySQL8.0 以上的版本，加密规则是mysql_native_password,而在mysql8之后,加密规则是caching_sha2_password。为了解决兼容性问题，一般来说，我选择把加密等级调低一点。 1mysql&gt; select host,user,plugin,authentication_string from mysql.user; 最后需要修改一下，加密规则 和 远程登录 12345USE mysql;UPDATE user SET host = &apos;%&apos; where user = &apos;root&apos;;ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;password&apos;;FLUSH PRIVILEGES; 参考资料:CentOS7 安装并配置MySQL8.0How To Install MySQL on CentOS 7centos彻底卸载mysql（不保留数据） Redis12# 用yum 安装$ yum install -y redis 默认是不设置密码的，我们需要在上面进行更进一步的安全策略配置。之前腾讯云上的一台服务器，由于暴露了无密码的redis接口，就中了 挖矿木马 1234567891011121314151617# /etc/redis.conf# bind：绑定主机IP，默认值为127.0.0.1bind 127.0.0.1 # 将这一行指注释掉，可以运行远程访问。不注释，只运行本地访问，安全性很高# daemonize：是否以后台进程运行，默认为no。Windows下不支持修改 。Linux平台下可以改为yes，这样就不用为了启动Redis而单独保留一个shell窗口。# pidfile：如以后台进程运行，则需指定一个pid，默认为/var/run/redis.pid。Windows下不支持修改。daemonize yesport 6379 # 监听端口，默认为6379timeout 300 # 超时时间，设置为300（秒）dbfilename dump.rdb # 本地数据库文件名，默认值为dump.rdbdir /var/lib/redis # 本地数据库存放路径，默认值为 /var/lib/redisrequirepass ABCD123 # 强烈建议设置 连接密码appendonly yes # 是否在每次更新操作后进行日志记录，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认值为no# 每个配置选项前都有详细的英文注释，如有需要可自行查阅配置。 以上只是选择了我认为的一些常用的设置，参考来源：邻居小黑 和 redis 菜鸟教程更多的安全策略，可以借鉴 Redis服务安全加固 yum 安装下来的服务，已经帮我们创建好了服务。我们直接使用重启就可以了 12345678910111213141516$ systemctl restart redis ● redis.service - Redis persistent key-value database Loaded: loaded (/usr/lib/systemd/system/redis.service; disabled; vendor preset: disabled) Drop-In: /etc/systemd/system/redis.service.d └─limit.conf Active: active (running) since 六 2020-03-07 13:39:44 CST; 35s ago Main PID: 12655 (redis-server) Tasks: 3 Memory: 1.0M CGroup: /system.slice/redis.service └─12655 /usr/bin/redis-server 127.0.0.1:6379$ redis-cli127.0.0.1:6379&gt; get abc(error) NOAUTH Authentication required.# 再一次的运行 redis-cli 发现已经需要了密码127.0.0.1:6379&gt; auth YOURPASSWORD dockerdocker 安装其实比较麻烦的，感谢 图灵:Docker开发指南 给的安装建议，我们可以直接用别人写好的脚本。 123456curl https://get.docker.com &gt; install.shchmod +x install.shcat install.sh # 感兴趣的话，可以研究一下 shell 究竟写了啥./install.sh # 安装完了，记得启动 docker 服务sudo systemctl start docker linux下 docker 加速123456789101112131415$ sudo touch /etc/docker/daemon.json # 添加国内站点&#123; \"registry-mirrors\": [\"https://registry.docker-cn.com\",\"http://hub-mirror.c.163.com\",\"https://mirror.ccs.tencentyun.com\",\"https://dockerhub.azk8s.cn\"]&#125;# 重启docker daemon$ sudo systemctl restart docker # 查看是否有修改成功$ docker info # 查看Register Mirrors的信息Registry Mirrors: https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ docker-compose(github 安装) 有条件的话，参考 docker官方教程这一种方法是官方推荐，但是鉴于中国墙，速度有可能非常感人 1. 从 github 上下载 docker-compose 命令1sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.3/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 2. 赋予可执行权限1sudo chmod +x /usr/local/bin/docker-compose 3. 验证是否安装成功1docker-compose --version docker-compose(pip 安装) 一般容易出问题的是 pip 的版本，如果是使用了conda作为包管理的话，可能主要注意pip的版本。我一开始是使用base环境的pip作下载，然后将安装的docker-compose 软连接至 /usr/local/bin 中 1pip install docker-compose Selenium + Chrome 环境配置linux 是无图形化界面，selenium 需要借助图形化的工具，下面我们直接看如何配置。 参考教程：centos7安装selenium 安装selenium1pip install selenium 安装chrome-browser1234567wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm --no-check-certificateyum install ./google-chrome-stable_current_x86_64.rpm# 或者直接使用yum 安装yum install google-chrome# 安装后，注意要查看一下 chrome 的版本号$ google-chrome --versionGoogle Chrome 80.0.3987.87 下载chromedriver 建议到 淘宝镜像下载 更全一点的话，有 官方镜像 12345$ wget https://npm.taobao.org/mirrors/chromedriver/80.0.3987.16/chromedriver_linux64.zip# 解压此文件，并将文件移动到/usr/bin目录下unzip chromedriver_linx64.zip# 移到 /usr/bin 下后，之后运行的时候就不必特意制定 chromedriver 路径了mv chromedriver /usr/bin/ 使用selenium12345678from selenium import webdriverurl='http://bing.com'option = webdriver.ChromeOptions()option.add_argument('--no-sandbox')option.add_argument('--headless')driver = webdriver.Chrome(chrome_options=option)driver.get(url)print(driver.page_source)","categories":[{"name":"centos","slug":"centos","permalink":"http://ppsteven.github.io/categories/centos/"}],"tags":[{"name":"centos","slug":"centos","permalink":"http://ppsteven.github.io/tags/centos/"}]},{"title":"git 实战（持续更新）","slug":"git-skill-in-learning","date":"2020-01-12T08:35:50.000Z","updated":"2020-02-19T09:12:22.397Z","comments":false,"path":"2020/01/12/git-skill-in-learning/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/git-skill-in-learning/","excerpt":"主要记录 git 在实际使用中碰到的问题，会逐步慢慢积累 问题一：新项目如何与远端同步？12345$ git init$ git remote add origin git@e.coding.net:datamate/pujiangjiaoye.git # 添加远端仓库$ git branch --set-upstream-to=origin/master # 设置分支对应关系$ git push --set-upstream origin master # 设置push 对应的远程仓库，建立本地分支的上游$ git remote -v # 查看分支 当我们尝试push的时候又会出现一个问题","text":"主要记录 git 在实际使用中碰到的问题，会逐步慢慢积累 问题一：新项目如何与远端同步？12345$ git init$ git remote add origin git@e.coding.net:datamate/pujiangjiaoye.git # 添加远端仓库$ git branch --set-upstream-to=origin/master # 设置分支对应关系$ git push --set-upstream origin master # 设置push 对应的远程仓库，建立本地分支的上游$ git remote -v # 查看分支 当我们尝试push的时候又会出现一个问题 12345678error: 推送一些引用到 'git@e.coding.net:datamate/pujiangjiaoye.git' 失败提示：更新被拒绝，因为您当前分支的最新提交落后于其对应的远程分支。提示：再次推送前，先与远程变更合并（如 'git pull ...'）。详见提示：'git push --help' 中的 'Note about fast-forwards' 小节。# 按照提示，尝试用git pull 合并,又失败$ git pullfatal: 拒绝合并无关的历史 原因是我们本地与远程的版本不一致，但是我们是新提交，怎么会出现这样的问题呢？因为很多平台在我们创建项目的时候，自动帮我们创建了README.md文件，所以会有不一致的情况存在。git pull 失败的原因是，两个不一致的文件没有共同祖先的历史。 解决方法也很简单 1git pull origin master --allow-unrelated-histories 问题二：如何修改上一次的提交？git 是分支管理的工具，我们的工作最好在一个 commit 中提交相应的代码，完成一个功能（如 bugfix 或者 feature_add ）。但是有的时候，我们的提交经过 Code Review 之后，可能会被打回来。这样面对新的修改，不应该重复提交。 首先，我们可以先建立一个提交。面对第二个文件（这里我们给 a 新增了 Hello world again ） 第一种选择，我们提交两个 commit 12git add .git commit -m \"second commit\" 第二种选择，我们直接修改上一次的修改（推荐） 工作流如下 123git add .git commit --amend # 代表直接在上一次的提交修改，这里会弹出上一次 commit 的信息。git push -f # 由于我们只是改了本地，提交的时候使用 -f 强制推送一下 这里强烈建议，使用 –amend 的方法的时候，一定要检查 commit 的信息，确定不是把别人的给冲掉了。 问题三：服务器端强制同步远端 git 仓库？1234git fetch git reset --hard origin/master # 要强制同步的分支！--hard 是丢弃分支的修改git pullAlready up-to-date. 问题四：为什么修改了 .gitignore 文件，忽略项还是不起作用新建的文件在git中会有缓存，如果某些文件已经被纳入了版本管理中，就算是在.gitignore中已经声明了忽略路径也是不起作用的，这时候我们就应该先把本地缓存删除，然后再进行git的push git清除本地缓存命令如下： 12git rm -r --cached .git add . 下面附上我的 .gitignore 文件 12345678910111213141516171819# Windows:Thumbs.dbehthumbs.dbDesktop.ini# MAC:*.DS_Store# Python:*.py[cod]*.so*.egg*.egg-infodistbuild# My configurations:*.log*.log.* 如何使用 git merge 123456789101112131415# 开发分支（dev）上的代码达到上线的标准后，要合并到 master 分支git checkout devgit pullgit checkout mastergit pull git merge devgit push -u origin master# 当master代码改动了，需要更新开发分支（dev）上的代码git checkout master git pull git checkout dev # 这里默认dev 远端没有动git merge master git push -u origin dev 参考: git merge最简洁用法 推荐一个 git merge 比较好的教程： merge：合并 commits","categories":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"}]},{"title":"如何配置多个git账号","slug":"how-to-manage-multipul-git","date":"2020-01-12T07:02:00.000Z","updated":"2020-02-22T13:20:09.591Z","comments":false,"path":"2020/01/12/how-to-manage-multipul-git/","link":"","permalink":"http://ppsteven.github.io/2020/01/12/how-to-manage-multipul-git/","excerpt":"随着学习和工作的深入，不可避免的会在电脑上有多个 git 账号，那么我们碰到的一个棘手的问题是如何管理我们的 git 账号。 本篇教程就是讲述如何处理这一类问题。","text":"随着学习和工作的深入，不可避免的会在电脑上有多个 git 账号，那么我们碰到的一个棘手的问题是如何管理我们的 git 账号。 本篇教程就是讲述如何处理这一类问题。 介绍Git共有三个级别的 config 文件，分别是 system 、global 和 local。global 的在$home\\.gitconfig，local的在仓库目录下的.git\\config。这三个级别都分别配置了用户信息，当git commit时，会依次从local、global、system里读取用户信息。因此，我们利用local的配置来设置不同的用户信息 生成公钥12345678910111213141516# 查看git账号，会按顺序读取local,global的用户信息git config user.namegit config user.email# 若是在空仓库中使用如下命令会出错，我们在仓库中使用--local，提前运行git initgit config --local -lfatal: --local 只能在一个仓库内使用# 更改本地账号git config --local/--global user.name \"Your name\"git config --local/--global user.email \"Your email\"# 生成公钥ssh-keygen -t rsa -C \"your_email@example.com\" -f ./-t rsa 约定加密类型-C 添加评论-f 保存秘钥的地址（默认是 ~/.ssh/id_rsa） 生成公钥的地方需要注意的是，生成的公钥会自动生成在~/.ssh/id_rsa中，若是你有多个账号的话，无疑会把原先的秘钥覆盖。可以在后续弹出的提示中约定key保存的地址 12Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter] // 推荐使用默认地址Enter passphrase (empty for no passphrase): //此处点击 Enter 键即可，也可以填写密码，填写密码后每次使用 SSH 方式推送代码时都会要求输入密码，由于这个 Key 也不是用于军事目的，所以也无需设置密码。 也可以在ssh-keygen中约定好 1234567ssh-keygen -t rsa -C \"your_email@example.com\" -f ~/.ssh/coding -f 保存在yon下的.ssh/coding文件中Your identification has been saved in /Users/ppsteven/.ssh/coding.Your public key has been saved in /Users/ppsteven/.ssh/coding.pub.The key fingerprint is:SHA256:P6R/Fo70VkCyKsQsFXXX... XXX@outlook.com .ssh 文件夹下也多了coding和coding.pub两个文件 coding是你的私钥，需要好好保管，在下面的配置文件中还需要使用，用以证明你自己的身份，coding.pub是公钥，我们需要上传到github，coding，码云等平台上去。 上传公钥这里只要找到对应上传的地方上传即可，一般平台都有对应的教程，下面我们copy一下coding的操作。 mac 复制文件小技巧 1cat coding.pub | pbcopy # 输出到剪切板 pbcopy : 表示复制剪切版pbpaste ：表示粘贴剪切版 配置config文件和添加私钥若是拥有多个账号，需要在 .ssh 下配置多个账号的配置文件 config ，这个配置文件是用来作为路由使用。我们需要检查是否存在 ~/.ssh/config 文件，不存在的话就创建如下文件。 123456789101112131415161718192021222324# ~/.ssh/config# github 账号Host github # HostName的别名,这个可以随便起HostName github.com # HostName: 远程仓库的域名AddKeysToAgent yes UseKeychain yes # Mac 上秘钥被持久化到&quot;钥匙串&quot;中，代表从钥匙串中使用保存的秘钥IdentityFile ~/.ssh/id_rsa # 私钥存储的地址User git # git 只是ssh的一个应用，会把 User 和 HostName 拼接 # coding 账号Host codingHostName git@e.coding.net # 如果不填写User，可以直接拼接AddKeysToAgent yesUseKeychain yesIdentityFile ~/.ssh/coding # github_work github工作账号Host github-workerHostName github.com AddKeysToAgent yesUseKeychain yesIdentityFile ~/.ssh/github_work User git 为了让SSH识别新的私钥，需将其添加到SSH agent中 12345ssh-agent bashssh-add -D # 删除之前存储的keyssh-add -l # 查看存储的key，这里应该是空的ssh-add ~/.ssh/id_rsassh-add ~/.ssh/coding 测试ssh是否设置成功123456789# ssh -T 后面的名字可以是上面的别名$ ssh -T githubHi PPsteven! You've successfully authenticated, but GitHub does not provide shell access.(base)$ ssh -T codingCoding 提示: Hello ppsteven, You've connected to Coding.net via SSH. This is a personal key.ppsteven，你好，你已经通过 SSH 协议认证 Coding.net 服务，这是一个个人公钥(base) 自动添加 秘钥 的几种方法ssh-add 这个命令是手动把私钥添加到 ssh-agent 所管理的 session 中，ssh-agent 是一个用于存储私钥的临时性的 session 服务。所以当我们重启机器的时候，ssh-agent 的服务也会重置。 方案一：使用 keychain（Mac推荐）keychain 是 Mac 电脑上的钥匙串服务，作用是存储密码、秘钥，证书等信息。Win 和 Linux 也有对应的机制，没有研究。 首先，我们要保证 config 里面有这样两段代码，Mac OS 10.12.2 以上系统需要，不然的话，无法持久化的添加到钥匙串中。 123456789# ~/.ssh/config# github 账号Host github # HostName的别名,这个可以随便起HostName github.com # HostName: 远程仓库的域名+ AddKeysToAgent yes # 是否把+ UseKeychain yes # Mac 上秘钥被持久化到\"钥匙串\"中，代表从钥匙串中使用保存的秘钥IdentityFile ~/.ssh/id_rsa # 私钥存储的地址User git # git 只是ssh的一个应用，会把 User 和 HostName 拼接 然后，利用 ssh-add -K ~/.ssh/[your file] 存储到 keychain 中。 1ssh-add -K Store passphrases in your keychain. 这时候，你可能在你的 钥匙串 中并没有发现成功添加，你可以利用 ssh -T github/coding/.. 也就是上面提到的测试的方法去测一下，如何成功的话，你会发现钥匙串中多了如下信息。 方案二：添加到启动配置中去（Linux推荐）我的 linux 上是直接把 私钥添加到 ssh-agent 中去的，尽管会失效，但是只要每次登陆的时候，都会添加一下就好，这个比较简单，适合懒人。 123$ eval \"$(ssh-agent -s)\"&gt; Agent pid 59566$ ssh-add ~/.ssh/id_rsa 下一个问题，应该把这一段代码添加到哪里。这里的建议是加到 .bashrc 或者 .bashrc_profile 这两个区别是前者是每次打开新 shell 的时候运行。后者是仅在登录的时候执行一次。 更多的地方参考我的另一篇教程：linux 环境变量执行顺序 参考资料如何添加多账号如何设置多个Git帐号 coding帮助中心 下面两个是 google 出来的解答，质量很高，建议参考 How to manage multiple GitHub accounts on a single machine with SSH keys 自动添加ssh账号是否必须每次添加ssh-add (推荐看) Generating a new SSH key and adding it to the ssh-agent (github 官方推荐流程)","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"}]},{"title":"docker命令大全","slug":"docker-cheetsheet","date":"2019-12-31T09:09:15.000Z","updated":"2020-01-26T08:59:10.833Z","comments":false,"path":"2019/12/31/docker-cheetsheet/","link":"","permalink":"http://ppsteven.github.io/2019/12/31/docker-cheetsheet/","excerpt":"最近在实习的过程中，需要将现有的服务上云，使用到了容器化的操作。需要自己制作Dockerfile文件，完成部署。鉴于对于docker技术的不熟练，用了几天时间好好把这个知识梳理了一下。 安装和基础命令详见上一篇文章 Docker安装及基础命令 P.S. 这篇博客又切换回了next 主题，主要的原因是这篇文章中一些代码与Butterfly主题有所冲突，所以又改用兼容性比较好的hexo。今天发现原来WordPress是用php写的，作为一个php程序员肯定要搞一把，之后有时间再研究一下。","text":"最近在实习的过程中，需要将现有的服务上云，使用到了容器化的操作。需要自己制作Dockerfile文件，完成部署。鉴于对于docker技术的不熟练，用了几天时间好好把这个知识梳理了一下。 安装和基础命令详见上一篇文章 Docker安装及基础命令 P.S. 这篇博客又切换回了next 主题，主要的原因是这篇文章中一些代码与Butterfly主题有所冲突，所以又改用兼容性比较好的hexo。今天发现原来WordPress是用php写的，作为一个php程序员肯定要搞一把，之后有时间再研究一下。 docker 镜像拉取镜像12$ docker pull alpine$ docker pull registry.hub.docker.com/alpine:latest 指定默认的仓库和版本号 123456[root@VM_118_62_centos ~]# docker pull alpineUsing default tag: latestlatest: Pulling from library/alpinee6b0cf9c0882: Pull complete Digest: sha256:2171658620155679240babee0a7714f6509fae66898db422ad803b951257db78Status: Downloaded newer image for alpine:latest 列出镜像12$ docker images$ docker image ls 给镜像加tag1$ docker tag alpine test 起到了链接的作用 查看镜像12$ docker inspect IMAGE # 返回json 格式$ docker inspect -f &#123;&#123; .\"DockerVersion\"&#125;&#125; IMAGE # 以GO 模范返回格式化的信息 搜索镜像123docker search IMAGE # 搜索镜像docker search --filter=starts=4 IMAGE # 返回收藏超过4的镜像docker search --filter=is-official=true IMAGE # 返回官方镜像 移除镜像123456789docker rmi IMAGE # 删除镜像docker image rm IMAGE # 删除镜像docker image rm ubuntu:latest # 删除指定tag 的镜像-f --force # 强制删除docker image prune -a, --all Remove all unused images, not just dangling ones （临时镜像） --filter filter Provide filter values (e.g. 'until=&lt;timestamp&gt;') -f, --force Do not prompt for confirmation 创建镜像 commit import build 三个子命令 commit 基于现有容器创建docker run -it alpine /bash/sh 1234# add a new file to this container [root@VM_118_62_centos ~]# docker run -it alpine /bin/sh / # touch text/ # exit docker [container] commit -m “add a new file” -a “johnjhwang” CONTAINER 注：方括号中的 container 是可以省略不写的。这里指出是说明commit 这个命令是 容器相关的命令比较建议写全，比如rm 在image 和 container 中都有，避免歧义 -m: 表示 Comment -a: 表示 Author由于是添加了一个文件，所以镜像的 IAMGE ID 发生了变化 当我们查看新的镜像的时候，能看到我们后续追加的信息 1234567891011[root@VM_118_62_centos ~]# docker inspect 764a657de081[ &#123; &quot;Id&quot;: &quot;sha256:764a657de08117c11b3af9720efe2310386fa99074802ad13f68973081972819&quot;, &quot;Parent&quot;: &quot;sha256:cc0abc535e36a7ede71978ba2bbd8159b8a5420b91f2fbc520cdf5f673640a34&quot;, &quot;Comment&quot;: &quot;add a new file &quot;, ...... &quot;Author&quot;: &quot;johnjhwang&quot;, ...... &#125;] 基于Dockerfile创建首先，创建一个文件Dockerfile 文件名必须是Dockerfile 编辑Dockerfile 12345FROM ununtu:latestLABEL version='1.0' maintainer='johnjhwang@tencent.com'RUN apt-get update &amp;&amp;\\ apt-get install -y python3 \\ apt-get clean 1docker [image] build -t python:3 .(小数点:这是上下文环境为当前目录) python 是镜像名，3是版本号注意，最后有一个点，代表的是上下文环境(当前目录) 基于本地模板导入// TO DO 存出和载入镜像12docker [image] save -o ubuntu_18.04.tar ubuntu:18.04 # 本地会出现ubuntu_18.04.tar 文件docker [image] load -i ubuntu_18.04.tar # 导入本地的文件，之后查看镜像库，发现出现了该镜像 这里我们可以用更加简便的写法 12docker save alpine &gt; alpine.tardocker load alpine &lt; alpine.tar 上传镜像 push// TO DO docker 容器新建容器&amp;&amp;启动容器 create、start、run docker create/start123docker [container] create -it alpine # 用create创建的容器处于停止状态 Created ，加-it 使用的是默认的shdocker [container] start CONTAINER # 运行后的容器状态转为 Up 查看状态 1234[root@VM_118_62_centos ~/desktop]# docker start 77a32260848[root@VM_118_62_centos ~/desktop]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES77a32260848e alpine \"/bin/sh\" 2 minutes ago Up 5 seconds naughty_lamport 还有一个更加方便的启动方式，等价于 先执行create 后执行 start docker run1234docker [container] run -it alpine /bin/sh-t, --tty Allocate a pseudo-TTY 分配一个伪终端 -i, --interactive Keep STDIN open even if not attached 标准输入保持打开 -d, --detach Run container in background and print container ID 暂停终止容器暂停/恢复容器 状态变为： Up (Paused) 1docker [container] pause/unpause CONTAINER 终止/启动容器 stop、kill、运行结束会使容器状态变为： Exited 1234docker [container] stop/start CONTAINER -t, --time int Seconds to wait for stop before killing it (default 10)docker [container] kill CONTAINER stop 是主动向容器发送 SIGTERM 信号，等待一段时候后，再发送SIGKILL信号来终止容器。默认10kill 是直接发送SIGKILL信号去终止容器。 有一种情况，当容器运行结束后，状态也会变为Exited 123456[root@VM_118_62_centos ~]# docker attach test/ # psPID USER TIME COMMAND 1 root 0:00 /bin/sh 6 root 0:00 ps/ # exit // 退出后容器会终止 可以看到容器中只有 /bin/sh 命令运行，此时使用 exit 或者 ctrl+d 退出容器，该容器会终止 清除容器prune12docker container prune # Remove all stopped containers -f, --force Do not prompt for confirmation rm1234docker container rm \\&lt;CONTAINER ID&gt; # Remove one or more containers -f, --force Force the removal of a running container (uses SIGKILL) -l, --link Remove the specified link -v, --volumes Remove the volumes associated with the container 重启容器 先停止容器后重启容器 1docker restart CONTAINER 进入容器attach1docker attach CONTAINER exec exec 相较于 attach 的优势是可以在运行的容器内执行任意命令Run a command in a running container 123456docker exec -it CONTAINER /bin/sh --detach-keys string Override the key sequence for detaching a container // 重载退出容器的方法,默认是ctrl+q -e, --env list Set environment variables -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) -w, --workdir string Working directory inside the container 导入/导出容器12docker [container] export -o test.tar test docker [image] import test.tar test01/test02:v1.0 注意: docker export 是 container 下的方法 docker import 是 image 下的方法，不要以为import 后导入到的容器库。 可以看到 docker [image] save 和 dokcer [image] load 是一对。docker [container] export 和 docker [image] import 是一对。但是 load 和 import 同样都是导入到 镜像库，区别在什么地方? docker save images_name：将一个镜像导出为文件，再使用docker load命令将文件导入为一个镜像，会保存该镜像的的所有历史记录。比docker export命令导出的文件大，很好理解，因为会保存镜像的所有历史记录。 docker export container_id：将一个容器导出为文件，再使用docker import命令将容器导入成为一个新的镜像，但是相比docker save命令，容器文件会丢失所有元数据和历史记录，仅保存容器当时的状态，相当于虚拟机快照。 查看容器123docker [container] inspect CONTAINRERdocker [container] top CONTAINER # 显示docker 内运行的进程 docker [container] stats CONTAINER # 显示docker的状态，CPU，内存，存储，网络等实时监控 * 其他容器命令 制作Dockerfile所需掌握的命令 docker cp 复制文件123Usage: docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH# FROM 左 TO 右 docker [container] cp data test:/temp 这是将本地路径下的 data 复制到 test 容器的/temp 路径下，注意只是复制文件内容，不没有包含文件夹。 docker [container] cp data test:/temp/data 这样才是把data文件夹移到了目标容器的文件夹下 docker container 命令大全12345678910111213141516171819202122232425attach Attach local standard input, output, and error streams to a running containercommit Create a new image from a container&apos;s changescp Copy files/folders between a container and the local filesystemcreate Create a new containerdiff Inspect changes to files or directories on a container&apos;s filesystemexec Run a command in a running containerexport Export a container&apos;s filesystem as a tar archiveinspect Display detailed information on one or more containerskill Kill one or more running containerslogs Fetch the logs of a containerls List containerspause Pause all processes within one or more containersport List port mappings or a specific mapping for the containerprune Remove all stopped containersrename Rename a containerrestart Restart one or more containersrm Remove one or more containersrun Run a command in a new containerstart Start one or more stopped containersstats Display a live stream of container(s) resource usage statisticsstop Stop one or more running containerstop Display the running processes of a containerunpause Unpause all processes within one or more containersupdate Update configuration of one or more containerswait Block until one or more containers stop, then print their exit codes docker 容器卷本章不再详述命令细节，只关注于常用命令 容器中对数据进行持久化的操作，需要借助数据管理操作。 一般有两种管理方式: Data Volumes Data Volume Containers 数据卷(Data Volumes)创建一个本地数据卷 docker volume create -d local –name haha 12-d, --driver string Specify volume driver name (default \"local\") --name 重命名 docker volumn create 创建完成的数据卷是在 /var/lib/docker/volumes 下的，可以通过 ls （查看） inspect(详细信息) prune 和 rm 去做进一步的操作。 123$ docker volume lsDRIVER VOLUME NAMElocal haha 这里mac需要注意，因为在mac上用docker会在mac上启动一个虚拟机运行docker，因此volume创建的directory并不在你的machine上，而是在虚拟机中。 mac用户如何查看数据卷地址如何进入mac上的虚拟机的办法请参考:这篇教程 具体的做法是执行：screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty 然后查看/var/lib/docker/volumes里面的容器 数据卷的类型 volume : 普通数据卷，映射到 /var/lib/docker/volumes下 bind: 绑定数据卷，是自己制定的目录 tmpfs: 临时数据卷，只存在于内存中，目前没有使用过 docker run -d –name test –mount type=bind,source=/mydata,destination=/opt/mydata CONTAINER COMMAND 这句话是绑定当前目录下的mydata文件夹至docker容器下的/opt/mydata文件夹 还有一个简洁的方式 -v docker run -d –name test -v /mydata:/opt/mydata CONTAINER COMMAND 数据容器(Data Volume Containers)创建一个数据卷容器，起别名 dbtest，并挂载 ~/Desktop/dbfile 到当前容器 docker run -it –name dbtest -v ~/Desktop/dbfile:/dbfile alpine:latest 然后，可以在其他容器中使用 –volumes-from 挂载dbtest 中的数据卷 docker run -it –name db1 –volumes-from dbtest alpinedocker run -it –name db2 –volumes-from dbtest alpine 数据卷高级用法：迁移数据数据的迁移有两步构成：备份+迁移 首先我们使用了上面建立好的 dbtest 数据卷容器，该容器和 ~/Desktop/dbfile 绑定，其中包含了我们需要保存的重要的数据。 备份 docker run –volumes-from dbtest -v $(pwd):/backup –name worker alpine tar cvf /backup/backup.tar /dbfile 这里我们把绑定的本地和容器内的/backup绑定，所以我们用压缩方法，把dbfile 内的数据打包放入了/backup文件夹中，直观的来说，在当前目录下会看到backup.tar 文件。 迁移 先创建一个新的数据卷容器dbtest2 docker run -v ~/Desktop/dbfile2:/dbfile –name dbtest2 alpine 创建新容器，挂载dbtest2的容器，并使用untar解压放在/backup/backup.tar 文件 docker run –volumes-from dbtest2 -v $(pwd):/backup –name worker2 ubuntu tar xvf /backup/backup.tar docker 端口映射启动一个web服务 12345docker run -d -P straining/webapp python app.py // 随机映射端口，49000~49900到容器内部端口docker run -d -p 5000:5000 training/webapp python app.py// HostPort:ContainerPortdocker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py// IP:HostPort:ContainerPortdocker run -d -p 127.0.0.1::5000 training/webapp python app.py // 自动分配一个端口docker run -d -p 127.0.0.1::5000/udp training/webapp python app.py // 制定UDP 稍后我们可以看到映射结果（下面是举例） 123127.0.0.1:32768-&gt;5000/tcp 0.0.0.0:3306-&gt;3306/tcp127.0.0.1:32768-&gt;5000/udp 容器互联–link name:aliasname:连接的容器 alias 容器的别名 容器间的互联是一个比较重要的知识点，后续会写一篇博客完善 参考资料docker load与docker import","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Docker","slug":"Docker","permalink":"http://ppsteven.github.io/tags/Docker/"}]},{"title":"Hexo进阶:博客转载文章设置","slug":"Hexo进阶:博客转载文章设置","date":"2019-12-22T07:10:44.000Z","updated":"2020-01-26T09:02:08.612Z","comments":false,"path":"2019/12/22/Hexo进阶:博客转载文章设置/","link":"","permalink":"http://ppsteven.github.io/2019/12/22/Hexo%E8%BF%9B%E9%98%B6:%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD%E6%96%87%E7%AB%A0%E8%AE%BE%E7%BD%AE/","excerpt":"遇见好的博客文章怎么办：1. 打上书签，让它永远的留在你的书签夹中。2. 在博客中转载在博客中转载的目的是把一些 工具类的网站，快捷键的整理记录下来。但是Hexo是用Markdown编写的，没有博客转载的功能，这时候我们就需要借助 HTML 的 iframe 去实现我们的功能了。这一部分知识属于前端的范畴了，也算是对于知识面的一个补充。","text":"遇见好的博客文章怎么办：1. 打上书签，让它永远的留在你的书签夹中。2. 在博客中转载在博客中转载的目的是把一些 工具类的网站，快捷键的整理记录下来。但是Hexo是用Markdown编写的，没有博客转载的功能，这时候我们就需要借助 HTML 的 iframe 去实现我们的功能了。这一部分知识属于前端的范畴了，也算是对于知识面的一个补充。 Same-Domain &amp;&amp; Cross-Domain我们的需求是在用 iframe 引用别人的网站的时候，需要根据这个网站的大小自动调节我们网站的大小。但是因为chrome 的安全限制，我们是无法直接获取别的网站的大小的。 &lt;iframe&gt;’s which display content from different domains have security measures in place to prevent all sorts of stuff. For example, you can’t have JavaScript access anything inside it. It can be very frustrating, for example, if you just want to do something normal and white-hat like adjust the height of the iframe to fit the content inside it. These security measures are in place to prevent all the black-hat kind of things you could do if you did have JavaScript access to the innards of an iframe. 简言之，就是游览器会阻止JavaScript 去做一些高危操作，如果是不一样的domian 的话，获取网站内部信息的行为就会被认为是危险的。 Same-DomianSame-Domain 的解决方法非常多，可以说，百度上搜到的大部分方法都是针对这一情况的。 我们直接附上代码 &amp;&amp; 实例 123456789101112131415161718&lt;style&gt; iframe &#123; width: 100px; min-width: 100%; &#125;&lt;/style&gt;&lt;script type=\"text/javascript\"&gt; function resizeIframe(obj) &#123; obj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px'; obj.style.width = obj.contentWindow.document.documentElement.scrollWidth + 'px'; alert(obj.style.height); alert(obj.style.width); &#125;&lt;/script&gt;&lt;iframe src=\"https://ppsteven.github.io/about/\"frameborder=\"0\" scrolling=\"no\" onload=\"resizeIframe(this)\" id = \"myiframe\"&gt;&lt;/iframe&gt; 下面是实例，这里未了方便展示，我们直接限制了Height最大为400 iframe { width: 100px; min-width: 100%; } function resizeIframe(obj) { obj.style.width = obj.contentWindow.document.documentElement.scrollWidth + 'px'; var height = obj.contentWindow.document.documentElement.scrollHeight; if (height > 400) height = 400; obj.style.height = height + 'px'; //alert(obj.style.height); //提示大小 //alert(obj.style.width); } Cross domain手动定义Size我们尝试使用上面Same-domain 的代码去获取百度的信息 1234&lt;iframe src=&quot;http://www.baidu.com&quot;frameborder=&quot;0&quot; scrolling=&quot;no&quot; onload=&quot;resizeIframe(this)&quot; id = &quot;abc&quot;&gt;&lt;/iframe&gt; 最终我们会得到 游览器 Block 的 警告 这个警告的页面是 在 Chrome 开发者工具的Console 中获得的，以后我们需要多次借助这个工具 123Uncaught DOMException: Blocked a frame with origin &quot;http://localhost:4000&quot; from accessing a cross-origin frame. at resizeIframe (http://localhost:4000/2019/12/21/test/:32:42) at HTMLIFrameElement.onload (http://localhost:4000/2019/12/21/test/:39:2) 其实最重要的问题就是获取 页面的大小，这个过程如果不让游览器自己去完成的话，我们人手工也可以完成，只是费劲一点（当然和写一篇博客比，这个过程可能只花费不到一分钟） 只要在Console 中输入 12document.body.scrollHeightdocument.body.scrollWidth 12345&lt;iframe src=\"http://www.laruence.com/2015/05/28/3038.html\"frameborder=\"0\" scrolling=\"no\"width=\"855px\"highth=\"26012px\"&gt;&lt;/iframe&gt; Autozise第二种方法就是利用postMessage 的方式，这一种方法我也亲自用过了，但是繁琐程度比较高。 需要在 Host.html 和 Frame.html 中都需要插入Js 代码 Host.html 就是 &lt;iframe&gt; 所在html，负责接受 Frame.html 传递过来的参数 Frame.html 也可以看做 source web 的网站，负责 传送数据。 这要求我们主动的去修改目标的html 代码，从中插入Js，这样的话，感觉不是很便捷，而且Js 代码也过于负责，目前不想整理这一块的内容。 具体操作请移步 参考资料 2 静态文本这一段是后加的, 我们可以直接存储html 格式的文件，然后在头部加上yaml 格式即可完成和markdown一样的操作 123---layout: false--- 参考资料 Cross Domain iframe Resizing这篇文章算是国外教程中整理的相当不错的文章了，介绍了在 same-domain 和 cross-domian 两种情况下的应对方式。 http://geekswithblogs.net/rashid/archive/2007/01/13/103518.aspx第一篇的教程就是参考这一篇文章的代码，原创级别","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"},{"name":"iframe","slug":"iframe","permalink":"http://ppsteven.github.io/tags/iframe/"}]},{"title":"PHP+phpstorm+xdebug 环境配置","slug":"PHP+phpstorm+xdebug 环境配置","date":"2019-12-14T15:19:51.000Z","updated":"2020-01-26T08:59:20.781Z","comments":false,"path":"2019/12/14/PHP+phpstorm+xdebug 环境配置/","link":"","permalink":"http://ppsteven.github.io/2019/12/14/PHP+phpstorm+xdebug%20%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"php 环境搭建是一件相当麻烦的事情，本篇博客记录了在Mac 系统下的环境配置。 Win上的php 环境搭建，建议使用XAMPP，一键搭建，而且自带xdebug.dll，用过就知道。Mac 上的php 环境，我一开始也使用了 XAMPP 作为环境，但是发现Mac 上的是阉割版的，也没有xdebug。 目前介绍的环境搭建方法是: brew 和 pecl","text":"php 环境搭建是一件相当麻烦的事情，本篇博客记录了在Mac 系统下的环境配置。 Win上的php 环境搭建，建议使用XAMPP，一键搭建，而且自带xdebug.dll，用过就知道。Mac 上的php 环境，我一开始也使用了 XAMPP 作为环境，但是发现Mac 上的是阉割版的，也没有xdebug。 目前介绍的环境搭建方法是: brew 和 pecl PHP 安装安装过程Mac 上是自带php和Apache的 12$ whereis php/usr/bin/php 我这里准备用brew 装一个最新的 12345678910$ brew search php==&gt; Formulaebrew-php-switcher php@7.2 phpmyadminphp php@7.3 ✔ phpstanphp-code-sniffer phplint phpunitphp-cs-fixer phpmd==&gt; Caskseclipse-php netbeans-php phpstorm(base) 安装最新的 php 7.3 1234567891011121314151617$ brew install php@7.3# 安装后，我们需要添加环境变量php@7.3 is keg-only, which means it was not symlinked into /usr/local,because this is an alternate version of another formula.If you need to have php@7.3 first in your PATH run: echo 'export PATH=\"/usr/local/opt/php@7.3/bin:$PATH\"' &gt;&gt; ~/.zshrc echo 'export PATH=\"/usr/local/opt/php@7.3/sbin:$PATH\"' &gt;&gt; ~/.zshrcFor compilers to find php@7.3 you may need to set: export LDFLAGS=\"-L/usr/local/opt/php@7.3/lib\" export CPPFLAGS=\"-I/usr/local/opt/php@7.3/include\"To have launchd start php@7.3 now and restart at login: brew services start php@7.3Or, if you don't want/need a background service you can just run: php-fpm brew 安装遇到的问题brew 安装php@7.3 的过程中，中间一条命令是 brew clean 产生了问题 12345$ brew cleanupWarning: Skipping opam: most recent version 2.0.3 not installedWarning: Skipping python: most recent version 3.7.2_2 not installedWarning: Skipping sqlite: most recent version 3.27.1 not installedError: Permission denied @ unlink_internal - /usr/local/lib/node_modules/@angular/cli/node_modules/.bin/in-install 既然说我们权限不够，第一反应是使用 sudo 命令，但是brew 不允许用户这么做。 经过查询后，可以使用如下命令，可以给没有权限的文件夹，更改权限。 1$ sudo chown -R \"$(whoami)\":admin /usr/local # 这里文件夹填写需要的 安装 xdebugxdebug 的安装是比较麻烦的，若是没有xdebug 需要的步骤复制很多。涉及到自己编译（自己编译的话，由于计算机环境不同又会产生很多问题） XAMPP 环境的安装这里XAMPP环境的话我建议参考下面的教程 Mac下XAMPP+PhpStorm中集成xdebug 简单的描述一下过程就是： 生成 phpinfo ，复制到 xdebug 官网官网下载xdebug.so 下载xdebug.tgz 解压文件: tar -xvzf xdebug.tgz 编译过程官方教程(有坑) 坑一：使用对phpize 命令。如果你电脑中安装的是XAMPP环境，你需要使用XAMPP环境的phpize /Applications/XAMPP/xamppfiles/bin/phpize 坑二：出现Cannot find autoconf 错误 brew install autoconf 坑三：./configure 编译问题 ./configure --with-php-config=/Applications/XAMPP/xamppfiles/bin/php-config make 获得 xdebug.so 文件 Pecl 方法安装（采用的方法）我们使用的较为简单的方法，就是使用pecl命令，如果我们成功的安装了 php 的话，pecl 是自带的。pecl 相当于为我们省去了编译的过程，也帮我们避免了很多的坑 pecl 之于 php 相当于 pip 之于 python 和 npm 之于 node.js，管理的是 php 的扩展(或者叫插件？) 配置php.ini找到php.ini 地址 12345$ php --iniConfiguration File (php.ini) Path: /usr/local/etc/php/7.3Loaded Configuration File: /usr/local/etc/php/7.3/php.iniScan for additional .ini files in: /usr/local/etc/php/7.3/conf.dAdditional .ini files parsed: /usr/local/etc/php/7.3/conf.d/ext-opcache.ini 添加如下代码 12345678910[xdebug]zend_extension=/Applications/XAMPP/xamppfiles/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so # xdebug 存放路径xdebug.remote_autostart=onxdebug.remote_enable=onxdebug.remote_mode=\"req\"xdebug.remote_host=localhostxdebug.remote_port=9000 # 端口号，记住xdebug.remote_handler=\"dbgp\"xdebug.idekey=\"PhpStorm\"xdebug.profiler_enable = Off 查看xdebug 是否成功安装，使用 php -m 查看所有已安装的扩展，存在xdebug 则表明安装成功。当然也可以使用 phpinfo() 查看xdebug。 注意: 重启Apache 服务才能看到 phpinfo 输出的情况 配置phpstorm 环境xdebug 在phpstorm 中的设置，有大量图，不想重复造轮子。看下面两个教程足够了。 史上最佳 Mac+PhpStorm+XAMPP+Xdebug 集成开发和断点调试环境的配置 Mac下XAMPP+PhpStorm中集成xdebug 实践下来，由于我只是作为php 后端开发，不需要与前端交互的话，我这里只需要保证下面的端口设置正确即可。 后记真实工作环境中，其实由于项目是很大的，实际上没有用到xdebug的机会（主要通过日志排查问题）。我这里安装xdebug 主要是想要通过逐步调试的过程，更好的理解php 语言，协程的使用方法等。 参考资料xdebug 官方安装教程 brew cleanup 问题解决方法–stackoverflow","categories":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/tags/php/"},{"name":"php环境配置","slug":"php环境配置","permalink":"http://ppsteven.github.io/tags/php%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"phpstorm","slug":"phpstorm","permalink":"http://ppsteven.github.io/tags/phpstorm/"}]},{"title":"php协程笔记","slug":"php协程笔记","date":"2019-12-07T10:19:13.000Z","updated":"2020-02-15T17:59:01.513Z","comments":false,"path":"2019/12/07/php协程笔记/","link":"","permalink":"http://ppsteven.github.io/2019/12/07/php%E5%8D%8F%E7%A8%8B%E7%AC%94%E8%AE%B0/","excerpt":"前言在实习的过程中使用到了腾讯微服务平台（Tencent Service Framework，TSF）框架，tsf中经常看到 $ret = (yield func(a,b)); 这样的用法。yield 外面包括号的用法并不常见，实际上这是yield的一种特殊的用法——协程。这里我准备通读一下这一领域的经典教程，好好理解yield 和 协程 是如何在PHP 项目开发中起到作用的。 在PHP中使用协程实现多任务调度| 风雪之隅 作者背景：风雪之隅，PHP开发组核心成员，鸟叔，PHP7的主要开发者。本篇文章其实他对一篇英文教程的翻译之作。 之所以标题起笔记，原因是原文理解起来稍有难度，所以我这里加上自己的理解。本篇可以在大家读原文的过程中做一个参考。","text":"前言在实习的过程中使用到了腾讯微服务平台（Tencent Service Framework，TSF）框架，tsf中经常看到 $ret = (yield func(a,b)); 这样的用法。yield 外面包括号的用法并不常见，实际上这是yield的一种特殊的用法——协程。这里我准备通读一下这一领域的经典教程，好好理解yield 和 协程 是如何在PHP 项目开发中起到作用的。 在PHP中使用协程实现多任务调度| 风雪之隅 作者背景：风雪之隅，PHP开发组核心成员，鸟叔，PHP7的主要开发者。本篇文章其实他对一篇英文教程的翻译之作。 之所以标题起笔记，原因是原文理解起来稍有难度，所以我这里加上自己的理解。本篇可以在大家读原文的过程中做一个参考。 进程、线程、协程的区别进程 进程是程序执行的一个实例 进程是资源分配的最小单位，资源包括：CPU，内存，I/O等 进程间的通讯方式（IPC） &lt;—- 抄，参考https://blog.csdn.net/daaikuaichuan/article/details/82951084 管道 Pipe 命名管道 FIFO * 消息队列（Message Queue) 腾讯的hippo Kafka 信号量（Semaphore） 共享内存（Shared Memory） * 套接字（Socket） 线程 轻量级进程(Lightweight Process，LWP） CPU调度的最小单位 进程由于是拥有系统资源，所以切换时需要保存上下文环境，开销大。线程开销小 协程 协程是一种比线程更加轻量级的存在 与进程线程不同的是，协程是完全由程序控制在（用户态执行） 举例： 当我们读文件的时候，我们可以主动让出控制权，而不是等待I/O操作完成。 特点 极高的执行效率，没有线程那么大的切换开销。我们知道涉及到内核参与管理的程序，需要从用户态通过中断的方式切换到内核态。这样的开销是极大的。 不需要多线程的锁机制，在协程中控制共享资源不加锁 对用户可见 协同，因为是由程序员自己写的调度策略，其通过协作而不是抢占来进行切换 协程的思想本质上就是控制流的主动让出（yield）和恢复（resume）机制（来源：PHP7下的协程实现） 迭代生成器迭代生成器是我们对于 yield 最常用的一个功能。用 yield 替代 return 作为函数的返回最大的作用是，它返回的不仅是一个值，而是一个迭代器。这一优点在面对无法载入到内存的大型数据集有很大的作用。 如以下代码 123456789function xrange($start,$end,$step = 1)&#123; for ($i = $start ; $i &lt;= $end ; $i += $step)&#123; yield $i; &#125;&#125;foreach (xrange(1,10000000000) as $num) &#123; echo $num .\"&lt;br&gt;\";&#125; 很明显，这里使用return的话，返回的是一个非常大的数组，当你数据量特别大的时候会造成数据溢出的问题。yield 的神奇之处在于，它会保持生成器的状态。函数会一直运行，直到下一个yield。程序执行的控制流可以在主代码和生成器函数之间切换，也不用用户担心上下文环境的问题。优点 运行大型数据集 不用编写就能生成复杂的生成器 写一个生成器的流程，需要 被迭代的类实现 IteratorAggregate 接口 定义一个返回迭代类的方法，这个类必须实现Iterator 接口 提供一系列必须实现的方法 rewind : 函数内部指针设置回到数据开始处 valid : 判读是否还有数据 key : 返回数据指针值 current : 返回当前指针指向的值 next : 移动到下一位yield 关键字简化了实现迭代器的过程。 TODO 实现一个PHP Iterator 对象 协程yield 的一个特性是函数每次执行到yield 的时候，就会主动让出控制权。这一点可以很好的帮助我们控制程序的执行顺序。 send 函数public Generator::send ( mixed $value ) : mixed 向生成器中传入一个值，并且当做 yield 表达式的结果。 然后继续执行生成器。 如果当这个方法被调用时，生成器不在 yield 表达式，那么在传入值之前，它会先运行到第一个 yield 表达式。传入生成器的值。这个值将会被作为生成器当前所在的 yield 的返回值。 利用send 函数，我们可以很方便的与协程进行交互，具体如下。 yield 作为参数接受者12345678910111213&lt;?phpfunction logger($fileName) &#123; echo \"这个语句只会执行一次\",\"\\n\"; while (true) &#123; echo yield . \"\\n\"; //函数每次都会执行要yield 暂停，然后让出控制权。 &#125;&#125;$logger = logger(__DIR__ . '/log');$logger-&gt;send('Foo'); // 输出 \"这个语句只会执行一次\", 输出 Foo \\n;$logger-&gt;send('Bar'); // 输出 Bar \\n;?&gt; yield 作用： 类似于debug 时候的断点，每一次都是运行到 yield 停止 可以利用send方法给 yield 传递数据 那自然会有一个疑问，此处的 yield 有没有接受数据回来？经过试验，发现此处的yield 是没有返回数据的。 这个例子可以看到yield 并没有返回数据，是NULL 12345678910111213&lt;?phpfunction logger($fileName) &#123; echo \"这个语句只会执行一次\",\"\\n\"; while (true) &#123; echo yield . \"\\n\"; //函数每次都会执行要yield 暂停，然后让出控制权。 &#125;&#125;$logger = logger(__DIR__ . '/log');$a = $logger-&gt;send('Foo'); // 输出 \"这个语句只会执行一次\", 输出 Foo;var_dump($a); // 返回 NULL , 这里的yield 并没有返回任何值?&gt; yield 同时接受和发送数据123456789101112131415&lt;?phpfunction gen() &#123; $ret = (yield 'yield1'); var_dump($ret); $ret = (yield 'yield2'); var_dump($ret);&#125; $gen = gen();var_dump($gen-&gt;current()); // string(6) \"yield1\"var_dump($gen-&gt;send('ret1')); // string(4) \"ret1\" (the first var_dump in gen) // string(6) \"yield2\" (the var_dump of the -&gt;send() return value)var_dump($gen-&gt;send('ret2')); // string(4) \"ret2\" (again from within gen) // NULL (the return value of -&gt;send())?&gt; 逐句分析 $ gen = gen() 指针指向这个迭代器 $ gen-&gt; current() 运行到第一个yield ，返回 yield 语句的值 yield，并 输出 类型和值 $ gen -&gt;send(“ret1”) 当前生成器在 yield 语句，于是把 “ret1” 当做 （yield “yield1”）的结果，并赋值给 $ret1。而且还会执行一个 gen-&gt;next() 移到下一个yield 处，返回第二个yield 语句的返回值 $ gen -&gt;send(“ret2”) 当前生成器在第二个yield 语句，把”ret2” 当做 (yield “yield2”) 的结果，并赋值给 $ret2 。继续向下执行，此时指针会移至迭代器末尾，此时已经没有yield ，所以返回NULL 多任务合作为了帮助理解 协程和任务调度的关机，yield 在 任务运行的过程中可以主动中断自身，并把控制权交还给调度器。 这里我们先需要实现: 任务、调度器 任务1234567891011121314151617181920212223242526272829303132333435&lt;?phpclass Task &#123; //实现一个任务 protected $taskId; //任务ID protected $coroutine;//协程 protected $sendValue = null;//send 传送的value protected $beforeFirstYield = true;//是不是第一次传送 // 因为每次send 返回的值，都是当前yield 的下一个yield 的返回值，这导致了第一个yield 的返回值被丢弃了。对于第一个 yield，我们需要用current()获取返回值，从第二个往后用send()获取返回值。 public function __construct($taskId, Generator $coroutine) &#123;//协程类型是 迭代器 $this-&gt;taskId = $taskId; $this-&gt;coroutine = $coroutine; &#125; public function getTaskId() &#123; return $this-&gt;taskId; &#125; public function setSendValue($sendValue) &#123; $this-&gt;sendValue = $sendValue; &#125; public function run() &#123; if ($this-&gt;beforeFirstYield) &#123;// 如果是第一次yield，那么就用current()返回 $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); &#125; else &#123;//如果不是第一个yield，就用send设置一个value，并返回下一个yield的值 $retval = $this-&gt;coroutine-&gt;send($this-&gt;sendValue); $this-&gt;sendValue = null;//设置完毕清空value return $retval; &#125; &#125; public function isFinished() &#123; return !$this-&gt;coroutine-&gt;valid();// 判断迭代器是否迭代完毕 &#125;&#125; 迭代器1234567891011121314151617181920212223242526272829303132333435363738&lt;?phpclass Scheduler &#123;//实现一个调度器 protected $maxTaskId = 0; // 最大任务 protected $taskMap = []; // taskId =&gt; task protected $taskQueue;// 任务队列 public function __construct() &#123; $this-&gt;taskQueue = new SplQueue(); // 实例化一个队列 &#125; public function newTask(Generator $coroutine) &#123; $tid = ++$this-&gt;maxTaskId;// 生成任务id $task = new Task($tid, $coroutine); // 创建任务 $this-&gt;taskMap[$tid] = $task;// 标识 taskId =&gt; task $this-&gt;schedule($task); return $tid; &#125; //任务入队 public function schedule(Task $task) &#123; $this-&gt;taskQueue-&gt;enqueue($task); &#125; //任务运行 public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue();// 出队 $task-&gt;run(); //任务运行 if ($task-&gt;isFinished()) &#123; //当前任务结束，删除 unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task);//未完成的话，放入队尾继续执行 &#125; &#125; &#125;&#125;?&gt; 用一个例子看看程序是否按照我们的期望在运行 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpinclude (\"Task.php\"); // 载入定义好的模块include(\"Scheduler.php\");function task1() &#123;// 程序运行10次 for ($i = 1; $i &lt;= 10; ++$i) &#123; echo \"This is task 1 iteration $i.\\n\"; yield; &#125;&#125;function task2() &#123;// 程序运行5次 for ($i = 1; $i &lt;= 5; ++$i) &#123; echo \"This is task 2 iteration $i.\\n\"; yield; &#125;&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task1());$scheduler-&gt;newTask(task2());$scheduler-&gt;run();结果如下:This is task 1 iteration 1.This is task 2 iteration 1.This is task 1 iteration 2.This is task 2 iteration 2.This is task 1 iteration 3.This is task 2 iteration 3.This is task 1 iteration 4.This is task 2 iteration 4.This is task 1 iteration 5.This is task 2 iteration 5.This is task 1 iteration 6.This is task 1 iteration 7.This is task 1 iteration 8.This is task 1 iteration 9.This is task 1 iteration 10. 发现程序是交替运行的，和我们的预期是相同的。因为我们使用了队列的结构，若是一个任务从队列中取出后并没有运行结束，我们会放入队尾继续运行。 与调度器之间的通信我们再看一眼，上面例子中需要运行的程序 123456function task1() &#123;// 程序运行10次 for ($i = 1; $i &lt;= 10; ++$i) &#123; echo \"This is task 1 iteration $i.\\n\"; // &lt;-- 若是要在用调度器中的taskid 替代此句需要怎么做。 yield; &#125;&#125; 如何实现：任务与调度器之间的通信。 我们使用的是 进程用来和操作系统会话的同样的方式来通信：系统调用。 要注意的是，不能简单的把调度器作为一个参数，传递给任务，不然很危险。这里作者通过yield表达式，配合send 来传递信息。 首先是对可调用的系统调用做一个封装 1234567891011121314151617&lt;?phpclass SystemCall &#123; protected $callback; // 传入的值是 一个可调用的类/函数 public function __construct(callable $callback) &#123; $this-&gt;callback = $callback; &#125; // __invoke:当类发生调用的使用使用 // 这样，类在使用的时候看上去和一个函数一样 // 传入的参数是 任务 和 调度器 // 作用是运行 初始化的函数/类 public function __invoke(Task $task, Scheduler $scheduler) &#123; $callback = $this-&gt;callback; return $callback($task, $scheduler); &#125;&#125;?&gt; 下面我们需要进行消息通讯 1234567891011121314151617&lt;?phpfunction task($max) &#123; // 我们需要传入 $tid 的值 从调度器中 $tid = (yield getTaskId()); // &lt;-- here's the syscall! for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"This is task $tid iteration $i.\\n\"; yield; &#125;&#125; $scheduler = new Scheduler; $scheduler-&gt;newTask(task(10));$scheduler-&gt;newTask(task(5)); $scheduler-&gt;run();?&gt; 这里，我们需要对传入的getTaskId 进行修改 传入的值是来自与调度器和任务的，结合之前的封装的系统调用 12345678910&lt;?phpfunction getTaskId() &#123; return new SystemCall(function(Task $task, Scheduler $scheduler) &#123; $task-&gt;setSendValue($task-&gt;getTaskId()); $scheduler-&gt;schedule($task); // 这里返回的是一个系统调用 // 作用是给任务设置 send 的值，send值的内容是 taskid // 把此任务加入调度器的队列中去 &#125;);&#125; 这里return 的不是如函数名写的 taskid，而是一个系统调用。 最后程序中的 $tid = (yield getTaskId()); 又会把这个系统调用传入调度器的队列中 进过这样的操作，我们调度器的队列中有两种类型的任务 SystemCall类型，但是它也可以和函数一样调用 Task 类型，也就是我们的任务类型 所以我们必须还要修改一下调度器的run方法（其实就是加入一段对SystemCall 的处理） 12345678910111213141516171819202122public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue(); $retval = $task-&gt;run(); // 这一段是新加的,如果出队的类型是系统调用，就在调度器里面调用它，传入任务 和 调度器 // 调用的结果是 // $task 会设置一个 Send 值 // $this(调度器) 会把这个 $task 加入到调度器的末尾 if ($retval instanceof SystemCall) &#123; $retval($task, $this); continue; &#125; //-------------------------- if ($task-&gt;isFinished()) &#123; unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task); &#125; &#125;&#125; 在xdebug 的帮助下，我们可以看到第一次 $retval = $task-&gt;run() 的返回值，会走到 Task(line: 24) 的$this-&gt;coroutine-&gt;current(); 最终取得的 getTaskId() 的返回值(类型为 SystemCall) 第二次走到$retval = $task-&gt;run() 的时候，最终是返回task 函数中的yield(); 所以返回值是null。 运行的结果就是，两个任务交替运行，知道结束。 123456789101112131415This is task 1 iteration 1.This is task 2 iteration 1.This is task 1 iteration 2.This is task 2 iteration 2.This is task 1 iteration 3.This is task 2 iteration 3.This is task 1 iteration 4.This is task 2 iteration 4.This is task 1 iteration 5.This is task 2 iteration 5.This is task 1 iteration 6.This is task 1 iteration 7.This is task 1 iteration 8.This is task 1 iteration 9.This is task 1 iteration 10. 协程堆栈协程堆栈是一个非常重要的应用，当你的项目变得越来越大的时候，会出现协程中套用另一个协程的情况。我们看下面这个例子。 123456789101112131415161718&lt;?phpfunction echoTimes($msg, $max) &#123; // 子协程 for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"$msg iteration $i\\n\"; yield; &#125;&#125; function task() &#123; echoTimes('foo', 10); // 期待打印10次foo，实际上返回的协程，并没有真实运行过 echo \"---\\n\"; echoTimes('bar', 5); // 期待打印5次bar，实际上返回的协程，并没有真实运行过 yield; // force it to be a coroutine&#125; $scheduler = new Scheduler;$scheduler-&gt;newTask(task());$scheduler-&gt;run();// 运行结果： ---\\n 最终的结果只运行了echo &quot;---\\n&quot;; 原因也很简单，当echoTimes(&#39;foo&#39;, 10) 运行后，实际上返回的协程，并没有参数去接受，也没有对协程进行进一步的处理（如 $this-&gt;current() $this-&gt;send ）自然也就不会运行了。 但是若是直接调用 echoTimes 子协程，也是无法运行 123456function task() &#123; yield echoTimes('foo', 10); // 添加了 yield 语句 echo \"---\\n\"; yield echoTimes('bar', 5); // 添加了 yield 语句 yield; // force it to be a coroutine&#125; 因为这里yield echoTimes(&#39;foo&#39;, 10);返回的是一个Generator 类型，而在我们的Task 类的run 方法里面，并没有对这一类型进行处理。而且我们需要的是进入函数内执行 yield 语句。这样来说，我们原先的方法就不适用了。如何解决？？ 解决的方法就是使用——协程栈 首先，我们对传入的 $coroutine 裸协程上写一个小小的封装，stackedCoroutine就是：“协程堆栈”。 因为它将管理嵌套的协程调用堆栈。这将使得通过生成协程来调用子协程成为可能。 注意: stackedCoroutine 中包含 yield 语句，所以它也是一个协程 1234567891011121314151617181920212223242526272829303132function stackedCoroutine(Generator $gen)&#123; $stack = new SplStack; // 新建一个栈 // 不断遍历这个传进来的生成器，作用和 while(True)一样 for (; ;) &#123; // $gen可以理解为指向当前运行的协程闭包函数（生成器） $value = $gen-&gt;current(); // 获取中断点，也就是yield出来的值 if ($value instanceof Generator) &#123; // 如果是也是一个生成器，这就是子协程了，把当前运行的协程入栈保存 $stack-&gt;push($gen); $gen = $value; // 把子协程函数给gen，继续执行，注意接下来就是执行子协程的流程了 continue; &#125; // 我们对子协程返回的结果做了封装 $isReturnValue = $value instanceof CoroutineReturnValue; // 子协程返回`$value`需要主协程帮忙处理 if (!$gen-&gt;valid() || $isReturnValue) &#123;// 协程栈没有执行完 或者 存在返回值 if ($stack-&gt;isEmpty()) &#123; return; &#125; // 如果是gen已经执行完毕，或者遇到子协程需要返回值给主协程去处理 $gen = $stack-&gt;pop(); //出栈，得到之前入栈保存的主协程 $gen-&gt;send($isReturnValue ? $value-&gt;getValue() : NULL); // 调用主协程处理子协程的输出值 continue; &#125; $gen-&gt;send(yield $gen-&gt;key() =&gt; $value); // 继续执行子协程 &#125;&#125; 我们发现这段语句中使用了到了一个我们之前没有使用到的类 CoroutineReturnValue 它的作用是接受 yield 的返回值，这个类比较简单，就是对返回的值，做了一层封装。子协程的返回的结果也需要主协程帮助处理。 在 $gen-&gt;send(yield ​$gen-&gt;key()=&gt;$value)； 调用者和当前正在运行的子协程之间扮演着简单代理的角色。 12345678910111213141516class CoroutineReturnValue &#123; protected $value; public function __construct($value) &#123; $this-&gt;value = $value; &#125; // 获取能把子协程的输出值给主协程，作为主协程的send参数 public function getValue() &#123; return $this-&gt;value; &#125;&#125;// 返回的值被封装成了一个类，这个类的话也很简单，就是存值。function retval($value) &#123; return new CoroutineReturnValue($value);&#125; 定义完了协程栈，如何去使用呢？这里需要将Task中的初始化方法改一下。 1234567public function __construct($taskId, Generator $coroutine) &#123; $this-&gt;taskId = $taskId; // $this-&gt;coroutine = $coroutine; // 换成这个，实际Task-&gt;run的就是stackedCoroutine这个函数，不是$coroutine保存的闭包函数了 $this-&gt;coroutine = stackedCoroutine($coroutine); &#125; 主程序如下 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?phpinclude (\"Task.php\");include (\"Scheduler.php\");include (\"stackedCorountine.php\");function echoTimes($msg, $max) &#123; for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"$msg iteration $i\\n\"; yield ; &#125; yield retval(\"程序运行结束\"); //我们在这里让子协程传值&#125;function task() &#123; $ret = yield echoTimes('foo', 5); // print foo ten times if ($ret)&#123; echo $ret; &#125; echo \"---\\n\"; $ret = (yield echoTimes('bar', 2)); // print bar five times if ($ret)&#123; echo $ret; &#125; yield; // force it to be a coroutine&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task());$scheduler-&gt;run();结果:foo iteration 1foo iteration 2foo iteration 3foo iteration 4foo iteration 5程序运行结束---bar iteration 1bar iteration 2程序运行结束 这个程序真的是不容易看懂，我是在xdebug 的逐步调试的过程中才看懂了一点。 解释下$gen-&gt;send(yield $gen-&gt;key()=&gt;$value)； 这个语句中send 和 yield 交叉，而且用了 $gen-&gt;key =&gt; $value 这样的用法。 yield 有三种用法 参考：php manual: yield 123yield; // 相当于 (yield null);$data = (yield $value); // 必须使用圆括号把yield申明包围起来$data = (yield $key =&gt; $value); //返回的是键值对，迭代的时候用 foreach($data as $key =&gt; $value) 首先我们找到 (yield $gen-&gt;key()=&gt;$value)； 返回的地方 12345678910public function run() &#123; if ($this-&gt;beforeFirstYield) &#123; $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); // &lt;-- 返回的是这里 &#125; else &#123; $retval = $this-&gt;coroutine-&gt;send($this-&gt;sendValue); // &lt;-- 返回的是这里 $this-&gt;sendValue = null; return $retval; &#125; &#125; 这里会让人很奇怪，因为我们返回的是键值对，这里直接调用current() 。经过实践可知 最终的值是$value ，也就是说，我们直接把语句改成 (yield $value) 也是正确的。 我的第二个疑问是$gen-&gt;send(yield $gen-&gt;key()=&gt;$value)； 中 send 方法到低发送出去了什么❓ send 方法中是一个yield 语句。那我们就可以找找在这个协程中有没有对应的send 方法即可。 最后，我们找到了这个协程的send 方法，但是$this-&gt;sendValue 我们是一直都没有设置过，始终是null。 协程堆栈小结这个协程堆栈实现起来比较费脑子，特别是主协程和子协程之间的沟通方式。可能现实情况下动手写的情况很少（我感觉是框架已经实现完毕，我们只需要简单的使用 $ret = (yield readfile()); 语句就可以）。但是如果能自己实现一遍协程堆栈，对yield 的用法肯定掌握的更好。 这篇教程参考了很多博客 PHP7下的协程实现 我是这么理解协程yield异步IO的 TO DO LIST yield from 教程中的 非阻塞IO 案例 代码分析 测试 配合我是这么理解协程yield异步IO的 程序附录程序一： 与调度器之间的通讯Index.php 123456789101112131415161718192021222324252627&lt;?phpinclude (\"Task.php\");include (\"Scheduler.php\");include (\"SystemCall.php\");function getTaskId() &#123; return new SystemCall(function(Task $task, Scheduler $scheduler) &#123; $task-&gt;setSendValue($task-&gt;getTaskId()); $scheduler-&gt;schedule($task); &#125;);&#125;function task($max) &#123; $tid = (yield getTaskId()); // &lt;-- here's the syscall! for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"This is task $tid iteration $i.\\n\"; yield; &#125;&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task(10));$scheduler-&gt;newTask(task(5));$scheduler-&gt;run();?&gt; Scheduler.php 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?phpclass Scheduler &#123; protected $maxTaskId = 0; protected $taskMap = []; // taskId =&gt; task protected $taskQueue; public function __construct() &#123; $this-&gt;taskQueue = new \\SplQueue(); &#125; public function newTask(Generator $coroutine) &#123; $tid = ++$this-&gt;maxTaskId; $task = new Task($tid, $coroutine); $this-&gt;taskMap[$tid] = $task; $this-&gt;schedule($task); return $tid; &#125; public function schedule(Task $task) &#123; $this-&gt;taskQueue-&gt;enqueue($task); &#125; public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue(); $retval = $task-&gt;run(); if ($retval instanceof SystemCall) &#123; $retval($task, $this); continue; &#125; if ($task-&gt;isFinished()) &#123; unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task); &#125; &#125; &#125;&#125;?&gt; SystemCall.php 12345678910111213&lt;?phpclass SystemCall &#123; protected $callback; public function __construct(callable $callback) &#123; $this-&gt;callback = $callback; &#125; public function __invoke(Task $task, Scheduler $scheduler) &#123; $callback = $this-&gt;callback; return $callback($task, $scheduler); &#125;&#125; Task.php 123456789101112131415161718192021222324252627282930313233343536&lt;?phpclass Task &#123; protected $taskId; protected $coroutine; protected $sendValue = null; protected $beforeFirstYield = true; public function __construct($taskId, Generator $coroutine) &#123; $this-&gt;taskId = $taskId; $this-&gt;coroutine = $coroutine; &#125; public function getTaskId() &#123; return $this-&gt;taskId; &#125; public function setSendValue($sendValue) &#123; $this-&gt;sendValue = $sendValue; &#125; public function run() &#123; if ($this-&gt;beforeFirstYield) &#123; $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); &#125; else &#123; $retval = $this-&gt;coroutine-&gt;send($this-&gt;sendValue); $this-&gt;sendValue = null; return $retval; &#125; &#125; public function isFinished() &#123; return !$this-&gt;coroutine-&gt;valid(); &#125;&#125;?&gt; 程序二： 协程堆栈index.php 123456789101112131415161718192021222324252627282930&lt;?phpinclude (\"Task.php\");include (\"Scheduler.php\");include (\"stackedCorountine.php\");function echoTimes($msg, $max) &#123; for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"$msg iteration $i\\n\"; yield ; &#125; yield retval(\"程序运行结束\\n\");&#125;function task() &#123; $ret = yield echoTimes('foo', 5); // print foo ten times if ($ret)&#123; echo $ret; &#125; echo \"---\\n\"; $ret = (yield echoTimes('bar', 2)); // print bar five times if ($ret)&#123; echo $ret; &#125; yield; // force it to be a coroutine&#125;$scheduler = new Scheduler;$scheduler-&gt;newTask(task());$scheduler-&gt;run(); stackedCoroutine.php 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?phpfunction stackedCoroutine(Generator $gen) &#123; $stack = new SplStack; for (;;) &#123; $value = $gen-&gt;current(); if ($value instanceof Generator) &#123; $stack-&gt;push($gen); $gen = $value; continue; &#125; $isReturnValue = $value instanceof CoroutineReturnValue; if (!$gen-&gt;valid() || $isReturnValue) &#123; if ($stack-&gt;isEmpty()) &#123; return; &#125; $gen = $stack-&gt;pop(); $gen-&gt;send($isReturnValue ? $value-&gt;getValue() : NULL); continue; &#125; $gen-&gt;send( (yield $gen-&gt;key() =&gt; $value)); &#125;&#125;class CoroutineReturnValue &#123; protected $value; public function __construct($value) &#123; $this-&gt;value = $value; &#125; // 获取能把子协程的输出值给主协程，作为主协程的send参数 public function getValue() &#123; return $this-&gt;value; &#125;&#125;function retval($value) &#123; return new CoroutineReturnValue($value);&#125; Task.php 和 Scheduler.php 不变","categories":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/tags/php/"},{"name":"协程","slug":"协程","permalink":"http://ppsteven.github.io/tags/%E5%8D%8F%E7%A8%8B/"}]},{"title":"如何利用SSH连接家中的服务器:ngrok","slug":"如何利用SSH连接家中的服务器","date":"2019-12-01T05:23:30.000Z","updated":"2020-01-20T17:47:59.749Z","comments":false,"path":"2019/12/01/如何利用SSH连接家中的服务器/","link":"","permalink":"http://ppsteven.github.io/2019/12/01/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8SSH%E8%BF%9E%E6%8E%A5%E5%AE%B6%E4%B8%AD%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"家中闲置了一台电脑，准备用来当做服务器。一方面也是作为linux 学习练练手，二是可以运行一些爬虫小程序或者是网页服务。 这里我用的manjaro，这是目前比较流行的linux 发行版，最热门的linux桌面发行版之一。 我选择manjaro也是想作为替代windows 来用。manjaro拥有一个非常方便的软件仓库，利用pacman和yay等命令可以十分方便的安装软件。","text":"家中闲置了一台电脑，准备用来当做服务器。一方面也是作为linux 学习练练手，二是可以运行一些爬虫小程序或者是网页服务。 这里我用的manjaro，这是目前比较流行的linux 发行版，最热门的linux桌面发行版之一。 我选择manjaro也是想作为替代windows 来用。manjaro拥有一个非常方便的软件仓库，利用pacman和yay等命令可以十分方便的安装软件。 家中的电脑，由于没有公网ip，只能在家中用ssh 访问，一旦出门，就无法访问服务器了。这非常不方便，因为可能要从电脑上获取资料，访问数据库，修改代码等等操作，一旦离开本地环境，也太不方便了。 经过百度后发现，需要利用 内网穿透 技术实现。 原因是我们的ip资源是稀缺的，我们普通家庭中使用的ip都是动态分配的ip地址。没有固定的ip的服务器是无法与外网连接的，所以我们至少需要一个公网ip。 内网穿透技术有很多了，我这里选择的是ngrok 这个方案。我试了一下两种方案，第一个是外国的ngrok，没有尝试成功，而且免费版本每次断开后，生成的url 是随机的。所以没有采用。第二个是国内的Sunny-Ngrok，有免费版的。先尝试一波。 ngrok ngrok.cc （Sunny-Ngrok） 使用Sunny-Ngrok一个很大的好处就是在当你没有服务器和公网ip的时候，它会是一个很不错的解决方案。当然若是你有服务器的话，自己搭一个ngrok未尝不是一个很好的选择。 局域网连接服务器这里先给出用局域网连接服务器的方法 1234# linux 查看ip 地址一般是下面三种方法（不同系统不一样）$ ifconfig$ ipconfig$ ip addr # &lt;--manjaro 运行如下 123456$ ip addr | grep inet inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host inet 192.168.1.102/24 brd 192.168.1.255 scope global dynamic noprefixroute wlp2s0 inet6 fe80::1bd5:9435:6572:ffc7/64 scope link noprefixroute# ip地址是 192.168.1.102 局域网中使用 12ssh -p 22 ppsteven@192.168.1.l02# -p 22 也可以省略，因为ssh 的默认端口号就是22 Sunny-Ngrok教程教程基本上都在 ngrok.cc官方文档 写的很清楚了，但是有一些还是需要注意的。 开通隧道 如果你是想用ssh，开通的就是TCP转发。记得要把本地端口换成22（当然不换也是可以的，只要你最后连ssh 的时候设置好端口就行了） 最后看到的结果是这样的 1$ ssh -p 10568 yourname@free.aa.com 就可以连接上你的服务器了 Ngrok 启动上图可以看到，在状态栏显示 是否成功开启ngrok 启动的方法，官网教程里面也有写，本人按照流程走一遍。 下载客户端我用的是Mac 下载zip文件，然后上传到服务器的操作。有图形界面的同学，可以直接按照官网操作。 1234$ scp ~/Downloads/linux_amd64.zip ppsteven@192.168.1.102:~/Documents$ ssh 192.168.1.102$ cd ~/Documents$ unzip linux_amd64.zip 启动ngrok 服务123# 当前目录在linux_amd64 下$ ./sunny clientid 隧道id # 启动隧道服务$ setsid ./sunny clientid 743acXXXX &amp; # 在后台启动隧道服务 启动服务后，我们在官网的后端就可以看到结果。为了让我们的服务器能不断的在后台运行，我们需要登录服务器后，运行第二行的命令 &amp; 作用是后台运行程序 setsid 作用是当终端关闭的时候命令一直不会关闭 高级教程——开机自动运行官网中已经给出了 Ngrok开机自启动 的教程，我们这里由于使用的是manjaro，官网的教程无法直接参考，我们这里给出自己的解决方案。 第一步：移动命令，并使之可执行12sudo mv sunny /usr/local/bin/sunnysudo chmod +x /usr/local/bin/sunny 第二步：编写启动脚本我们这里直接上手修改官网的shell语言 sunny_auto.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/bash -e### BEGIN INIT INFO# Provides: ngrok.cc# Required-Start: $network $remote_fs $local_fs# Required-Stop: $network $remote_fs $local_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: autostartup of ngrok for Linux### END INIT INFONAME=sunnyDAEMON=/usr/local/bin/$NAMEPIDFILE=/var/run/$NAME.pid# 判断 sunny 是否可执行[ -x \"$DAEMON\" ] || exit 0case \"$1\" in start) # 根据/var/run/sunny.pid 文件判断sunny是否正在运行 if [ -f $PIDFILE ]; then echo \"$NAME already running...\" echo -e \"\\033[1;35mStart Fail\\033[0m\" else echo \"Starting $NAME...\" # start-stop-daemon -S -p $PIDFILE -m -b -o -q -x $DAEMON -- clientid 隧道id || return 2 # 不使用start-stop-daemon，使用常规的方法后台运行 setsid sunny clientid 1cb52410136cfe34 &amp; echo -e \"\\033[1;32mStart Success\\033[0m\" fi ;; stop) echo \"Stoping $NAME...\" # start-stop-daemon -K -p $PIDFILE -s TERM -o -q || return 2 # pkill 是 kill 和 pgrep 的结合，删除所有中带sunny的进程 pkill -9 sunny rm -rf $PIDFILE echo -e \"\\033[1;32mStop Success\\033[0m\" ;; restart) $0 stop &amp;&amp; sleep 2 &amp;&amp; $0 start ;; *) echo \"Usage: $0 &#123;start|stop|restart&#125;\" exit 1 ;;esacexit 0 写完之后，我们需要测试一下 12345chmod a+x sunny_auto.sh./sunny_auto.sh # 会输出使用方法./sunny_auto.sh start ./sunny_auto.sh stop./sunny_auto.sh restart 测试成功后，我们需要让系统自己启动。我看了一下，目前网上大部分教程都是直接给了代码，并没有解释清楚自启动的原理。我认为这是可以通过查看官方教程一步步讲清楚的。抱着“授人以鱼不如授人以渔” 的态度，我准备写的仔细一点。 第三步：自动跑起来我们的系统是manjaro，是arch linux 的衍生版本，所以我们第一想到的就是去 https://wiki.archlinux.org/ 上找。 archlinux 上，在如下九个方面，我们可以完成”autostart” 操作 开关机 登录登出 插入拔出设备 计时事件 文件系统事件 shell登录登出 Xorg 桌面环境 窗口管理启动 这里，我们需要第一项开关机 Systemd 作为我们自启动的方式，其实很多教程中也是采用的这个方式。 单元文件一个服务可以看做是一个unit，每个unit需要编写自己的单元文件。systemd 单元文件的语法来源于 XDG 桌面项配置文件.desktop文件，最初的源头则是Microsoft Windows的.ini文件。 单元文件操作立即激活单元： 1# systemctl start &lt;单元&gt; 立即停止单元： 1# systemctl stop &lt;单元&gt; 重启单元： 1# systemctl restart &lt;单元&gt; 重新加载配置： 1# systemctl reload &lt;单元&gt; 输出单元运行状态： 1$ systemctl status &lt;单元&gt; 检查单元是否配置为自动启动： 1$ systemctl is-enabled &lt;单元&gt; 开机自动激活单元： 1# systemctl enable &lt;单元&gt; 设置单元为自动启动并立即启动这个单元: 1# systemctl enable --now unit 取消开机自动激活单元： 1# systemctl disable &lt;单元&gt; 编辑我们的单元文件单元文件的语法，可以参考系统已经安装的单元，也可以参考 systemd.service(5) 中的EXAMPLES章节。英文不好的同学，有一位热心的大牛，已经写好了中文教程 systemd.index 中文手册 单元文件的地址如下 /usr/lib/systemd/system/ ：软件包安装的单元 /etc/systemd/system/ ：系统管理员安装的单元 从网上的教程看下来，大家最喜欢的一个做法就是创建一个rc.local 文件，和一个rc-local.service 服务。然后把我们需要运行的脚本加入rc.local中。 我认为这样的做法很省事，也比较简单，不过缺点是所有的开机自启服务都放一起了，比较乱不好管理。这里我准备按照自己的想法来创建一个服务，我这里借鉴了docker.service。 sunny.service 1234567891011121314151617[Unit]Description=ngrok sunny[Service]Type=forkingUser=ppsteven# 自动重启服务# Restart=always# RestartSec=30# 执行命令Restart=on-failureExecStart=/etc/sunny.sh startExecStop=/etc/sunny.sh stop# ExecReload=/bin/kill -s HUP $MAINPID[Install]WantedBy=multi-user.target 连接远程服务器ngrok 的作用直观的来说，就是给我们提供了一个公网ip，使我们可以访问内网地址。ngrok的作用就是，将我们传给www.abc.com:12345 的端口转发给我们本地服务器127.0.0.1:22端口上，实现了ssh功能。 1$ ssh -p 12345 yourname@www.abc.com .zshrc 配置小结12$ alias localDell=\"ssh ppsteven@192.168.1.102\"$ alias remoteDell=\"ssh -p 10568 yourname@free.aa.com\" 参考资料有了内网穿透神器 ngrok ，个人电脑也能做服务器","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ppsteven.github.io/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://ppsteven.github.io/tags/ssh/"},{"name":"sunny-ngrok","slug":"sunny-ngrok","permalink":"http://ppsteven.github.io/tags/sunny-ngrok/"}]},{"title":"Docker安装及基础命令","slug":"docker-installation-and-basic-command","date":"2019-11-21T12:22:30.000Z","updated":"2020-05-22T13:49:45.242Z","comments":false,"path":"2019/11/21/docker-installation-and-basic-command/","link":"","permalink":"http://ppsteven.github.io/2019/11/21/docker-installation-and-basic-command/","excerpt":"最近的工作 php 学习，设计到LAMP的环境搭建。虽然是Mac上Apache 和 php 都是自带的，但是环境上还是不足，所以要用Docker。DAMP 爬虫ip 池搭建，发现别人造好的轮子上需要如redis，flask等环境。而且配置完了，最终也是要部署到服务器上去的，所以docker 是必不可少的 最近的工作，让我感到Docker的学习一定要提前了。因为只是先用起来，首先记录一些常用的命令，争取一天搞定。","text":"最近的工作 php 学习，设计到LAMP的环境搭建。虽然是Mac上Apache 和 php 都是自带的，但是环境上还是不足，所以要用Docker。DAMP 爬虫ip 池搭建，发现别人造好的轮子上需要如redis，flask等环境。而且配置完了，最终也是要部署到服务器上去的，所以docker 是必不可少的 最近的工作，让我感到Docker的学习一定要提前了。因为只是先用起来，首先记录一些常用的命令，争取一天搞定。 Docker 安装我的主力机子是Mac，家里用旧电脑搭了 manjaro ，所以我需要两个安装教程 Mac Docker安装Mac 上配置docker最为方便 这里参考 菜鸟教程:MacOS Docker 安装 1234brew cask install docker # 查看是否安装成功docker info docker -v 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。还有 https://registry.docker-cn.com 是官方的中国站点。这些站点存储的是docker hub 的官方热门镜像，如果是私人的镜像，还是需要去美国站点下载。 在任务栏点击 Docker for mac 应用图标 -&gt; Perferences… -&gt; Daemon -&gt; Registry mirrors。在列表中填写加速器地址即可。修改完成之后，点击 Apply &amp; Restart 按钮，Docker 就会重启并应用配置的镜像地址了。 Manjaro docker 安装Manjaro 也拥有非常强大的包管理软件 pacman 和 yay这里我们使用pacman，这里面的软件都是来自官方库 12345678# 安装docker$ sudo pacman -S docker# 启动docker 服务$ sudo systemctl start docker # 查看docker服务状态$ sudo systemctl status docker# 设置docker开启启动服务$ sudo systemctl enable docker 这里Linux 有一个比Mac 麻烦一点的地方，就是每次使用docker 需要用sudo 超级管理员权限 12345678# 如果还没有 docker group 就添加一个sudo groupadd docker# 将自己的登录名($&#123;USER&#125; )加入该 group 内。然后退出并重新登录就生效啦sudo gpasswd -aG $&#123;USER&#125; docker# 重启 docker 服务sudo systemctl restart docker Linux 镜像加速 12345678910111213141516# 新建配置文件$ sudo touch /etc/docker/daemon.json # 添加国内站点&#123; \"registry-mirrors\": [\"https://registry.docker-cn.com\",\"http://hub-mirror.c.163.com\"]&#125;# 重启docker daemon$ sudo systemctl restart docker # 查看是否有修改成功$ docker info # 查看Register Mirrors的信息Registry Mirrors: https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ Centos docker使用脚本安装docker 安装其实比较麻烦的，感谢 图灵:Docker开发指南 给的安装建议，我们可以直接用别人写好的脚本。 123456curl https://get.docker.com &gt; install.shchmod +x install.shcat install.sh # 感兴趣的话，可以研究一下 shell 究竟写了啥./install.sh # 安装完了，记得启动 docker 服务sudo systemctl start docker docker-compose(github 安装) 有条件的话，参考 docker官方教程这一种方法是官方推荐，但是鉴于中国墙，速度有可能非常感人 1. 从 github 上下载 docker-compose 命令1sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.3/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 2. 赋予可执行权限1sudo chmod +x /usr/local/bin/docker-compose 3. 验证是否安装成功1docker-compose --version docker-compose(pip 安装) 一般容易出问题的是 pip 的版本，如果是使用了conda作为包管理的话，可能主要注意pip的版本。我一开始是使用base环境的pip作下载，然后将安装的docker-compose 软连接至 /usr/local/bin 中 1pip install docker-compose Docker 镜像使用12345678910111213141516171819202122232425# 列出本地的镜像 images$docker images$docker image ls REPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest 775349758637 2 weeks ago 64.2MB# 标签的含义- REPOSTITORY：表示镜像的仓库源- TAG：镜像的标签- IMAGE ID：镜像ID- CREATED：镜像创建时间- SIZE：镜像大小# 获取镜像$docker pull ubuntu:13.10# 查找镜像$docker search ubuntu- NAME:镜像仓库源的名称- DESCRIPTION:镜像的描述- OFFICIAL:是否docker官方发布# 删除镜像$docker rmi# 删除所有镜像 创建并启动容器docker run 是docker 命令中比较复杂的一个命令 12345678$docker run &lt;images&gt; &lt;command&gt;$docker run busybox echo hello world$docker run Ubuntu:16.01 /bin/bash$docker run -t-i Ubuntu:16.01 /bin/bash-t-i: 交互式会话-d: 后台方式--rm: 运行完成后就会删除$docker exec -ti &lt;CONTAINER ID&gt; /bin/bash 容器信息12345# 下面所有的&lt;CONTAINER ID&gt; 都可以用容器的NAME 替代# docker 很贴心的为我们的容器起了名字# 列出运行容器$docker ps $docker ps -a # 包含停止但没有消失的容器 容器管理12345678910111213141516# 停止正在运行的容器$docker kill &lt;CONTAINER ID&gt;$docker stop &lt;CONTAINER ID&gt; # 两个命令都是会停止容器运行# 停止没有消失的容器$docker restart &lt;CONTAINER ID&gt;$docker start &lt;CONTAINER ID&gt;# 启动并进入交互界面$docker start -it &lt;CONTAINER ID&gt; /bin/bash# 删除无用的容器$docker rm &lt;CONTAINER ID&gt;# 删除所有已停止的容器$docker rm -v $(docker ps -aq -f status=exited)# 删除所有容器$docker rm $(docker ps -a) 查看docker输出用于查看docker 的输出，对于没有交互(-ti)的容器的时候，需要用这个命令查看容器输出 1$docker logs &lt;CONTAINER ID&gt; 文件拷贝1$docker cp &lt;CONTAINER ID&gt;:[/path/to/file] 参考资料 DockerCheatSheetLinux(Manjaro) -Docker 安装及基本配置","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Docker","slug":"Docker","permalink":"http://ppsteven.github.io/tags/Docker/"}]},{"title":"Github 搜索技巧","slug":"github-search-tips","date":"2019-11-21T12:12:42.000Z","updated":"2020-02-18T18:39:29.477Z","comments":false,"path":"2019/11/21/github-search-tips/","link":"","permalink":"http://ppsteven.github.io/2019/11/21/github-search-tips/","excerpt":"前言因为最近手头上的东西很多，要最快的在很短的时间内完成一个项目，需要多多参考别人的优秀的代码。很多东西，在github 上都开源了，反复造轮子浪费时间，用好别人东西才是最高效的方法。","text":"前言因为最近手头上的东西很多，要最快的在很短的时间内完成一个项目，需要多多参考别人的优秀的代码。很多东西，在github 上都开源了，反复造轮子浪费时间，用好别人东西才是最高效的方法。 瞎逛逛 GitHub Trend 页面总结了每天/每周/每月周期的热门 Repositories 和 Developers，你可以看到在某个周期处于热门状态的开发项目和开发者。 GitHub Topic 展示了最新和最流行的讨论主题，在这里你不仅能够看到开发项目，还能看到更多非开发技术的讨论主题，比如 Job、Chrome 浏览器等。 搜索技巧12345678910in:name xx //搜索名字中带有&quot;xx&quot;的in:readme xx //搜索readme中带有&quot;xx&quot;的in:description xx //搜索描述中带有&quot;xx&quot;的stars:&gt;1000 //搜索stars&gt;1000的forks:&gt;1000 //搜索forks&gt;1000的pushed:&gt;2019-09-01 //搜索最近更新于2019年9月1日之后的language:xx //搜索xx的项目pushed:&gt;2019-09-01 //2019年9月1日后有更新的language:java //用Java编写的项目user:ppsteven forks:&gt;100 //ppsteven用户下forks&gt;100 的项目 有影响力的项目 free-programming-books：整理了所有和编程相关的免费书籍，同时也有 中文版项目。 github-cheat-sheet：集合了使用 GitHub 的各种技巧。 后续会逐步更新添加 参考 掌握 3 个搜索技巧，在 GitHub 上快速找到实用软件资源","categories":[{"name":"基础技能","slug":"基础技能","permalink":"http://ppsteven.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E8%83%BD/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://ppsteven.github.io/tags/Github/"}]},{"title":"PHP学习笔记","slug":"php学习笔记","date":"2019-11-19T11:17:08.000Z","updated":"2020-02-15T18:02:05.494Z","comments":false,"path":"2019/11/19/php学习笔记/","link":"","permalink":"http://ppsteven.github.io/2019/11/19/php%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"php 入门教程，主要来自于菜鸟教程，入门级别，日常学习笔记。找了一个 php 的实习，必须马上掌握啊。","text":"php 入门教程，主要来自于菜鸟教程，入门级别，日常学习笔记。找了一个 php 的实习，必须马上掌握啊。 示例123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;My first PHP page&lt;/h1&gt;&lt;?phpecho \"Hello World!\";?&gt;&lt;/body&gt;&lt;/html&gt; 注释123456&lt;?php// php 代码？&gt;// 单行注释/**/ 多行注释 echo/printecho // 多个print // 一个 12345&lt;?php //两行是相同效果，&lt;br&gt; 看做回车 echo \"Hello world! from:\",\"Elen\",\"&lt;br&gt;\"; print \"Hello world! from:\".\"Elen\".'&lt;br&gt;'; ?&gt; Echo,print,print_r,var_dump 区别 1.echo 输出一个或者多个字符串。 2.print 和 echo 最主要的区别： print 仅支持一个参数，并总是返回 1。 3.print_r 打印关于变量的易于理解的信息,如果给出的是 string、integer 或 float，将打印变量值本身。如果给出的是 array，将会按照一定格式显示键和元素。object 与数组类似。 记住，print_r() 将把数组的指针移到最后边。使用 reset() 可让指针回到开始处。 4.var_dump 此函数显示关于一个或多个表达式的结构信息，包括表达式的类型与值。数组将递归展开值，通过缩进显示其结构。 5.var_dump 和 print_r 的区别 var_dump 返回表达式的类型与值而 print_r 仅返回结果，相比调试代码使用 var_dump 更便于阅读。 EOF 定义字符串1234567&lt;?php$name=\"Sally\";$a= &lt;&lt;&lt;EOF \"hername : \" $name \"123\"EOF;echo $a; output: 1&quot;hername : &quot; Sally &quot;123&quot; 结束需要独立一行且前后不能空格 $name 经过了计算 空格和换行都被处理为一个空格 PHP 类型String（字符串）, Integer（整型）, Float（浮点型）, Boolean（布尔型）, Array（数组）, Object（对象）, NULL（空值） 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?php// String$a = \"Hello world\";// Integer $b = 3;// Float$c = 3.0;$d = (float)$a;// Boolean$e = '3.0'==3; //$e 的值应该是为true，因为== 是弱比较，不关心等式左右的类型$f = true; // Array$g = array('name'=&gt;'wang','year'=&gt;2000);// Objectclass Car&#123; var $color; function __construct($color=\"green\") &#123; $this-&gt;color = $color; &#125; function what_color() &#123; return $this-&gt;color; &#125;&#125;$h = new Car();// NULL$i = null;function print_($obj) &#123; echo $obj,'=&gt;',var_dump($obj),'&lt;br&gt;';&#125;// 输出print_($a);print_($b);print_($c);print_($d);print_($e);print_($f);print_($g);var_dump($h);echo \"&lt;br&gt;\";print_($i);?&gt; 结果如下 123456789Hello world=&gt;string(11) &quot;Hello world&quot;3=&gt;int(3)3=&gt;float(3)0=&gt;float(0)1=&gt;bool(true)1=&gt;bool(true)Array=&gt;array(2) &#123; [&quot;name&quot;]=&gt; string(4) &quot;wang&quot; [&quot;year&quot;]=&gt; int(2000) &#125;object(Car)#1 (1) &#123; [&quot;color&quot;]=&gt; string(5) &quot;green&quot; &#125;=&gt;NULL 常量1234bool define ( string $name , mixed $value [, bool $case_insensitive = false ] )$name:常量名$value:值$case_insensitive:是否对大小写敏感,true 代表不敏感 define(“GREETING”, “欢迎访问 Runoob.com”);echo GREETING; // 输出 “欢迎访问常量默认是全局变量 字符串相关123456//字符串合并$txt .&quot;+&quot;.$txt2 //字符串长度strlen()//字符串查找，未找到返回Falsestrpos(&quot;文本&quot;,&quot;查找字符&quot;) // 返回字符串位置，从0开始 条件语句1234567891011121314151617181920212223242526272829303132&lt;?php$age = 18;$stage = array('青少年','成年','老年');if ($age &gt;=60)&#123; $title = $stage[2];&#125;elseif ($age &gt;=18)&#123; $title = $stage[1];&#125;else&#123; $title = $stage[0];&#125;echo $title,'&lt;br&gt;&lt;br&gt;';$favcolor=\"red\";switch ($favcolor)&#123;case \"red\": echo \"你喜欢的颜色是红色!\"; break;case \"blue\": echo \"你喜欢的颜色是蓝色!\"; break;case \"green\": echo \"你喜欢的颜色是绿色!\"; break;default: echo \"你喜欢的颜色不是 红, 蓝, 或绿色!\";&#125;?&gt; 循环while/do while/for /foreach while/do while123456789101112131415&lt;?php// while echo \"while &lt;br&gt;\";$x = 5;while ($x) &#123; echo $x--,'&lt;br&gt;';&#125;// do .. while echo \"do..while &lt;br&gt;\";$x = 5;do echo $x,'&lt;br&gt;';while ($x--)?&gt; 输出： 12345678910111213while54321do..while543210 for/ foreach123456789101112&lt;?phpfor ($i=1; $i&lt;=5; $i++)&#123; echo \"The number is \" . $i . \"&lt;br&gt;\";&#125;$x=array(\"one\"=&gt;1,\"two\"=&gt;2,\"three\"=&gt;3);foreach ($x as $key =&gt; $value)&#123; echo $key,\" : \",$value,\"&lt;br&gt;\";&#125;?&gt; 输出 12345678The number is 1The number is 2The number is 3The number is 4The number is 5one : 1two : 2three : 3 魔术常量12345678__LINE__: 语句所处的行号__FILE__: 文件的完整路径（含文件名）__DIR__: 文件的目录__FUNCTION__: 函数名__CLASS__: 类名__TRAIT__: Trait 名__METHOD__:类的方法名__NAMESPACE__:命名空间 1234567891011121314151617181920&lt;?phpnamespace MyProject;// 必须是在首行// 魔术常量echo &apos;这是第 &quot; &apos; . __LINE__ . &apos; &quot; 行&apos;,&apos;&lt;br&gt;&apos;;echo &apos;该文件位于 &quot; &apos; . __FILE__ . &apos; &quot; &apos;,&apos;&lt;br&gt;&apos;;echo &apos;该文件位于 &quot; &apos; . __DIR__ . &apos; &quot; &apos;,&apos;&lt;br&gt;&apos;;echo &apos;命名空间为：&quot;&apos;, __NAMESPACE__, &apos;&quot;&apos;; // 输出 &quot;MyProject&quot;class test &#123; function _print() &#123; echo &apos;类名为：&apos; . __CLASS__ . &quot;&lt;br&gt;&quot;; echo &apos;函数名为：&apos; . __FUNCTION__ .&quot;&lt;br&gt;&quot;; echo &apos;类的方法名：&apos; . __METHOD__ ; &#125;&#125;$t = new test();$t-&gt;_print();?&gt; 输出 123456这是第 &quot; 4 &quot; 行该文件位于 &quot; /Library/WebServer/Documents/a.php &quot;该文件位于 &quot; /Library/WebServer/Documents &quot;命名空间为：&quot;MyProject&quot;类名为：MyProject\\test函数名为：_print类的方法名：MyProject\\test::_print 注：PHP中的命名空间，可以解决的问题： 用户编写的代码与PHP内部的类/函数/常量名字冲突 为很长的标识符创建一个更加可读的别名 数组数组定义 自动分配id 1$cars = array(\"Volvo\",\"BMW\",\"Toyota\"); 12345$a = array( 'a',3 =&gt; 'b',1 =&gt; 'c', 'd');var_dump($a)// 输出//array(4) &#123; [0]=&gt; string(1) \"a\" [3]=&gt; string(1) \"b\" [1]=&gt; string(1) \"c\" [4]=&gt; string(1) \"d\" &#125; 关联数组 1$age = array(\"Peter\"=&gt;\"35\",\"Ben\"=&gt;\"37\",\"Joe\"=&gt;\"43\"); 遍历数组 123456&lt;?php$age = array(\"Peter\"=&gt;\"35\",\"Ben\"=&gt;\"37\",\"Joe\"=&gt;\"43\");foreach ($age as $key =&gt; $value) &#123; echo $key,' =&gt; ',$value,' type: ',var_dump($key),'&lt;br&gt;';&#125;?&gt; 数组排序 sort() &lt;–&gt; rsort()asort() &lt;–&gt; arsort() //关联数组ksort() &lt;–&gt; krsort() //关联数组 1234567891011121314151617&lt;?php$age=array(\"a\"=&gt;\"5\",\"c\"=&gt;\"37\",\"b\"=&gt;\"-1\",\"e\"=&gt;\"1\");echo \"原始数组:\";print_r($age);echo \"&lt;br&gt;\";echo \"按key 排序\";ksort($age);print_r($age);echo \"&lt;br&gt;\";echo \"按value 排序\";asort($age);print_r($age);echo \"&lt;br&gt;\";?&gt; PHP 面向对象123456789101112131415161718192021222324252627282930313233343536373839&lt;?phpclass Site &#123; /* 成员变量 */ var $url; var $title; function __construct($par1,$par2)&#123; $this-&gt;url = $par1; $this-&gt;title = $par2; &#125; function __destruct()&#123; echo __FUNCTION__.\" 已经运行\"; &#125; /* 成员函数 */ function setUrl($par)&#123; $this-&gt;url = $par; &#125; function getUrl()&#123; echo $this-&gt;url . PHP_EOL; &#125; function setTitle($par)&#123; $this-&gt;title = $par; &#125; function getTitle()&#123; echo $this-&gt;title . PHP_EOL; &#125;&#125;$siteobj = new Site('www.baidu.com','baidu');print $siteobj-&gt;url;$siteobj-&gt;setUrl('ppsteven.github.io');$siteobj-&gt;setTitle('learnPHP');$siteobj-&gt;getUrl();$siteobj-&gt;getTitle();?&gt; 函数作用域12345678910111213141516171819202122232425262728&lt;?php$y = \"globals varibale\"; //全局变量function myTest($z=null)&#123; global $y; // $y 为全局变量，有两种方式使用 echo $y,'&lt;br&gt;'; echo $GLOBALS['y'],'&lt;br&gt;'; echo '参数作用域',$z; static $x1=0; $x2 = 0; // 局部变量 echo $x1.'('.$x2.\"）\";// 静态变量是不会随着函数完成而删除 $x1++; $x2++;&#125; myTest();myTest();myTest();/*x2(x1)0(0)0(1)0(2)*/?&gt; 其他包含一些小的知识点和未系统整理的知识 三元：expr1 ? expr2 : expr3 12345678&lt;?php $var = true ? 1 : false ? 2 : 3; $varx = (true ? 1 : false)? 2 : 3; $vary = true ? 1 : (false ? 2 : 3);echo $var.'&lt;br&gt;';echo $varx.'&lt;br&gt;';echo $vary.'&lt;br&gt;';// 结果是 2 2 1 , 这里的三元运算需要注意执行的顺序 null == false : 返回的是false 1/2 (0.5) PHP中没有整除算法，有整除函数intdiv(1/2) php 作用域 local global static parameter // 参数作用域 1234567891011121314&lt;?phpfunction myTest()&#123; static $x=0; echo $x; $x++; echo PHP_EOL; // 换行符&#125;// 这里的 static 使得$x 的值会一直累加myTest(); // 0 myTest(); // 1myTest(); // 2?&gt; echo PHP_EOL; // 换行符 == 弱比较=== 强比较","categories":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://ppsteven.github.io/tags/php/"},{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"git cheetsheet","slug":"git-cheetsheet","date":"2019-11-14T11:20:00.000Z","updated":"2020-02-15T18:09:58.285Z","comments":true,"path":"2019/11/14/git-cheetsheet/","link":"","permalink":"http://ppsteven.github.io/2019/11/14/git-cheetsheet/","excerpt":"cheetsheet入门级别的git 基础操作，仅仅收录理解了的，常用的命令。负责的命令，在附录的大全里面可以找到 git configGit 有三层的配置文件 仓库级的配置文件：在仓库的 .git/config 目录下，只对本仓库有效 全局级的配置文件：Mac在 ~/.gitconfig 目录 系统级的配置文件：在Git 的 安装目录下 (经过查找，我的目录为/usr/local/Cellar/git/2.23.0_1/.bottle/etc)","text":"cheetsheet入门级别的git 基础操作，仅仅收录理解了的，常用的命令。负责的命令，在附录的大全里面可以找到 git configGit 有三层的配置文件 仓库级的配置文件：在仓库的 .git/config 目录下，只对本仓库有效 全局级的配置文件：Mac在 ~/.gitconfig 目录 系统级的配置文件：在Git 的 安装目录下 (经过查找，我的目录为/usr/local/Cellar/git/2.23.0_1/.bottle/etc) 12345678910111213141516171819# --local: 仓库级 , --glocal: 全局级 , --system: 系统级# 添加配置$ git config --global user.name \"Name\" # 添加用户名 --global 代表配置的全局的参数$ git config --global user.email \"email@example.com\" # 添加邮箱# 查看配置$ git config --list/ -l # 查看全部git配置$ git config --get user.name/user.email # 查看单个配置# 删除配置$ git config --unset user.name# 编辑配置$ git config -e --global# 添加别名，对于一些比较长的别名，可以简化# 也可以通过git config $ git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit\"$ git config --global alias.graph \"log --graph --oneline\" git init12$ git init # 创建空的git代码库$ git init Myfolder # 创建文件夹Myfolder，并创建git代码库 文件（增删改提）git add 增123456789101112131415# 把指定的文件添加到暂存区中$ git add &lt;文件路径&gt;# 添加所有修改、已删除的文件到暂存区中$ git add -u [&lt;文件路径&gt;]$ git add --update [&lt;文件路径&gt;]# 添加所有修改、已删除、新增的文件到暂存区中，省略 &lt;文件路径&gt; 即为当前目录$ git add -A [&lt;文件路径&gt;]$ git add --all [&lt;文件路径&gt;]$ git add . # 当前目录（递归子目录）# 查看所有修改、已删除但没有提交的文件，进入一个子命令系统$ git add -i [&lt;文件路径&gt;]$ git add --interactive [&lt;文件路径&gt;] git commit 提交123456789101112131415# 把暂存区中的文件提交到本地仓库，调用文本编辑器输入该次提交的描述信息$ git commit# 把暂存区中的文件提交到本地仓库中并添加描述信息$ git commit -m \"&lt;提交的描述信息&gt;\"# 把所有修改、已删除的文件提交到本地仓库中# 不包括未被版本库跟踪的文件，等同于先调用了 \"git add -u\"$ git commit -a -m \"&lt;提交的描述信息&gt;\"# 修改上次提交的描述信息$ git commit --amend -m \"desc\"# 拿372a* 提交的信息（作者、提交者、注释、时间戳等）来提交当前修改$ git commit -c 372a git reset 还原12345678910111213141516# 重置暂存区，但文件不受影响# 相当于将用 \"git add\" 命令更新到暂存区的内容撤出暂存区，可以指定文件# 没有指定 commit ID 则默认为当前 HEAD# 丢弃暂存区中的所有文件的修改（工作区不受影响）$ git reset $ git reset --mixed $ git reset &lt;文件路径,commit ID&gt;$ git reset --mixed &lt;文件路径,commit ID&gt;$ git reset --hard HEAD^ # 回到上一个版本（HEAD: 当前版本，HEAD^: 上一个版本，HEAD~100: 往上100个版本）$ git reset --hard 1234567 # 回到指定版本号commit id（此处：commit id 假设为1234567******，Git会根据commit id的前几位自动寻找对应的版本）$ git reset --soft HEAD~ # hard 和 soft 的区别在与 soft（暂存区和工作区中的所有文件的修改都不丢弃）$ git reset --merge &lt;commit&gt; // 在被污染的工作区中回滚merge或者$ git reflog # 查看命令历史 git revert 反做12# 生成一个新的提交来撤销某次提交，此次提交之前的所有提交都会被保留。$ git revert &lt;commit ID&gt; 比较一下 git revert 和 git reset 的区别： git reset是把HEAD向后移动来删除提交，而git revert是用一次新的提交来回滚之前的提交（HEAD会继续前进）。下面一幅图比较形象生动。 关于git 的版本回退的问题，廖雪峰的博客：时光穿梭机已经讲的很好了，我们可以通过git log 查看“当前”版本库的状态，但是如何查看“未来”的版本库呢？可以通过git reflog 查看。 git remove 删除1234$ git rm &lt;文件路径&gt; # 删除工作区文件，若文件在工作区或缓存区中有修改，会失败。有两种解决方式：1、强制删除 2、只删除暂存区的文件$ git rm -f &lt;文件路径&gt; # 1.无论有没有在工作区或暂存区修改，强制删除$ git rm --cached &lt;文件路径&gt; # 2.移除暂存区的文件，在本地仓库的文件夹中保留该文件$ git rm -r &lt;文件夹路径&gt; # 移除文件夹 git diff12345678910111213141516171819# 比较当前文件和暂存区中文件的差异，显示没有暂存起来的更改$ git diff# 比较暂存区中的文件和上次提交时的差异$ git diff --cached$ git diff --staged# 比较当前文件和上次提交时的差异$ git diff HEAD# 查看从指定的版本之后改动的内容$ git diff &lt;commit ID&gt;# 比较两个分支之间的差异$ git diff &lt;分支名称&gt; &lt;分支名称&gt;# 查看两个分支分开后各自的改动内容$ git diff &lt;分支名称&gt;...&lt;分支名称&gt;# 可以使用 Beyond Compare4 软件 * git checkout 恢复12345678910# 当在暂存区中有修改时，使用暂存区中的修改覆盖工作区中的 &lt;文件路径&gt;# 当不在暂存区中时，使用本地版本库中的HEAD指针处的修改覆盖工作区中的&lt;文件路径&gt;$ git checkout -- &lt;文件路径&gt;# 用本地版本库中 HEAD处提交的文件，覆盖 暂存区和工作区的文件$ git checkout HEAD &lt;文件路径&gt;# 用本地版本库中 93ef处提交的文件，覆盖 暂存区和工作区的文件$ git checkout 93ef &lt;文件路径&gt;# 替换掉本地的改动，新增的文件和已经添加到暂存区的内容不受影响$ git checkout &lt;文件路径&gt; 恢复文件举例 a 文件被修改过，checkout 去除修改 123456789$ cat a Hello worldorphan`$ git checkout aUpdated 1 path from the index$ cat aHello worldadd a line git 日志与文件状态git status 状态12345678910# 查看当前所处的分支暂存区和工作区的文件（会显示当前所处分支）# 注1：处于暂存区的文件状态:：staged(已暂存)；处于工作区的文件状态:：untrack(未跟踪)、modified(已修改)# 注2：工作区中的空目录不会被git追踪$ git status$ git status &lt;branch name&gt;# 以简短模式查看暂存区和工作区的文件# 会显示两列，第一列是文件的状态，第二列是对应的文件# 文件状态：A 新增，M 修改，D 删除，?? 未添加到Git中$ git status -s git log 日志12345678910111213141516171819202122# 打印所有的提交记录$ git log# 打印从第一次提交到指定的提交的记录$ git log &lt;commit ID&gt;$ git log -- &lt;文件&gt;# 打印指定数量的最新提交的记录$ git log -&lt;指定的数量&gt;# 高级功能# 记不住可以设置别名$ git log -p &lt;文件&gt; # 显示出每次修改的内容$ --graph # 图形化的方式显示$ --graph --oneline # 图形化简洁模式$ --graph --oneline --name-only # 图像化简洁模式（只显示文件名清单）$ --author = leon # 限定作者leon$ --grep = \"test\" # 限定注释$ --since=\"2018-10-7\" --until='2019-10-12'# since,until 标记对和 after，before 标记对是等价的$ --after=\"2018-10-7\" --before='2018-10-12'$ --since=2.weeks # 最近2周的提交记录 git show 显示修改1234567# 统计各个提交者的次数$ git shortlog -sn # 显示修改内容(详细)$ git show 3a6c$ git show HEAD# 显示最近一次提交的修改内容（不显示具体的修改内容）$ git show --name-only HEAD 分支管理git branch1234567891011121314151617181920212223242526272829303132# 列出本地的所有分支，当前所在分支以 \"*\" 标出$ git branch# 列出本地的所有分支并显示最后一次提交，当前所在分支以 \"*\" 标出$ git branch -v$ git branch -r # 列出所有远程分支 cache$ git branch -a # 列出所有本地分支和远程分支cache$ git branch -av # 列出所有本地分支和远程分支cache（含简单说明）$ git branch -vv # 查看本地分支和远程分支cache的追踪关系# 创建新分支，新的分支基于上一次提交建立$ git branch &lt;分支名&gt;# 修改分支名称# 如果不指定原分支名称则为当前所在分支$ git branch -m [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 强制修改分支名称$ git branch -M [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 删除指定的本地分支# 删除的时候需要从被删除的分区切换出去$ git branch -d &lt;分支名称&gt;# 强制删除指定的本地分支$ git branch -D &lt;分支名称&gt;# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream hexo origin:hexo ??# 如果在本地新建了分支，远程没有分支的情况$ git branch --set-upstream origin master # 建立联系$ git branch -vv # 查看本地和远程的追踪关系 git checkout 分支切换123456# git 提交流程 工作区-&gt; 暂存区 -&gt; 版本库$ git checkout &lt;分支名称&gt; # 切换分支$ git checkout -- &lt;file&gt; # 撤销修改：1. 文件在添加到缓存区前修改，则回退到原工作区状态；2. 文件在添加到缓存区后修改，则回退到原缓存区状态。也即是将&lt;file&gt;撤回到最近一次git add或git commit状态（注：--表示在当前分支，如果没有，则切换到另一个分支）$ git checkout -b &lt;分支名称&gt; # 创建并切换$ git checkout --orphan &lt;分支名称&gt;# 创建并切换到指定的分支，删除所有的提交记录$ git checkout -# 切换到上一次分支 git merge/rebase 分支合并 12345678# 把指定的分支合并到当前所在的分支下$ git merge &lt;分支名称&gt; # 无冲突时会直接提交$ git merge --no-commit &lt;分支名称&gt; # 不自动提交$ git merge --no-ff -m \"merge with no-ff\" &lt;name&gt; # 合并后的分支有历史记录，而Fast-Forward合并之后，分支没有历史记录# Fast-Forwar 的合并的方法是指针的移动。$ git rebase &lt;分支名称&gt; # rebase 能保持清晰的提交记录，但是合并的操作没有记录下来（merge 则是会新建一个提交） 远程操作git clone 克隆12345678910111213141516# 克隆文件# Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快，https 每次推送都必须输入口令。git clone https://github.com/XXX/learngit.git Yourfilepath # httpsgit clone git@github.com:XXX/learngit.git ./lesson01 # ssh（推荐）# 默认在当前目录下创建和版本库名相同的文件夹并下载版本到该文件夹下$ git clone &lt;远程仓库的网址&gt;# 指定本地仓库的目录$ git clone &lt;远程仓库的网址&gt; &lt;本地目录&gt;# -b 指定要克隆的分支，默认是master分支$ git clone -b &lt;分支名称&gt; &lt;远程仓库的网址&gt; &lt;本地目录&gt;# -o 设置远程仓库为origin$ git clone -o &lt;orgin name&gt; https://github.com/kekec/Test.git git remote1234567891011121314151617181920212223242526272829303132333435363738# 列出已经存在的远程仓库$ git remoteorigin # 列出远程仓库的详细信息，在别名后面列出URL地址$ git remote -v$ git remote --verboseorigin https://github.com/kekec/Test.git (fetch)origin https://github.com/kekec/Test.git (push)# 添加远程仓库$ git remote add &lt;远程仓库的别名&gt; &lt;远程仓库的URL地址&gt;# 修改远程仓库的别名$ git remote rename &lt;原远程仓库的别名&gt; &lt;新的别名&gt;# 删除指定名称的远程仓库$ git remote remove/rm &lt;远程仓库的别名&gt;# 修改/显示远程仓库的 URL 地址$ git remote set-url &lt;远程仓库的别名&gt; &lt;新的远程仓库URL地址&gt;$ git remoter get-url &lt;远程仓库的别名&gt;# 显示远程仓库的信息（举例）$ git remote show origin * remote origin Fetch URL: https://github.com/kekec/Test.git Push URL: https://github.com/kekec/Test.git HEAD branch: master Remote branches: master tracked v3.1 trackedLocal branch configured for 'git pull': master merges with remote masterLocal refs configured for 'git push': master pushes to master (fast-forwardable) v3.1 pushes to v3.1 (up to date)# 可以查看 git pull 和 git push 的具体信息 git fetch 从远程仓库获取最新的版本到本地分支上 12345# 将远程仓库所有分支的最新版本全部取回到本地$ git fetch origin# 将远程仓库指定分支的最新版本取回到本地$ git fetch orgin master/dev * git pull git pull &lt;远程仓库名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 从远程仓库获取最新版本并合并到本地。首先会执行 git fetch，然后执行 git merge，把获取的分支的 HEAD 合并到当前分支。 1234# 先执行fetch，然后将远程origin/master分支merge合并到当前分支（最后会更新origin/master, origin/HEAD指针到最新提交）$ git pull origin master$ git pull -r origin master # 先执行fetch，然后将远程origin/master分支rebase合并到master分支$ git pull origin master:dev # 先执行fetch，然后将远程origin/master 分支merge合并到本地dev分支 * git push 把本地仓库的提交推送到远程仓库。 git push &lt;远程仓库的别名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 1234567891011# 将本地仓库的修改push到origin所指向的远程仓库URL的master分支上，并在.git/config文件中记录当前分支与远程分支master的对应关系$ git push -u origin master # -u 在第一次push的时候使用即可$ git push origin -f # 当合入对应的远端仓库有冲突的时候，使用当前分支更新$ git push origin --all # 推送本地的所有的分支到各自的远端分支# 删除指定的远程仓库的分支$ git push &lt;远程仓库的别名&gt; :&lt;远程分支名&gt;$ git push &lt;远程仓库的别名&gt; --delete/-d &lt;远程分支名&gt;$ git push origin:dev # 删除远端分支 dev$ git push origin -d dev # 效果同上 存储文件的区块贮藏区 git stash123456789101112131415161718$ git stash # 将工作区中所有文件的修改备份压栈到储藏区，然后丢弃工作区与暂存区的所有文件的修改。# 经过试验，git stash 会丢弃已有文件的修改的，不会删除新建的文件。$ git stash pop # 恢复工作区，并将贮藏区的备份删除$ git stash list # 查看贮藏区stash@&#123;0&#125;: WIP on master: 30e5191 add a$ git stash show -p stash@&#123;0&#125; # 查看栈顶文件的修改diff --git a/a b/aindex 11817a2..399e9b0 100644--- a/a+++ b/a@@ -1,3 +1,4 @@ Hello world add a line+add a line$ git stash drop # 直接移除储藏区的栈顶处备份（不用于恢复当前分支的工作区）$ git stash clear # 清除储藏区栈列表$ git stash apply stash@&#123;0&#125; # 使用stash@&#123;0&#125;来恢复当前分支的工作区，但不移除储藏区中任何备份 工作区 git clean12$ git clean -nd # 探测工作区中有哪些未追踪状态的文件和目录$ git clean -fd # 删除工作区中未追踪状态的文件和目录 暂存区 git ls-files1234$ git ls-files # 查询暂存区中的文件列表（递归子目录）# 下面是抄的$ git ls-files -s // 查看暂存区中所有文件的blob数据块信息$ git ls-files -s -- README.md // 查看暂存区中的README.md文件的blob数据块信息 打包 git archive12# 将当前master分支所有文件使用zip压缩方式打包到d:/file.zip$ git archive --format zip --output ./file.zip master 团队合作分支 TO DO LIST 看完教程git 教程 补充 参考资料 廖雪峰git教程 Git原理与命令大全 Git命令大全","categories":[{"name":"cheetsheet","slug":"cheetsheet","permalink":"http://ppsteven.github.io/categories/cheetsheet/"}],"tags":[{"name":"日常学习笔记","slug":"日常学习笔记","permalink":"http://ppsteven.github.io/tags/%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"git","slug":"git","permalink":"http://ppsteven.github.io/tags/git/"},{"name":"cheetsheet","slug":"cheetsheet","permalink":"http://ppsteven.github.io/tags/cheetsheet/"}]},{"title":"Pine Script 学习笔记(二)——基本特点","slug":"Pine Script 学习笔记(二)","date":"2019-11-04T13:45:13.000Z","updated":"2020-02-15T18:07:54.202Z","comments":false,"path":"2019/11/04/Pine Script 学习笔记(二)/","link":"","permalink":"http://ppsteven.github.io/2019/11/04/Pine%20Script%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/","excerpt":"前言这是Pine Script 学习笔记的第二篇，简单挑教程上重要的记录了一下。","text":"前言这是Pine Script 学习笔记的第二篇，简单挑教程上重要的记录了一下。 Context switching and the security functionsecurity 函数可以用于按照特定要求请求数据 1234//@version=4study(&quot;Example security 1&quot;, overlay=true)ibm_15 = security(&quot;NYSE:IBM&quot;, &quot;15&quot;, close)plot(ibm_15) 1security(symbol, resolution, expression, gaps, lookahead) symbol (string) 商品代码。 商品代码可以包含数据提供商信息，也可以不含 如 “NYSE:IBM”,”BATS:IBM”,”IBM”(如不提供，默认使用BATS) syminfo.ticker and syminfo.tickerid是表示当前图标上的商品代码，syminfo.ticker是不含数据供应商信息，syminfo.tickerid是包含供应商信息。Pine教程建议使用后者，为了避免数据的模糊性 resolution (string) 分辨率/ timeframe时间周期 分钟级：1，5，10，21，60，120，等等 日级: D,1D,2D 等等 周级：W，1W，2W 月级：M，1M，2M timeframe.period 记录当前图标时间周期 expression (series) 计数并从 security调用返回的表达式。 如果仅仅是获取收盘价数据，我们可以用security(&#39;EURUSD&#39;,&#39;D&#39;,close) 但是，expression能给我们提供更加丰富的操作，比如，我们需要知道，EURUSD相对于GBPUSD 上涨的幅度 1234567//@version=4study(title = &quot;Advance Decline Ratio&quot;, shorttitle=&quot;ADR&quot;)ratio(t1, t2, source) =&gt; s1 = security(t1, timeframe.period, source) s2 = security(t2, timeframe.period, source) s1 / s2plot(ratio(&quot;GBPUSD&quot;, &quot;EURUSD&quot;, close-open)) 如上图所以，GBPUSD上涨幅度/EURUSD 的上涨幅度我们可以很轻松的通过7行代码实现。在绝大多数情况下，两者是同比例变动，但是在某些特等情况下，变化是相反的。这对于研究这两种货币对的走势关系有很大的帮助。 在security数据应用到当前图表上的时候，有两个控制，一个是gaps，另一个是lookahead gaps (const bool) 默认值为barmerge.gaps_off。可以理解为数据平滑的操作，因为数据中会存在空值（na），在gaps_off的情况下，na会被离它最近的非空值所替代，也就不会出现间隔（gap）的情况 lookahead (const bool) 默认值为barmerge.lookahead_off。 合并所请求数据位置的策略。 请求的条形图与当前的条形图按照k线开盘时间合并。 这种合并策略可能导致从“未来”获取数据计算历史的不良影响。 这在回溯测试策略中不被接受，但在指标中可使用。 123456//@version=4study(&apos;My Script&apos;, overlay=true)a = security(syminfo.tickerid, &apos;60&apos;, low, lookahead=barmerge.lookahead_off)plot(a, color=color.red)b = security(syminfo.tickerid, &apos;60&apos;, low, lookahead=barmerge.lookahead_on)plot(b, color=color.lime) 红色是lookahead_off，绿色是lookahead_on。 我们发现开启了lookahead功能后，所产生的最低价是整个时间段的最低价，而原先是开盘K点的最低价。 bar state.* 变量 barstate.isfirst 当前k线为k线组的第一条k线 barstate.islast 当前k线为k线组的最后一条k线 barstate.ishistory 当前k线为历史k线 batstate.isrealtime 当前k线为实时k线 barstate.isnew 新K线的第一次更新 batstate.isconfirmed =当前k线的最后(关闭)更新 不建议在security表达式中使用barstate.isconfirmed 所有的历史柱线都曾被认为是新的柱线，因为脚本是依次执行的。当柱线第一更开盘价生成的时候，认为此柱线是新的。 会话和时间信息Pine 提供方法来生成 交易区间，时间和日期的信息。 time(变量): 返回的是时间戳格式 time(函数)：time(resolution, session) → series 返回的是按照session 格式返回的时间，如果不在session时间段的话便会返回na值 1234//@version=4study(&quot;Time&quot;, overlay=true)t1 = time(timeframe.period, &quot;0000-0000&quot;)bgcolor(t1 ? color.blue : na) session = “0000-0000:23456” 即24h，去除周六日，运行结果如下 可以看到，周一至周五背景都变成了蓝色，因为t1 不在session的范围内的时候返回na值 交易区间的格式有 0000-0000:1234567 24小时交易，时间从午夜0点开始 0000-0000:23456 工作日24小时交易 1700-1700：24小时交易，时间从17点开始 0930-1700:146 交易时间为09:30~17:00，交易时间在周日（1），周三（4），周五（6） 24x7 等价于 0000-0000:1234567 1234567// 判断是否为30min的新柱线//@version=4study(&quot;new 30 min bar&quot;)is_newbar(res) =&gt; t = time(res) not na(t) and (na(t[1]) or t &gt; t[1])plot(is_newbar(&quot;30&quot;) ? 1 : 0) 用到的函数变量和类型 time：UNIX格式的当前k线时间 timenow：UNIX格式的当前时间 syminfo.timezone：时区 当前K线用到的变量 year/month/weekofyear dayofmonth dayofweek（sunday,monday 等） hour/minute/second 创建时间 timestamp(year, month, day, hour, minute) 策略编写backtesting &amp; forwardtestingstrategy脚本是可以产生交易订单的Pine 脚本。利用strategy 可以做策略回测（backtesting）和 模拟交易（forwardtesting） 无论backtesting 还是forwardtesting，计算都是默认发生在K线收盘的时候，但是在forwardtesting 的时候，可以选择在每一个tick发生的时候，都运行一次。 做法一是调整strategy的 Setting/Properties，或者修改代码，添加strategy(... ,calc_on_every_tick=true ) ，此外还可以选择在每笔订单完成之后计算strategy(... , calc_on_order_fills=true) 经纪商模拟仅仅只有OHLC数据的话，K线内数据的生成有一套逻辑，如果最高价更接近开盘价，生成顺序是 open-&gt;high-&gt;low-&gt;close，此外还假设价格是没有gaps的 订单生成命令strategy.entry 订单生成函数这是进入市场的命令。 如果具有相同ID的订单已经挂起，则可修改订单。 如果没有指定ID的订单，则会发出新的订单。 要取消/停用预挂单，应使用命令strategy.cancel或strategy.cancel_all。 与函数strategy.order相比，strategy.entry功能受金字塔影响，可以正确反转市场位置。 如果“Limit”和“stop”参数均为“NaN”，则订单类型为市场订单。 1strategy.entry(id, long, qty, limit, stop, oca_name, oca_type, comment, when) → void strategy.exit 订单退出函数1strategy.exit(id, from_entry, qty, qty_percent, profit, limit, loss, stop, trail_price, trail_points, trail_offset, oca_name, comment, when) → void 这是一个退出指定进场或整个市场地位的命令，重点区分它和strategy.close 的不同 id(string): 订单的标识符。 from_entry(string): 这里填入要平仓的订单的标识符，默认为空。 qty: 平仓手数(弄清楚合约的大小) qty_percent: 平台的比例 profit: 获利点数(一定搞清楚单位是点还是步) limit: 与profit 相似，limit约定获利的价格 loss:止损点数 stop:与loss 相似，stop约定止损的价格 tail.*: 指明跟踪指数 strategy.order这条命令可以生成开仓也可以生成平仓命令，但是它不受金字塔影响。它的作用就是弥补strategy.entry 和 strategy.exit 函数的不灵活星。 实例下面是几个例子，可以帮助我们理解strategy函数 例1123456//@version=4strategy(&quot;revers demo&quot;)if bar_index &gt; 4000 strategy.entry(&quot;buy&quot;, strategy.long, 4, when=strategy.position_size &lt;= 0) strategy.entry(&quot;sell&quot;, strategy.short, 6, when=strategy.position_size &gt; 0)plot(strategy.equity) 当仓位为空头或者无头寸的话，买4。当仓位为多头的话，卖6。 我们可以看到entry中buy 或sell 在交易的时候，会自动平仓，平掉反向的仓位。仓位在+4 –&gt; -6 变化。 例21234567//@version=4strategy(&quot;Partial exit demo&quot;)if bar_index &gt; 6500 and bar_index &lt;6550 strategy.entry(&quot;buy&quot;, strategy.long, 40000, when=strategy.position_size &lt;= 0)strategy.exit(&quot;bracket1&quot;, &quot;buy&quot;, 20000, profit = 3000,loss = 3000)strategy.exit(&quot;bracket2&quot;, &quot;buy&quot;, profit=2000, loss=2000)plot(strategy.equity) 盈亏曲线 交易逻辑 buy：当空仓时候买入，40000笔合约（40000美金） bracket1：设定平仓对象为buy标识的交易，平仓2000美金，止盈300点（单位为步，3000步=300点）。止损300点 bracket2：止盈止损200点 下面结合交易清单具体分析 1：空仓买入4000美金 2：止损200点，亏损20000 * 200 * 0.0001 = $ 400，从图中可以看到是bracket2 先止损 3：价格继续向下，亏损300点，bracket1策略触发，亏损$ 600 4,5,6:同上逻辑 风险管理strategy.risk.* 一系列函数，可以帮助进行风险管理。当风险管理规则被激活的时候，没有订单会生成。 123456//@version=4strategy(&quot;multi risk demo&quot;, overlay=true, pyramiding=10, calc_on_order_fills = true)if year &gt; 2014 strategy.entry(&quot;LE&quot;, strategy.long)strategy.risk.max_intraday_filled_orders(5)strategy.risk.max_intraday_filled_orders(2) strategy.risk.max_intraday_filled_orders(2) 限制一天成交的最大的交易单数，一旦达到，所有未成交订单全部取消，成交订单关闭。并且一直关闭交易直到本交易日结束。 上图中，当第二笔交易生成的时候，同时也是两笔交易关闭的时间。 其余的函数参考手册 指标重绘历史数据仅仅包含OHLC，不包含线内的运动。这会导致的问题是，历史数据上的回测和实时数据不一致的情况。 另外一个担心是，未来函数的使用。这里尤其要关注security 函数，此函数可能会错误的引入未来的信息。 绘图Pine V4 中存在两种绘图类型：label 和 line。 注：用户的绘图和 编程绘图是不一样的，编程得到的绘图是不能用鼠标修改的。 和指标绘图函数(plot,plotshape,plotchar) 不一样的是，绘图函数可以在图表右侧没有K线的地方。 label1label.new(x, y, text, xloc, yloc, color, style, textcolor, size) → series[label] 1234//@version=4study(&quot;My Script&quot;, overlay=true)label.new(bar_index, high, style=label.style_none, text=&quot;x=&quot; + tostring(bar_index) + &quot;\\ny=&quot; + tostring(high)) x的位置是用bar_index 标识的，此时xloc 的默认值为xloc.barindex y的位置是最高价 xloc取值：xloc.bar_index(默认) 和 xloc.bar_time yloc取值： yloc.price 传入此函数，需要输入y值 yloc.abovebar,yloc.belowbar 启动时，y值会失效。标签在图表上部或者下部 style: 很多种，可能用到比较多的有label.style_none，无底色 label.set_* 一系列函数可以用来对对象进一步的修改。 line1line.new(x1, y1, x2, y2, xloc, extend, color, style, width) → series[line] extend: extend.none/extend.right/extend.left","categories":[{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/"},{"name":"Pine","slug":"量化/Pine","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/Pine/"}],"tags":[{"name":"Pine","slug":"Pine","permalink":"http://ppsteven.github.io/tags/Pine/"},{"name":"TradingView","slug":"TradingView","permalink":"http://ppsteven.github.io/tags/TradingView/"},{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/tags/%E9%87%8F%E5%8C%96/"}]},{"title":"Pine Script 学习笔记","slug":"Pine Script 学习笔记","date":"2019-10-31T14:03:08.000Z","updated":"2020-02-15T18:08:45.074Z","comments":false,"path":"2019/10/31/Pine Script 学习笔记/","link":"","permalink":"http://ppsteven.github.io/2019/10/31/Pine%20Script%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"Pine Script 学习笔记——基础语法篇（一）简介量化交易平台 TrendingView 是一个支持多种资产的投资平台，很多人在上面分享对于股票，外汇，数据货币等资产的投资观点，难得的是在上面能找到很多人的交易策略。 TrendingView 使用的是自己开发的Pine 语言作为脚本，这一点和MT4 开发的mql4 很像。用户可以自己编写脚本和策略，并与其他人分享。Pine 直观给我的印象比Mql4 更加简单，更加关注于策略本身，而不是编程技巧。 此外，Pine语言编辑器没有那么强大的debug 功能，这对于一开始上手练习来说，不是那么方便。不过它一直在更新，发展的很快。 TrendingView 对接了很多经纪商，使得它支持的交易品种很丰富，而且它的图表功能很强大。 下面记录一下自己学习Pine 脚本的一些基础的笔记，权当备忘。主要内容都参考自Pine 的脚本文档","text":"Pine Script 学习笔记——基础语法篇（一）简介量化交易平台 TrendingView 是一个支持多种资产的投资平台，很多人在上面分享对于股票，外汇，数据货币等资产的投资观点，难得的是在上面能找到很多人的交易策略。 TrendingView 使用的是自己开发的Pine 语言作为脚本，这一点和MT4 开发的mql4 很像。用户可以自己编写脚本和策略，并与其他人分享。Pine 直观给我的印象比Mql4 更加简单，更加关注于策略本身，而不是编程技巧。 此外，Pine语言编辑器没有那么强大的debug 功能，这对于一开始上手练习来说，不是那么方便。不过它一直在更新，发展的很快。 TrendingView 对接了很多经纪商，使得它支持的交易品种很丰富，而且它的图表功能很强大。 下面记录一下自己学习Pine 脚本的一些基础的笔记，权当备忘。主要内容都参考自Pine 的脚本文档 脚本结构指明用的Pine 脚本版本 1//@version=4 Pine 可以分为study脚本 和 strategy 脚本（指标&amp;策略）study 脚本必须包含 plot,plotshape,barcolor,line.new 等输出strategy 脚本包含 strategy.* 即交易函数 换行 Line wrapping1234567891011//例子1 换行需要空格a = open+ high+ low// 例子2 换行中不能有注释a = open+ high // 此处加注释会出问题// 例子3 函数内换行，空行必须要超过一个Tab（或者4个空格）label.new(bar_index, na, yloc=yloc.abovebar, text=t, color=hist ? color.green : color.red)// 这里空格必须超过4个 运算符 算术： + - * / % 1/2 = 01/2.0 = 0.5 比较: == != 逻辑: not and or 三元运算符： condition ? result1 : result2 iff(condition, result1, result2) 1有房？嫁:有车？: 嫁:帅？嫁: 不嫁 [] 运算符(History reference operator)close 代表最新的价格，close[1]代表了历史价格。 1close = close[0] //显示的是最新的收盘价 除此之外，Pine脚本里面还有一个变量 bar_index，记录着bar的数目，编号自左向右，从0开始。bar_index = (bar数量)N-1。 为什么运行close[bar_index-1] ≠ close[0] ?而close[bar_index-1] 会出错 函数Pine 脚本中包含了大量的自建函数，用户还可以自定义函数、 单行函数 1f(x,y) =&gt; x+y Pine Script 的函数不支持递归 即，不允许在函数中再次调用自己本身 多行函数 1234geom_average(x, y) =&gt; a = x*x b = y*y sqrt(a + b) Pine Script 需要（一个Tab 或者4空格，TrendingView 会自动用4个空格来替换掉Tab）来划定函数的范围 最后一行的表达式或 变量作为函数的输出结果 输出&gt;=2 123456fun(x,y) =&gt; a = x+y b = x-y retrun [a,b]// 调用函数[a,b] =fun(3,2) 函数的注意事项当在函数块中使用函数或者历史数据信息的时候要注意。因为所使用的历史信息是每一次连续调用生成的。 如果函数并不是在每一根柱线上都调用，那么数据生成就会出现错误。 例1 123456// 定义两个函数f1,f2f1(a) =&gt; a[1]f2() =&gt; close[1]// 说明下列用法的实际意义f1(close) 等价于 close[2]f2() 等价于 close[1] f1 传入的close 序列，需要在第一次调用后才能生成，所以f1 的 价格信息实际上比f2 晚一天 变量声明&amp;语句statementvar Pine 语言中变量定义的方式有两种： = 和 var 12345a = 1 // a为整形float a = 1 // a为浮点型var a = 0var int a = 0b = na //出错 变量定义的时候，需要指明变量的类型(或者 等式右侧表达式能指明类型亦可) na 没有特定的类型，所以赋值时会出错 var 关键词 var 是用于分配和一次性初始化变量的关键词。 不含var 关键词的变量在每次数据更新的时候都会覆盖变量的值。使用了var 关键词的变量，在数据更新中，可以“保持状态”。举例 12345678910111213141516//@version=4study(&quot;Var keyword example&quot;)var a = closevar b = 0.0var c = 0.0var green_bars_count = 0if close &gt; open var x = close b := x green_bars_count := green_bars_count + 1 if green_bars_count &gt;= 10 var y = close c := yplot(a)plot(b)plot(c) 变量 ‘a’ 保持系列中每个柱线的第一根柱线的收盘价。 变量 ‘b’保持系列中第一个“绿色”价格棒的收盘价。 变量 ‘c’保持系列中第十个“绿色”条的收盘价。 即a,b,c 都是一个常数。 去除var 的话，a,b,c 会随着价格变化而变化 if 语句 12345678910// This code compilesx = if close &gt; open closeelse open// This code doesn&apos;t compilex = if close &gt; open closeelse &quot;open&quot; 需要注意的是，与python不同，Pine要求，then 和 else语句返回的值的类型是相同的。在上面的第二个例子中，close 和 “open” 一个是float Series，另一个是string，不同类型的话，编译会出错。 1234 x = if close &gt; open close// If current close &gt; current open, then x = close.// Otherwise the x = na. if 语句中可以忽略else，但是系统会默认赋值（na,false,””） for 语句12for i = 1 to length-1 sum := sum + price[i] 执行模型Pine代码是根据价格信息计算的。但是价格信息并不是完整加载的，用户可以一直向左滑动图表，直到最早的一根柱子（Pro 用户可以在图表上加载10000左右，免费用户可以加载5000根柱子） 实时数据的计算Pine指标计算实时数据的时候和计算历史数据略有不同，因为实时数据会有addtional commit(?)和rollback action(?) 在实时数据的处理过程中，柱线的每一次变动都会引起Pine 指标的计算 rollback : 在每一根柱线更新时发生 commit : 在每一根柱线关闭时发生 对于判断柱线的状态，Pine中有一系列的自建函数 barstate.* 来显示当前柱线的状态。","categories":[{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/"},{"name":"Pine","slug":"量化/Pine","permalink":"http://ppsteven.github.io/categories/%E9%87%8F%E5%8C%96/Pine/"}],"tags":[{"name":"Pine","slug":"Pine","permalink":"http://ppsteven.github.io/tags/Pine/"},{"name":"TradingView","slug":"TradingView","permalink":"http://ppsteven.github.io/tags/TradingView/"},{"name":"量化","slug":"量化","permalink":"http://ppsteven.github.io/tags/%E9%87%8F%E5%8C%96/"}]},{"title":"Hexo 博客搭建:个性篇","slug":"hexo-blog-build-advanced","date":"2019-10-27T13:46:00.000Z","updated":"2020-01-21T09:09:01.089Z","comments":true,"path":"2019/10/27/hexo-blog-build-advanced/","link":"","permalink":"http://ppsteven.github.io/2019/10/27/hexo-blog-build-advanced/","excerpt":"通过上一篇文章，我们已经搭建好了一个博客的基本功能，已经可以开始编写博客了。下面我们简单写一点Hexo的美化配置","text":"通过上一篇文章，我们已经搭建好了一个博客的基本功能，已经可以开始编写博客了。下面我们简单写一点Hexo的美化配置 文章页个性配置主题目录下的 themes\\next_config.yml 文件负责与主题相关的配置，用户可以通过修改该文件来自定义与主题相关的内容或功能，修改后刷新浏览器即可即时生效。 目录导航设置基础配置themes\\next\\_config.yml 123456789# Table Of Contents in the Sidebartoc: enable: true # Automatically add list number to toc. number: true # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false 展开/隐藏目录层级默认情况下，next 的目录是多级折叠的，阅读时只会展开当前目录分支。我们希望目录完全展开，同时为了避免长目录结构，约定只展开到三级目录。三级以下的目录会被隐藏，只有当文章阅读到的时候才会展开。 themes\\next\\source\\css_custom\\custom.styl 1234//TOC目录默认展开三级，这里是指Markdown标签的h3.post-toc .nav .nav-level-2&gt;.nav-child &#123; display: block;&#125; 若是希望三级以下的目录完全被隐藏 1234//TOC目录默认只显示两级目录.nav-level-2 &gt; .nav-child &#123; display: none !important;&#125; 美化字体美化在 Google Fonts 上找到心仪的字体，然后在主题配置文件中为不同的应用场景配置字体，我们这里直接使用别人配置好的字体：别人的字体 12345678910111213141516171819202122232425262728293031# themes\\next\\_config.ymlfont: enable: true # 外链字体库地址，例如 //fonts.googleapis.com (默认值) host: # 全局字体，应用在 body 元素上 global: external: true family: Monda # 标题字体 (h1, h2, h3, h4, h5, h6) headings: external: true family: Roboto Slab # 文章字体 posts: external: true family: # Logo 字体 logo: external: true family: # 代码字体，应用于 code 以及代码块 codes: external: true family: 标签图标美化默认情况下标签前缀是 # 字符，用户可以通过修改主题源码将标签的字符前缀改为图标前缀 在文章布局模板中找到文末标签相关代码段，将 # 换成 &lt;i class=&quot;fa fa-tags&quot;&gt;&lt;/i&gt; 即可： 1234567891011# themes\\next\\layout\\_macro\\post.swig &lt;footer class=\"post-footer\"&gt; &#123;% if post.tags and post.tags.length and not is_index %&#125; &lt;div class=\"post-tags\"&gt; &#123;% for tag in post.tags %&#125;- &lt;a href=\"&#123;&#123; url_for(tag.path) &#125;&#125;\" rel=\"tag\"&gt;# &#123;&#123; tag.name &#125;&#125;&lt;/a&gt;+ &lt;a href=\"&#123;&#123; url_for(tag.path) &#125;&#125;\" rel=\"tag\"&gt;&lt;i class=\"fa fa-tags\"&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;% endfor %&#125; &lt;/div&gt; &#123;% endif %&#125; ... &lt;/footer&gt;","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"}]},{"title":"Hexo 博客搭建：基础篇","slug":"hexo-blog-build-basic","date":"2019-10-27T13:46:00.000Z","updated":"2020-01-21T04:15:46.698Z","comments":true,"path":"2019/10/27/hexo-blog-build-basic/","link":"","permalink":"http://ppsteven.github.io/2019/10/27/hexo-blog-build-basic/","excerpt":"Hexo 是一款基于node.js 的静态博库框架，而且可以方便的托管在Github 上， 这里简单记录一下Hexo 的安装配置过程。 本篇博客算是Hexo博客搭建的第一篇文章，以后会陆续写几篇优化的文章。","text":"Hexo 是一款基于node.js 的静态博库框架，而且可以方便的托管在Github 上， 这里简单记录一下Hexo 的安装配置过程。 本篇博客算是Hexo博客搭建的第一篇文章，以后会陆续写几篇优化的文章。 从0到1，快速搭建hexo博客下载node.js 官网下载LTS版本，直接安装。Hexo 是依赖于Node.js 和 git 工具，我们首先需要安装node.js ，然后利用npm去安装一些必要的插件。 安装hexo注意：切换为 root 账号操作，切换淘宝源 cnpm,会更加快npm的速度 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装hexo cnpm install hexo-cli -g 安装完后用hexo -v 查看一下是否安装成功 启动hexo在目录下创建 blog 文件夹 mkdir blog ,进入 cd blog 初始化hexo 1hexo init 出现 INFO Start blogging with Hexo! 表示安装完成 启动hexo 本地启动的博客会在localhost:4000中启动，用户在本地是找不到相对应的Web资源目录。markdown文件修改完后即会调用hexo中的引擎自动渲染。 1hexo server/s 清空hexo 1hexo 生成hexo 这一步会生成对应public文件夹，其中包含了页面对应的HTML文件，未来我们部署到服务器上看到的就是public文件夹中的内容。 1hexo generate / hexo g 第一篇博客1hexo new post &apos;my first blog&apos; 该命令会在 /Users/YourUserName/blog/source/_posts/ 文件夹下生成对应的 md文件 模板文件在./scaffolds/post.md中找到。 Github Page 部署传统的博客搭建成本非常高，因为我们需要自己租用服务器，购买域名。现在我们可以将我们的代码托管到github仓库中，并利用Github Page 作为我们博客的页面（同样Github也提供了对应的域名） 第一步：新建仓库 名字必须为自己的用户名+.github.io 如 PPsteven.github.io 第二步：安装git 插件git 插件可以帮助我们方便的把我们的修改提交到我们的仓库中，是一个很方便的插件。 1cnpm install --save hexo-deployer-git 第三步：在配置文件中添加仓库信息在配置文件_config.yml中找到如下代码，添加repo 信息和 branch 信息 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/PPsteven/PPsteven.github.io.git # github 仓库地址 branch: master # 提交到的分支 第四步：部署hexo123hexo clean #会清除缓存文件db.json及之前生成的静态文件夹public；hexo g #会重新生成静态文件夹public；hexo deploy/ hexo d #因为之前已经安装了插件并且在博客配置文件中也配置好了，所以这个命令会在博客根目录下生成一个.deploy_git的文件夹，并 把本地生成的静态文件部署到LiLei.github.io这个仓库中的master分支上； 如果是第一次部署，会提示输入github 账号和密码 成功！！ 远端访问：PPsteven.github.io Hexo CheetSheet 初始化目录：hexo init [folder] 新建文章：hexo new/n [layout] &lt;title&gt; 或 新建草稿：hexo new draft &lt;title&gt; 新建页面：hexo new page tags 将草稿发布为正式文章：hexo publish &lt;title&gt; 生成静态文件：hexo generate/g 监听文件变化：hexo g --watch 或 hexo g -w 部署：hexo deploy/d 先生成后部署：hexo d -g 等于 hexo g 加 hexo d 启动本地服务器（服务器会监听文件变化并自动更新） hexo server/s 启动调试：hexo s --debug 预览草稿：hexo s --draft 清除缓存：hexo clean 站点配置主题安装教程 安装教程： NexT主题官网 Butterfly主题 下载主题&amp;启动12345cd bloggit clone https://github.com/iissnan/hexo-theme-next themes/next# 编辑_config.ymltheme: next# theme: Butterfly NexT 主题配置设定主题/语言主题配置的文件在themes/NexT 文件夹下的_config.yml 中，我们按照官网教程，依次配置 12345#scheme: Muse#scheme: Mistscheme: Pisceslanguage: zh-Hans 添加标签/分类/关于页面hexo 新建命令 hexo n [layout] title 中 layout 有三个模板 post创建文章，生成在/source/_posts文件夹下，draft创建草稿，生成在/source/ _drafts 文件夹下，page创建页面，生成在/source/YourPageName文件夹下 ![image-20191027011714501](/Users/ppsteven/Library/Application Support/typora-user-images/image-20191027011714501.png) 新建页面 123hexo new page tagshexo new page categorieshexo new page about 修改菜单（编辑 themes/next/_config.yml） 123456789menu: home: / || home about: /about/ || user # 关于页面 tags: /tags/ || tags # 标签页面 categories: /categories/ || th # 分类页面 archives: /archives/ || archive # 归档页面 #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap commonweal: /404/ || heartbeat # 公益404 设置头像_config.yml 在blog 文件和 theme/next 文件夹下都有 blog 下的为站点配置文件，主题下的为主题配置文件 mkdir themes/next/source/uploads ，放置头像图片（jpg/gif 等） 修改配置文件 12# avatar: http://example.com/avatar.pngavatar: /uploads/avatar_1.jpg 设置作者昵称修改 站点配置文件 1author: Your name 设置阅读字数与时长需要安装插件，地址 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true 配置搜索服务Local Search添加百度/谷歌/本地 自定义站点内容搜索 1cnpm install hexo-generator-searchdb --save 编辑站点配置文件，新增如下代码 12345search: path: search.xml field: post format: html limit: 10000 编辑主题配置文件，启动本地搜索 123456789# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 3 设置摘要 12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: True length: 150 多端同步正常情况下，我们写的博客是备份在本地的，没有上传服务器，但是若是有多台电脑的话。如何保持同步是一个问题。最近用闲置的笔记本搞了一个manjaro 玩耍，需要进行多端同步。 创建分支在blog文件夹下，我们用hexo d 命令提交的仅仅是public 文件夹里面的内容，默认的是提交在 master 分支上。为了在同一个repo 下管理我们的博客，我们可以建立新的分支hexo github 上创建一个新的分支 hexo。进入仓库在，点击Branch，输入新的分支名回车建立 在本地仓库创建hexo 分支，添加remote 地址 123456$git checkout -b hexo # 代表创建并切换$git remote add origin git@github.com:PPsteven/hexo_source.git # 添加远端地址$git remote -v # 查看remote 地址origin git@github.com:PPsteven/PPsteven.github.io.git (fetch)origin git@github.com:PPsteven/PPsteven.github.io.git (push)# 表示添加成功 其实有一个取巧的方法，在GitHub上创建新的分支hexo 后，在blog 文件夹中直接将该仓库的hexo 分支克隆到本地。 1$git clone -b git@github.com:PPsteven/PPsteven.github.io.git 向本地分支添加文件 123$git add . # 本地文件添加至暂存区$git commit -m \"blog file backup\" # 暂存区文件提交至本地分支$git push origin hexo # 向远端hexo 分支提交文件 看到网上讨论，在提交文件的时候，themes 文件夹会出错。原因是themes 下文件夹的主题包含.git 文件，造成了冲突，删除即可。 同步分支进入新的电脑，同步到本地就可以编辑了 1$git pull origin hexo 参考教程： hexo教程:基本配置+更换主题+多终端工作+coding page部署分流(2) 如何使用 Hexo 和 GitHub Pages 搭建这个博客 学习了上面的教程后，基本的搭建和部署已经没有问题了。","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"}]},{"title":"Mac 入门基础环境搭建","slug":"Mac 入门配置","date":"2019-10-26T13:46:00.000Z","updated":"2020-02-15T17:21:39.268Z","comments":true,"path":"2019/10/26/Mac 入门配置/","link":"","permalink":"http://ppsteven.github.io/2019/10/26/Mac%20%E5%85%A5%E9%97%A8%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Homebrew常用命令 官网安装 Homebrew http://mxcl.github.com/homebrew/ 前言包管理软件 Win: 360软件管家 Debian/Ubuntu: apt包管理系统 Redhat/Fedora: yum包管理系统 Mac OS X: Macports,Fink,AppStore 以及 Homebrew 使用方法brew -v 查询Homebrew版本brew -h brew帮助brew update 更新Homebrewbrew install 安装任意软件brew uninstall 卸载任意软件brew search 查询任意包brew list 列出安装列表brew info 查看任意包内容信息brew upgrade 更新任意包brew cleanup 删除具体旧软件brew cleanup 删除所有旧软件brew outdated 已安装的包是否需要更新 item2+oh-my-zsh1sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" chsh -s /bin/zsh. # 命令航切换bash为zsh shelliterm的perference-&gt;profiles-&gt;commond 设置成/bin/zsh # iterm2 界面手动切换 更改shell 语言 cat /etc/shells # 查看所有 shell chsh -s /bin/zsh #切换为zsh 修改文件vi ~/.zshrcsource ~/.zshrc echo $SHELL # 查看当前shell Iterm2 使用技巧 参考 iTerm2常用的快捷键 设置全局打开快捷键 Perferemance -&gt; Keys -&gt;Hotkey -&gt; show/hide all windows with a system-wide hotkey command + shift + t # 设置快捷键 打开iterm2 1234567891011121314新建标签：command + t关闭标签：command + w切换全屏：command + enter查找：command + f垂直分屏：command + d垂直上下分屏：command + shift + d左右 tab 之间来回切换：⌘ + 1 / 2查看历史命令：command + ; （输入常用命令的前缀后使用该快捷键可以实现补全的功能）除当前行：ctrl + u / ctrl +c 上一条命令：ctrl + p搜索命令历史：ctrl + r清屏：clear重新打开：command + riTerm2 剪切板历史：command + shift + h zsh 插件配置目前已经有的自带插件在官网Github中可以看到，https://github.com/robbyrussell/oh-my-zsh/tree/master/plugins。凡是这里有的，都可以立刻生效。 参考页面 一些实用常用插件推荐 for zsh oh-my-zsh git 默认自带zsh-syntax-highlighting 语法高亮1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting 将zsh-syntax-highlighting 下载到zsh 的plugins 目录中 1plugins=(其他的插件 zsh-autosuggestions) zsh-autosuggestions 自动建议1git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions 1plugins=(其他的插件 zsh-autosuggestions) sublime 默认自带 命令 作用 st 打开sublime st + 文件夹 打开文件夹 st + 文件 打开文件 stt 打开当前文件夹 ，等价于 st . sst 管理员权限 相当于 sudo st z 默认自带12z -x 无效路径z 目录名称 autojump12345678910111213141516171819$ brew install autojump plugins=(其他的插件 autojump)# 如果是linux 系统可能比较麻烦一点，需要从github 上下源码安装（当然也可以保证是最新的）$ git clone git@github.com:wting/autojump.git autojump$ cd autojump$ ./install.py# 运行完毕后就会出现如下信息Please manually add the following line(s) to ~/.zshrc: [[ -s /home/ppsteven/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; source /home/ppsteven/.autojump/etc/profile.d/autojump.sh autoload -U compinit &amp;&amp; compinit -uPlease restart terminal(s) before running autojump.# 按照操作在 .zshrc 中添加，我是乖乖添加了，其实我们可以直接在plugins 中添加的plugins=(其他的插件 autojump) 附录.zshrc配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123# If you come from bash you might have to change your $PATH.# export PATH=$HOME/bin:/usr/local/bin:$PATH# Path to your oh-my-zsh installation.export ZSH=\"/Users/ppsteven/.oh-my-zsh\"# Set name of the theme to load --- if set to \"random\", it will# load a random theme each time oh-my-zsh is loaded, in which case,# to know which specific one was loaded, run: echo $RANDOM_THEME# See https://github.com/robbyrussell/oh-my-zsh/wiki/Themes# ZSH_THEME=\"agnoster\"ZSH_THEME=\"ys\"# Set list of themes to pick from when loading at random# Setting this variable when ZSH_THEME=random will cause zsh to load# a theme from this variable instead of looking in ~/.oh-my-zsh/themes/# If set to an empty array, this variable will have no effect.# ZSH_THEME_RANDOM_CANDIDATES=( \"robbyrussell\" \"agnoster\" )# Uncomment the following line to use case-sensitive completion.# CASE_SENSITIVE=\"true\"# Uncomment the following line to use hyphen-insensitive completion.# Case-sensitive completion must be off. _ and - will be interchangeable.# HYPHEN_INSENSITIVE=\"true\"# Uncomment the following line to disable bi-weekly auto-update checks.# DISABLE_AUTO_UPDATE=\"true\"# Uncomment the following line to automatically update without prompting.# DISABLE_UPDATE_PROMPT=\"true\"# Uncomment the following line to change how often to auto-update (in days).# export UPDATE_ZSH_DAYS=13# Uncomment the following line if pasting URLs and other text is messed up.# DISABLE_MAGIC_FUNCTIONS=true# Uncomment the following line to disable colors in ls.# DISABLE_LS_COLORS=\"true\"# Uncomment the following line to disable auto-setting terminal title.# DISABLE_AUTO_TITLE=\"true\"# Uncomment the following line to enable command auto-correction.# ENABLE_CORRECTION=\"true\"# Uncomment the following line to display red dots whilst waiting for completion.# COMPLETION_WAITING_DOTS=\"true\"# Uncomment the following line if you want to disable marking untracked files# under VCS as dirty. This makes repository status check for large repositories# much, much faster.# DISABLE_UNTRACKED_FILES_DIRTY=\"true\"# Uncomment the following line if you want to change the command execution time# stamp shown in the history command output.# You can set one of the optional three formats:# \"mm/dd/yyyy\"|\"dd.mm.yyyy\"|\"yyyy-mm-dd\"# or set a custom format using the strftime function format specifications,# see 'man strftime' for details.# HIST_STAMPS=\"mm/dd/yyyy\"# Would you like to use another custom folder than $ZSH/custom?# ZSH_CUSTOM=/path/to/new-custom-folder# Which plugins would you like to load?# Standard plugins can be found in ~/.oh-my-zsh/plugins/*# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/# Example format: plugins=(rails git textmate ruby lighthouse)# Add wisely, as too many plugins slow down shell startup.plugins=( git# zsh-syntax-highlighting zsh-autosuggestions sublime autojump )source $ZSH/oh-my-zsh.sh# User configuration# export MANPATH=\"/usr/local/man:$MANPATH\"# You may need to manually set your language environment# export LANG=en_US.UTF-8# Preferred editor for local and remote sessions# if [[ -n $SSH_CONNECTION ]]; then# export EDITOR='vim'# else# export EDITOR='mvim'# fi# added by Anaconda3 2019.07 installer# &gt;&gt;&gt; conda init &gt;&gt;&gt;# !! Contents within this block are managed by 'conda init' !!__conda_setup=\"$(CONDA_REPORT_ERRORS=false '/Users/ppsteven/anaconda3/bin/conda' shell.bash hook 2&gt; /dev/null)\"if [ $? -eq 0 ]; then \\eval \"$__conda_setup\"else if [ -f \"/Users/ppsteven/anaconda3/etc/profile.d/conda.sh\" ]; then . \"/Users/ppsteven/anaconda3/etc/profile.d/conda.sh\" CONDA_CHANGEPS1=false conda activate base else \\export PATH=\"/Users/ppsteven/anaconda3/bin:$PATH\" fifiunset __conda_setup# &lt;&lt;&lt; conda init &lt;&lt;&lt;# Compilation flags# export ARCHFLAGS=\"-arch x86_64\"# Set personal aliases, overriding those provided by oh-my-zsh libs,# plugins, and themes. Aliases can be placed here, though oh-my-zsh# users are encouraged to define aliases within the ZSH_CUSTOM folder.# For a full list of active aliases, run `alias`.## Example aliasesalias zshconfig=\"vim ~/.zshrc\"# alias ohmyzsh=\"mate ~/.oh-my-zsh\" 解压软件解压软件 unrarbrew install unrar 使用方法 unrar x test.rar # 解压到当前目录 解压软件 7zbrew search 7z # p7zip brew install p7zip 使用方法 7z e filename.7z 图床软件PicGo安装教程 https://github.com/Molunerfinn/PicGo 看完上面的配置才发现也是找工作的学生，真是厉害 Github 图床配置 12345PPsteven/picturesmasterToken:XXXXXimg/https://cdn.jsdelivr.net/gh/PPsteven/pictures 设置 ssh 远程连接超时为了解决 ssh 连接一段时间后会断开，我们需要在 服务端 和 客户端 做出以下操作 12/etc/ssh/sshd_config # 服务端配置/etc/ssh/ssh_config # 客户端配置 服务器端1234vim /etc/ssh/sshd_config# 修改为ClientAliveInterval 30 # 客户端每隔多少秒向服务发送一个心跳数据ClientAliveCountMax 86400 # 客户端多少秒没有相应，服务器自动断掉连接 最后重启 sshd 服务 (centos7+) 1sudo systemctl restart sshd 客户端12ServerAliveInterval 60 # 每分钟发送一次, 然后客户端响应, 从而保持长连接;ServerAliveCountMax 3 # 表示服务器发出请求后客户端没有响应的次数达到3次, 就自动断开 Charles破解教程 参考教程：Charles mac 破解教程 123# 工具栏中的 help --&gt; registerRegistered Name: https://zhile.ioLicense Key: 48891cf209c6d32bf4 Charles设置指南：Charles使用指南","categories":[{"name":"电脑基本配置","slug":"电脑基本配置","permalink":"http://ppsteven.github.io/categories/%E7%94%B5%E8%84%91%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ppsteven.github.io/tags/Hexo/"}]}]}